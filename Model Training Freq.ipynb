{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epycmNPr0I3d"
   },
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Dwn1PtIp4058"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matteo/.pyenv/versions/3.11.2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.],\n",
      "         [ 3.,  4.,  5.],\n",
      "         [ 6.,  7.,  8.],\n",
      "         [ 9., 10., 11.],\n",
      "         [12., 13., 14.],\n",
      "         [15., 16., 17.],\n",
      "         [18., 19., 20.],\n",
      "         [21., 22., 23.],\n",
      "         [24., 25., 26.],\n",
      "         [27., 28., 29.]]])\n",
      "tensor([[    0.,    60.,   336.,   990.,  2184.,  4080.,  6840., 10626., 15600.,\n",
      "         21924.]])\n",
      "tensor([[   60.,   990.,  4080., 10626., 21924.]])\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from IPython.display import display, clear_output\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "\n",
    "ROOT = os.path.join(\"./\")\n",
    "sys.path.append(ROOT + \"lib\")\n",
    "sys.path.append(ROOT + \"models\")\n",
    "\n",
    "from helpers import *\n",
    "from sourceset import SourceSet\n",
    "from fourier import FourierModelTest, FourierModelTestNU\n",
    "from final import AnomalyDetector\n",
    "from transformer import FluxAnomalyPredictionTF\n",
    "from general_trainer import compete, gen_train\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_default_device(device)\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2917,
     "status": "ok",
     "timestamp": 1698123021083,
     "user": {
      "displayName": "Matteo",
      "userId": "07662895649750931658"
     },
     "user_tz": 420
    },
    "id": "0o5bi2-e_n2z",
    "outputId": "1792997b-1077-4089-b8ae-b1b818428b61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<sourceset.SourceSet at 0x104535c90>, <sourceset.SourceSet at 0x169dbb2d0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with open(ROOT + \"processed_datasets/transittrain.pt\", \"rb\") as f:\n",
    "#   data_train = torch.load(f, map_location=device)\n",
    "# with open(ROOT + \"processed_datasets/transitvalid.pt\", \"rb\") as f:\n",
    "#   data_valid = torch.load(f, map_location=device)\n",
    "\n",
    "with open(ROOT + \"processed_datasets/freqtrain.pt\", \"rb\") as f:\n",
    "  data_train = torch.load(f, map_location=device)\n",
    "with open(ROOT + \"processed_datasets/freqtrain.pt\", \"rb\") as f:\n",
    "  data_valid = torch.load(f, map_location=device)\n",
    "\n",
    "\n",
    "\n",
    "data_train, data_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PU4Zzbo31tIp"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1698123021980,
     "user": {
      "displayName": "Matteo",
      "userId": "07662895649750931658"
     },
     "user_tz": 420
    },
    "id": "QCaXFn0b4T4E",
    "outputId": "046486bb-7ddf-4d47-ff86-8c8da5e3c5eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blend_bilinear.weight\n",
      "torch.Size([6, 6, 6])\n",
      "blend_bilinear.bias\n",
      "torch.Size([6])\n",
      "selfattn_signal.in_proj_weight\n",
      "torch.Size([6, 2])\n",
      "selfattn_signal.in_proj_bias\n",
      "torch.Size([6])\n",
      "selfattn_signal.out_proj.weight\n",
      "torch.Size([2, 2])\n",
      "selfattn_signal.out_proj.bias\n",
      "torch.Size([2])\n",
      "selfattn_fourier.in_proj_weight\n",
      "torch.Size([6, 2])\n",
      "selfattn_fourier.in_proj_bias\n",
      "torch.Size([6])\n",
      "selfattn_fourier.out_proj.weight\n",
      "torch.Size([2, 2])\n",
      "selfattn_fourier.out_proj.bias\n",
      "torch.Size([2])\n",
      "to_out.weight\n",
      "torch.Size([3, 6])\n",
      "to_out.bias\n",
      "torch.Size([3])\n",
      "291\n"
     ]
    }
   ],
   "source": [
    "model = AnomalyDetector()\n",
    "model_pars = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_pars])\n",
    "\n",
    "for p in model.named_parameters():\n",
    "    print(p[0])\n",
    "    print(p[1].size())\n",
    "\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 202,
     "status": "ok",
     "timestamp": 1698123023002,
     "user": {
      "displayName": "Matteo",
      "userId": "07662895649750931658"
     },
     "user_tz": 420
    },
    "id": "BOJnl8dTJEoi",
    "outputId": "4aa465eb-c350-44e1-9ba4-8fb3b276d6dc"
   },
   "outputs": [],
   "source": [
    "train = DataLoader(data_train, batch_size=len(data_train)//100, shuffle=True, collate_fn=padded_collate)\n",
    "valid = DataLoader(data_valid, batch_size=len(data_valid)//100, shuffle=False, collate_fn=padded_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XX8cN71g14oT"
   },
   "source": [
    "# Training Loop (Single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "blue"
         },
         "mode": "lines",
         "name": "Training Loss",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299
         ],
         "y": [
          1.11412167151769,
          1.1075928593675295,
          1.0824760258197785,
          1.1000718588630358,
          1.0881997302174569,
          1.080190196633339,
          1.0655928239226342,
          1.051158327360948,
          1.061589243511359,
          1.0394405995806058,
          1.0089254940549532,
          0.9797792529066404,
          1.0153541080653667,
          0.9822025810678799,
          1.0167830566565195,
          0.9637928927938143,
          1.0673120928307374,
          0.968507464726766,
          0.9390213285883268,
          0.9878173472980658,
          0.9324514490862688,
          0.9198432323833307,
          0.9362206809222698
         ]
        },
        {
         "line": {
          "color": "orange"
         },
         "mode": "lines",
         "name": "Validation Loss",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299
         ],
         "y": [
          1.938750610169436,
          1.4027879353845492,
          1.5202618902789253,
          1.1611561541755995,
          1.4410244186844163,
          1.511985568915649,
          1.990991497272686,
          1.3863971875980496,
          1.5366018794312064,
          3.0457286229667564,
          2.780459573272189,
          2.643527768883361,
          2.415339394576016,
          4.267163909886343,
          3.172557787530563,
          5.04203365072608,
          1.8923664159869076,
          2.937491629105557,
          3.4867018131228784,
          3.988445064922174,
          3.162553667105264,
          5.20547161536136,
          3.8436633606741375
         ]
        },
        {
         "line": {
          "color": "gray"
         },
         "mode": "lines",
         "name": "Null Accuracy",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299
         ],
         "y": [
          0.74999999375,
          0.7833333268055557,
          0.7916666600694445,
          0.7999999933333334,
          0.04166666631944445,
          0.024999999791666668,
          0.03333333305555556,
          0.824999993125,
          0.8166666598611112,
          0.7999999933333334,
          0.7833333268055557,
          0.833333326388889,
          0.8083333265972223,
          0.674999994375,
          0.8833333259722222,
          0.7666666602777779,
          0.8416666596527779,
          0.8666666594444445,
          0.8916666592361112,
          0.833333326388889,
          0.8916666592361112,
          0.8416666596527779,
          0.8583333261805556
         ]
        },
        {
         "line": {
          "color": "yellow"
         },
         "mode": "lines",
         "name": "Nova Accuracy",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299
         ],
         "y": [
          0,
          0,
          0,
          0.1666666652777778,
          0.4833333293055556,
          0.5749999952083333,
          0.5666666619444445,
          0.09999999916666667,
          0.0833333326388889,
          0.024999999791666668,
          0.19166666506944446,
          0.22499999812500002,
          0.22499999812500002,
          0.25833333118055557,
          0.0833333326388889,
          0.17499999854166667,
          0.19999999833333335,
          0.17499999854166667,
          0.058333332847222225,
          0.1583333320138889,
          0.14166666548611112,
          0.22499999812500002,
          0.28333333097222224
         ]
        },
        {
         "line": {
          "color": "green"
         },
         "mode": "lines",
         "name": "Pulsator Accuracy",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299
         ],
         "y": [
          0.8333332638888946,
          0.7999999333333389,
          0.7333332722222273,
          0.36666663611111366,
          0.8416665965277836,
          0.7333332722222273,
          0.7249999395833383,
          0.4166666319444473,
          0.5166666236111147,
          0.6583332784722268,
          0.6749999437500047,
          0.3999999666666694,
          0.4499999625000031,
          0.8166665986111168,
          0.36666663611111366,
          0.7333332722222273,
          0.4499999625000031,
          0.4499999625000031,
          0.4166666319444473,
          0.5999999500000042,
          0.2333333138888905,
          0.3999999666666694,
          0.24999997916666838
         ]
        },
        {
         "line": {
          "color": "purple"
         },
         "mode": "lines",
         "name": "Transit Accuracy",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299
         ],
         "y": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
         ]
        },
        {
         "line": {
          "color": "red"
         },
         "mode": "lines",
         "name": "Total Validation Accuracy",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299
         ],
         "y": [
          0.5277777777777778,
          0.5277777777777778,
          0.5083333333333333,
          0.4444444444444444,
          0.45555555555555555,
          0.4444444444444444,
          0.44166666666666665,
          0.44722222222222224,
          0.4722222222222222,
          0.49444444444444446,
          0.55,
          0.4861111111111111,
          0.49444444444444446,
          0.5833333333333334,
          0.4444444444444444,
          0.5583333333333333,
          0.49722222222222223,
          0.49722222222222223,
          0.45555555555555555,
          0.5305555555555556,
          0.4222222222222222,
          0.4888888888888889,
          0.4638888888888889
         ]
        }
       ],
       "layout": {
        "legend": {
         "x": 1,
         "xanchor": "right",
         "y": 1,
         "yanchor": "top"
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Training and Validation Loss Over Epochs: 22/300"
        },
        "xaxis": {
         "linecolor": "black",
         "linewidth": 1,
         "mirror": true,
         "range": [
          0,
          300
         ],
         "showline": true,
         "tickfont": {
          "size": 12
         },
         "title": {
          "text": "Epochs"
         }
        },
        "yaxis": {
         "linecolor": "black",
         "linewidth": 1,
         "mirror": true,
         "range": [
          0,
          2
         ],
         "showline": true,
         "tickfont": {
          "size": 12
         },
         "title": {
          "text": "Loss"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Failed:  1\n",
      "Epoch  22 :  0.9362206809222698\n",
      "nulls: 0.8583333261805556 novas:  0.28333333097222224 pulsators:  0.24999997916666838 transits:  0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m optim \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.003\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.00005\u001b[39m)\n\u001b[1;32m      4\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mgen_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/WISE/./lib/general_trainer.py:60\u001b[0m, in \u001b[0;36mgen_train\u001b[0;34m(model, kwargs, optim, lossfn, trainloader, validloader, epochs, log)\u001b[0m\n\u001b[1;32m     58\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m\"\u001b[39m, data)\n\u001b[1;32m     59\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m\"\u001b[39m, label)\n\u001b[0;32m---> 60\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m log:\n\u001b[1;32m     62\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOut\u001b[39m\u001b[38;5;124m\"\u001b[39m, out)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/WISE/./models/final.py:30\u001b[0m, in \u001b[0;36mAnomalyDetector.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(x[:, :, \u001b[38;5;241m1\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m# Gives N-long vector \u001b[39;00m\n\u001b[1;32m     28\u001b[0m x \u001b[38;5;241m=\u001b[39m x[:, :, (\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m)] \u001b[38;5;66;03m# Removed std feature\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m selfattend_signal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselfattn_signal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     31\u001b[0m selfattend_fourier \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselfattn_fourier(x,x,x)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     34\u001b[0m postattn_signal \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mprod(selfattend_signal, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze() \u001b[38;5;66;03m# Multiplies dim=2 (embed_dim) with itself down into 1 row (N x L)\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/torch/nn/modules/activation.py:1189\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1175\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1176\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1177\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1186\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1187\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1189\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/torch/nn/functional.py:5110\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5108\u001b[0m tens_ops \u001b[38;5;241m=\u001b[39m (query, key, value, in_proj_weight, in_proj_bias, bias_k, bias_v, out_proj_weight, out_proj_bias)\n\u001b[1;32m   5109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tens_ops):\n\u001b[0;32m-> 5110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtens_ops\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5116\u001b[0m \u001b[43m        \u001b[49m\u001b[43membed_dim_to_check\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5118\u001b[0m \u001b[43m        \u001b[49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5119\u001b[0m \u001b[43m        \u001b[49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5122\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mout_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mout_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5131\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_separate_proj_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_separate_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mq_proj_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk_proj_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mv_proj_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mv_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatic_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatic_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatic_v\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatic_v\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5137\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5138\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5140\u001b[0m is_batched \u001b[38;5;241m=\u001b[39m _mha_shape_check(query, key, value, key_padding_mask, attn_mask, num_heads)\n\u001b[1;32m   5142\u001b[0m \u001b[38;5;66;03m# For unbatched input, we unsqueeze at the expected batch-dim to pretend that the input\u001b[39;00m\n\u001b[1;32m   5143\u001b[0m \u001b[38;5;66;03m# is batched, run the computation and before returning squeeze the\u001b[39;00m\n\u001b[1;32m   5144\u001b[0m \u001b[38;5;66;03m# batch dimension so that the output doesn't carry this temporary batch dimension.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/torch/overrides.py:1534\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_torch_function_mode_enabled():\n\u001b[1;32m   1531\u001b[0m     \u001b[38;5;66;03m# if we're here, the mode must be set to a TorchFunctionStackMode\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m     \u001b[38;5;66;03m# this unsets it and calls directly into TorchFunctionStackMode's torch function\u001b[39;00m\n\u001b[1;32m   1533\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _pop_mode_temporarily() \u001b[38;5;28;01mas\u001b[39;00m mode:\n\u001b[0;32m-> 1534\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mmode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1535\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1536\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/torch/utils/_device.py:62\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/torch/nn/functional.py:5302\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5300\u001b[0m attn_output_weights \u001b[38;5;241m=\u001b[39m softmax(attn_output_weights, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   5301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dropout_p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m-> 5302\u001b[0m     attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout_p\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5304\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(attn_output_weights, v)\n\u001b[1;32m   5306\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(tgt_len \u001b[38;5;241m*\u001b[39m bsz, embed_dim)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/torch/nn/functional.py:1252\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(p))\n\u001b[0;32m-> 1252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kwargs=dict()\n",
    "model = AnomalyDetector(**kwargs).to(device)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.003, weight_decay=0.00005)\n",
    "loss = torch.nn.CrossEntropyLoss().to(device)\n",
    "gen_train(model, kwargs, optim, loss, train, valid, 300, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0.])\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "opacity": 0.7,
          "size": 5
         },
         "mode": "markers",
         "name": "w1mpro z-scored",
         "type": "scatter",
         "x": [
          0,
          0.00004262767834006809,
          0.00008521416020812467,
          0.0001278418640140444,
          0.0001491351140430197,
          0.00017042836407199502,
          0.0001917627960210666,
          0.00021305604605004191,
          0.00023434929607901722,
          0.00025564254610799253,
          0.00027697699260897934,
          0.0002982702280860394,
          0.0003195634635630995,
          0.00034085672814399004,
          0.0003621499636210501,
          0.00036219117464497685,
          0.000404777645599097,
          0.00044736414565704763,
          0.0004474053275771439,
          0.001427304930984974,
          0.0014486394356936216,
          0.05863862857222557,
          0.058681175112724304,
          0.05872371792793274,
          0.05876626446843147,
          0.05878756195306778,
          0.058808814734220505,
          0.05880885571241379,
          0.058830104768276215,
          0.05885139852762222,
          0.05887265130877495,
          0.058893945068120956,
          0.05891519784927368,
          0.05893649160861969,
          0.0589577853679657,
          0.058979034423828125,
          0.05900032818317413,
          0.05904287472367287,
          0.0590854212641716,
          0.11798493564128876,
          0.11806990951299667,
          0.11811237037181854,
          0.11813361942768097,
          0.11815487593412399,
          0.11817612498998642,
          0.11819738149642944,
          0.11821858584880829,
          0.11823984235525131,
          0.11826109141111374,
          0.11828234791755676,
          0.11830359697341919,
          0.11834605783224106,
          0.11838856339454651,
          0.11843102425336838,
          0.1747230738401413,
          0.17476549744606018,
          0.1748291403055191,
          0.17485038936138153,
          0.17487159371376038,
          0.17489281296730042,
          0.17491401731967926,
          0.1749352216720581,
          0.17495644092559814,
          0.17497768998146057,
          0.1749989092350006,
          0.17502011358737946,
          0.1750413179397583,
          0.17508374154567719,
          0.17512616515159607,
          0.17516863346099854,
          0.23575077950954437,
          0.23579315841197968,
          0.23579318821430206,
          0.23583558201789856,
          0.23587799072265625,
          0.2358991652727127,
          0.23592038452625275,
          0.2359415888786316,
          0.23596279323101044,
          0.2359839677810669,
          0.23600518703460693,
          0.23602639138698578,
          0.23604759573936462,
          0.23608998954296112,
          0.23611119389533997,
          0.23615357279777527,
          0.23615361750125885,
          0.23619599640369415,
          0.29078617691993713,
          0.29082855582237244,
          0.29087093472480774,
          0.2908921539783478,
          0.29091331362724304,
          0.2909345328807831,
          0.29095569252967834,
          0.2909769117832184,
          0.29099807143211365,
          0.2910192310810089,
          0.2910192906856537,
          0.29104045033454895,
          0.291061669588089,
          0.29108282923698425,
          0.29112520813941956,
          0.2911463975906372,
          0.2911887764930725,
          0.2912311553955078,
          0.2929687201976776,
          0.2929898798465729,
          0.3535657823085785,
          0.3535658121109009,
          0.3536081612110138,
          0.3536505401134491,
          0.353692889213562,
          0.35371407866477966,
          0.3537352681159973,
          0.3537564277648926,
          0.35377758741378784,
          0.3537776470184326,
          0.3537988066673279,
          0.35381999611854553,
          0.3538411557674408,
          0.35386237502098083,
          0.3538835346698761,
          0.3539259135723114,
          0.3539682626724243,
          0.3540106415748596,
          0.3547731935977936,
          0.35479435324668884,
          0.3548155426979065,
          0.3548579216003418,
          0.3549002707004547,
          0.35494264960289,
          0.4073735475540161,
          0.40838995575904846,
          0.40838998556137085,
          0.4084746539592743,
          0.40853822231292725,
          0.4085593819618225,
          0.4085805416107178,
          0.4086228907108307,
          0.40864405035972595,
          0.4086652398109436,
          0.40868639945983887,
          0.4087076187133789,
          0.40874993801116943,
          0.40879228711128235,
          0.4723586440086365,
          0.4724009931087494,
          0.47242215275764465,
          0.4724433422088623,
          0.47246450185775757,
          0.47248566150665283,
          0.4725068509578705,
          0.47252801060676575,
          0.472549170255661,
          0.47257035970687866,
          0.4725915193557739,
          0.4726126790046692,
          0.47263386845588684,
          0.47267618775367737,
          0.4727185368537903,
          0.4727608859539032,
          0.5249097347259521,
          0.5249520540237427,
          0.5249943733215332,
          0.5250366926193237,
          0.525057852268219,
          0.5250790119171143,
          0.5251213908195496,
          0.5251425504684448,
          0.5251636505126953,
          0.5251848101615906,
          0.5252060294151306,
          0.5252271890640259,
          0.5252483487129211,
          0.5253118276596069,
          0.5253541469573975,
          0.525396466255188,
          0.5901211500167847,
          0.5901634693145752,
          0.5901634693145752,
          0.5902057886123657,
          0.590226948261261,
          0.5902481079101562,
          0.5902692675590515,
          0.5902904272079468,
          0.590311586856842,
          0.5903327465057373,
          0.5903539061546326,
          0.5903751254081726,
          0.5903962254524231,
          0.5904173851013184,
          0.5904385447502136,
          0.5904809236526489,
          0.5905231833457947,
          0.6426958441734314,
          0.6426958441734314,
          0.6427804827690125,
          0.642822802066803,
          0.6428439021110535,
          0.6428439617156982,
          0.6428651213645935,
          0.6428862810134888,
          0.642907440662384,
          0.6429285407066345,
          0.6429497599601746,
          0.6429920792579651,
          0.6430131793022156,
          0.6430343985557556,
          0.6430978178977966,
          0.6431401371955872,
          0.6431824564933777,
          0.7078431844711304,
          0.7088164687156677,
          0.7088587880134583,
          0.7089011073112488,
          0.708922266960144,
          0.708943247795105,
          0.7089645862579346,
          0.7089856863021851,
          0.7090068459510803,
          0.7090280055999756,
          0.7090491652488708,
          0.7090703248977661,
          0.7090914845466614,
          0.7091126441955566,
          0.7091338038444519,
          0.7091761231422424,
          0.7092183828353882,
          0.7092607617378235,
          0.7605277299880981,
          0.7605700492858887,
          0.7605912089347839,
          0.7606123089790344,
          0.7606123685836792,
          0.7606546878814697,
          0.7606757879257202,
          0.7606968283653259,
          0.7607179284095764,
          0.760739266872406,
          0.7607815861701965,
          0.760802686214447,
          0.7608873248100281,
          0.7609296441078186,
          0.7614158987998962,
          0.7614582180976868,
          0.7615639567375183,
          0.7615851163864136,
          0.7616274356842041,
          0.7616485953330994,
          0.7616908550262451,
          0.7617120146751404,
          0.7617543339729309,
          0.7617754936218262,
          0.7618177533149719,
          0.7618178129196167,
          0.761902391910553,
          0.8266242146492004,
          0.826666533946991,
          0.8267087936401367,
          0.8267087936401367,
          0.826729953289032,
          0.8267510533332825,
          0.8267722725868225,
          0.826793372631073,
          0.8268143534660339,
          0.8268356919288635,
          0.826856791973114,
          0.8268568515777588,
          0.8268779516220093,
          0.8268991112709045,
          0.8269202709197998,
          0.8269413709640503,
          0.8269836902618408,
          0.8270260095596313,
          0.8270682692527771,
          0.8792397379875183,
          0.8792819976806641,
          0.8793665766716003,
          0.8793877363204956,
          0.8794299960136414,
          0.8794511556625366,
          0.8794934153556824,
          0.8795356750488281,
          0.8795568346977234,
          0.8795990943908691,
          0.8796413540840149,
          0.8796836733818054,
          0.9444440007209778,
          0.9444862604141235,
          0.9445496201515198,
          0.9445707201957703,
          0.9445918798446655,
          0.944612979888916,
          0.9446341395378113,
          0.9446552395820618,
          0.944676399230957,
          0.9446974992752075,
          0.9447186589241028,
          0.9447609186172485,
          0.9448031187057495,
          0.9448031783103943,
          0.9448453783988953,
          0.944887638092041,
          0.9468947052955627,
          0.9469158053398132,
          0.9970255494117737,
          0.9970677495002747,
          0.9971521496772766,
          0.9971732497215271,
          0.9972153902053833,
          0.9972786903381348,
          0.9972997903823853,
          0.9973208904266357,
          0.9973419904708862,
          0.9973630905151367,
          0.9973841905593872,
          0.9974263906478882,
          0.9974263906478882,
          0.9974685907363892,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
         ],
         "y": [
          2.895444869995117,
          2.878053665161133,
          2.8643264770507812,
          2.846027374267578,
          2.8542613983154297,
          2.90276837348938,
          2.846942186355591,
          2.8441977500915527,
          2.8634114265441895,
          2.869817018508911,
          2.82315993309021,
          2.829561948776245,
          2.8341352939605713,
          2.869817018508911,
          2.896360158920288,
          2.869817018508911,
          2.8441977500915527,
          2.856091260910034,
          2.8268182277679443,
          2.871647357940674,
          2.8487720489501953,
          2.934817314147949,
          2.866156578063965,
          2.827732801437378,
          2.84328293800354,
          2.8670716285705566,
          2.8441977500915527,
          2.8414533138275146,
          2.8387088775634766,
          2.896360158920288,
          2.849686861038208,
          2.856091260910034,
          2.871647357940674,
          2.8414533138275146,
          2.8634114265441895,
          2.8588361740112305,
          2.8579213619232178,
          2.861581325531006,
          2.8441977500915527,
          2.8441977500915527,
          2.8506016731262207,
          2.8689019680023193,
          2.846027374267578,
          2.8487720489501953,
          2.849686861038208,
          2.840538501739502,
          2.8679866790771484,
          2.8506016731262207,
          2.8624963760375977,
          2.849686861038208,
          2.8423681259155273,
          2.853346347808838,
          2.8551764488220215,
          2.8734776973724365,
          2.8478569984436035,
          2.8396236896514893,
          2.8624963760375977,
          2.8478569984436035,
          2.8396236896514893,
          2.829561948776245,
          2.8213307857513428,
          2.837794303894043,
          2.7664811611175537,
          2.8643264770507812,
          2.8506016731262207,
          2.8387088775634766,
          2.870732069015503,
          2.860666275024414,
          2.8396236896514893,
          2.8396236896514893,
          2.871647357940674,
          2.8286473751068115,
          2.846942186355591,
          2.8643264770507812,
          2.835050106048584,
          2.849686861038208,
          2.8807992935180664,
          2.824989080429077,
          2.8259036540985107,
          2.882629871368408,
          2.878053665161133,
          2.869817018508911,
          2.877138376235962,
          2.8387088775634766,
          2.883545160293579,
          2.8423681259155273,
          2.837794303894043,
          2.849686861038208,
          2.871647357940674,
          2.840538501739502,
          2.8195018768310547,
          2.773791790008545,
          2.816758394241333,
          2.8798840045928955,
          2.820416212081909,
          2.870732069015503,
          2.852431535720825,
          2.8423681259155273,
          2.8689019680023193,
          2.8643264770507812,
          2.8478569984436035,
          2.857006311416626,
          2.8506016731262207,
          2.8487720489501953,
          2.8624963760375977,
          2.8441977500915527,
          2.8396236896514893,
          2.832305908203125,
          2.8332207202911377,
          2.8286473751068115,
          2.8597512245178223,
          2.803956985473633,
          2.849686861038208,
          2.8396236896514893,
          2.8542613983154297,
          2.8240745067596436,
          2.865241527557373,
          2.840538501739502,
          2.857006311416626,
          2.8423681259155273,
          2.832305908203125,
          2.8725624084472656,
          2.835050106048584,
          2.856091260910034,
          2.816758394241333,
          2.865241527557373,
          2.8908677101135254,
          2.846942186355591,
          2.835050106048584,
          2.84328293800354,
          2.883545160293579,
          2.846942186355591,
          2.8542613983154297,
          2.6769981384277344,
          2.8881216049194336,
          2.8359646797180176,
          2.79390025138855,
          2.849686861038208,
          2.8817145824432373,
          2.8551764488220215,
          2.8387088775634766,
          2.846027374267578,
          2.856091260910034,
          2.8679866790771484,
          2.8012139797210693,
          2.849686861038208,
          2.846942186355591,
          2.829561948776245,
          2.8624963760375977,
          2.8451125621795654,
          2.8487720489501953,
          2.8551764488220215,
          2.8451125621795654,
          2.8679866790771484,
          2.8451125621795654,
          2.8643264770507812,
          2.871647357940674,
          2.849686861038208,
          2.8396236896514893,
          2.7911579608917236,
          2.8743927478790283,
          2.8734776973724365,
          2.8689019680023193,
          2.8487720489501953,
          2.8213307857513428,
          2.8332207202911377,
          2.866156578063965,
          2.885375738143921,
          2.857006311416626,
          2.8240745067596436,
          2.8341352939605713,
          2.8158438205718994,
          2.8670716285705566,
          2.8268182277679443,
          2.8597512245178223,
          2.885375738143921,
          2.8487720489501953,
          2.8259036540985107,
          2.813100576400757,
          2.8634114265441895,
          2.8313913345336914,
          2.849686861038208,
          2.8387088775634766,
          2.856091260910034,
          2.861581325531006,
          2.8487720489501953,
          2.8268182277679443,
          2.8542613983154297,
          2.849686861038208,
          2.8542613983154297,
          2.820416212081909,
          2.852431535720825,
          2.861581325531006,
          2.852431535720825,
          2.8579213619232178,
          2.7399871349334717,
          2.8579213619232178,
          2.8624963760375977,
          2.8624963760375977,
          2.8506016731262207,
          2.8588361740112305,
          2.818587303161621,
          2.8588361740112305,
          2.8670716285705566,
          2.8259036540985107,
          2.8506016731262207,
          2.8643264770507812,
          2.800299882888794,
          2.8158438205718994,
          2.8423681259155273,
          2.837794303894043,
          2.8487720489501953,
          2.849686861038208,
          2.837794303894043,
          2.8579213619232178,
          2.856091260910034,
          2.8176727294921875,
          2.8551764488220215,
          2.8487720489501953,
          2.818587303161621,
          2.8478569984436035,
          2.8478569984436035,
          2.837794303894043,
          2.886291027069092,
          2.8515167236328125,
          2.865241527557373,
          2.8441977500915527,
          2.8506016731262207,
          2.8359646797180176,
          2.84328293800354,
          2.837794303894043,
          2.816758394241333,
          2.8423681259155273,
          2.796642780303955,
          2.84328293800354,
          2.856091260910034,
          2.8341352939605713,
          2.8423681259155273,
          2.837794303894043,
          2.8240745067596436,
          2.8313913345336914,
          2.8798840045928955,
          2.837794303894043,
          2.835050106048584,
          2.8515167236328125,
          2.8789689540863037,
          2.8542613983154297,
          2.8341352939605713,
          2.8057854175567627,
          2.8451125621795654,
          2.861581325531006,
          2.8359646797180176,
          2.820416212081909,
          2.8341352939605713,
          2.8396236896514893,
          2.8158438205718994,
          2.804871082305908,
          2.860666275024414,
          2.846027374267578,
          2.8670716285705566,
          2.840538501739502,
          2.827732801437378,
          2.8670716285705566,
          2.8551764488220215,
          2.8634114265441895,
          2.861581325531006,
          2.8423681259155273,
          2.8341352939605713,
          2.840538501739502,
          2.84328293800354,
          2.8368794918060303,
          2.8158438205718994,
          2.835050106048584,
          2.837794303894043,
          2.877138376235962,
          2.8679866790771484,
          2.846942186355591,
          2.82315993309021,
          2.8451125621795654,
          2.8332207202911377,
          2.8423681259155273,
          2.8222453594207764,
          2.837794303894043,
          2.79390025138855,
          2.8387088775634766,
          2.8286473751068115,
          2.8634114265441895,
          2.8414533138275146,
          2.8679866790771484,
          2.871647357940674,
          2.8387088775634766,
          2.876223087310791,
          2.846027374267578,
          2.8542613983154297,
          2.84328293800354,
          2.865241527557373,
          2.8597512245178223,
          2.8423681259155273,
          2.8341352939605713,
          2.8579213619232178,
          2.877138376235962,
          2.861581325531006,
          2.8515167236328125,
          2.82315993309021,
          2.852431535720825,
          2.8643264770507812,
          2.846027374267578,
          2.8423681259155273,
          2.883545160293579,
          2.8268182277679443,
          2.8441977500915527,
          2.8634114265441895,
          2.835050106048584,
          2.8259036540985107,
          2.8359646797180176,
          2.846027374267578,
          2.852431535720825,
          2.8222453594207764,
          2.8414533138275146,
          2.832305908203125,
          2.866156578063965,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 5
         },
         "mode": "markers",
         "name": "w2mpro z-scored",
         "type": "scatter",
         "x": [
          0,
          0.00004262767834006809,
          0.00008521416020812467,
          0.0001278418640140444,
          0.0001491351140430197,
          0.00017042836407199502,
          0.0001917627960210666,
          0.00021305604605004191,
          0.00023434929607901722,
          0.00025564254610799253,
          0.00027697699260897934,
          0.0002982702280860394,
          0.0003195634635630995,
          0.00034085672814399004,
          0.0003621499636210501,
          0.00036219117464497685,
          0.000404777645599097,
          0.00044736414565704763,
          0.0004474053275771439,
          0.001427304930984974,
          0.0014486394356936216,
          0.05863862857222557,
          0.058681175112724304,
          0.05872371792793274,
          0.05876626446843147,
          0.05878756195306778,
          0.058808814734220505,
          0.05880885571241379,
          0.058830104768276215,
          0.05885139852762222,
          0.05887265130877495,
          0.058893945068120956,
          0.05891519784927368,
          0.05893649160861969,
          0.0589577853679657,
          0.058979034423828125,
          0.05900032818317413,
          0.05904287472367287,
          0.0590854212641716,
          0.11798493564128876,
          0.11806990951299667,
          0.11811237037181854,
          0.11813361942768097,
          0.11815487593412399,
          0.11817612498998642,
          0.11819738149642944,
          0.11821858584880829,
          0.11823984235525131,
          0.11826109141111374,
          0.11828234791755676,
          0.11830359697341919,
          0.11834605783224106,
          0.11838856339454651,
          0.11843102425336838,
          0.1747230738401413,
          0.17476549744606018,
          0.1748291403055191,
          0.17485038936138153,
          0.17487159371376038,
          0.17489281296730042,
          0.17491401731967926,
          0.1749352216720581,
          0.17495644092559814,
          0.17497768998146057,
          0.1749989092350006,
          0.17502011358737946,
          0.1750413179397583,
          0.17508374154567719,
          0.17512616515159607,
          0.17516863346099854,
          0.23575077950954437,
          0.23579315841197968,
          0.23579318821430206,
          0.23583558201789856,
          0.23587799072265625,
          0.2358991652727127,
          0.23592038452625275,
          0.2359415888786316,
          0.23596279323101044,
          0.2359839677810669,
          0.23600518703460693,
          0.23602639138698578,
          0.23604759573936462,
          0.23608998954296112,
          0.23611119389533997,
          0.23615357279777527,
          0.23615361750125885,
          0.23619599640369415,
          0.29078617691993713,
          0.29082855582237244,
          0.29087093472480774,
          0.2908921539783478,
          0.29091331362724304,
          0.2909345328807831,
          0.29095569252967834,
          0.2909769117832184,
          0.29099807143211365,
          0.2910192310810089,
          0.2910192906856537,
          0.29104045033454895,
          0.291061669588089,
          0.29108282923698425,
          0.29112520813941956,
          0.2911463975906372,
          0.2911887764930725,
          0.2912311553955078,
          0.2929687201976776,
          0.2929898798465729,
          0.3535657823085785,
          0.3535658121109009,
          0.3536081612110138,
          0.3536505401134491,
          0.353692889213562,
          0.35371407866477966,
          0.3537352681159973,
          0.3537564277648926,
          0.35377758741378784,
          0.3537776470184326,
          0.3537988066673279,
          0.35381999611854553,
          0.3538411557674408,
          0.35386237502098083,
          0.3538835346698761,
          0.3539259135723114,
          0.3539682626724243,
          0.3540106415748596,
          0.3547731935977936,
          0.35479435324668884,
          0.3548155426979065,
          0.3548579216003418,
          0.3549002707004547,
          0.35494264960289,
          0.4073735475540161,
          0.40838995575904846,
          0.40838998556137085,
          0.4084746539592743,
          0.40853822231292725,
          0.4085593819618225,
          0.4085805416107178,
          0.4086228907108307,
          0.40864405035972595,
          0.4086652398109436,
          0.40868639945983887,
          0.4087076187133789,
          0.40874993801116943,
          0.40879228711128235,
          0.4723586440086365,
          0.4724009931087494,
          0.47242215275764465,
          0.4724433422088623,
          0.47246450185775757,
          0.47248566150665283,
          0.4725068509578705,
          0.47252801060676575,
          0.472549170255661,
          0.47257035970687866,
          0.4725915193557739,
          0.4726126790046692,
          0.47263386845588684,
          0.47267618775367737,
          0.4727185368537903,
          0.4727608859539032,
          0.5249097347259521,
          0.5249520540237427,
          0.5249943733215332,
          0.5250366926193237,
          0.525057852268219,
          0.5250790119171143,
          0.5251213908195496,
          0.5251425504684448,
          0.5251636505126953,
          0.5251848101615906,
          0.5252060294151306,
          0.5252271890640259,
          0.5252483487129211,
          0.5253118276596069,
          0.5253541469573975,
          0.525396466255188,
          0.5901211500167847,
          0.5901634693145752,
          0.5901634693145752,
          0.5902057886123657,
          0.590226948261261,
          0.5902481079101562,
          0.5902692675590515,
          0.5902904272079468,
          0.590311586856842,
          0.5903327465057373,
          0.5903539061546326,
          0.5903751254081726,
          0.5903962254524231,
          0.5904173851013184,
          0.5904385447502136,
          0.5904809236526489,
          0.5905231833457947,
          0.6426958441734314,
          0.6426958441734314,
          0.6427804827690125,
          0.642822802066803,
          0.6428439021110535,
          0.6428439617156982,
          0.6428651213645935,
          0.6428862810134888,
          0.642907440662384,
          0.6429285407066345,
          0.6429497599601746,
          0.6429920792579651,
          0.6430131793022156,
          0.6430343985557556,
          0.6430978178977966,
          0.6431401371955872,
          0.6431824564933777,
          0.7078431844711304,
          0.7088164687156677,
          0.7088587880134583,
          0.7089011073112488,
          0.708922266960144,
          0.708943247795105,
          0.7089645862579346,
          0.7089856863021851,
          0.7090068459510803,
          0.7090280055999756,
          0.7090491652488708,
          0.7090703248977661,
          0.7090914845466614,
          0.7091126441955566,
          0.7091338038444519,
          0.7091761231422424,
          0.7092183828353882,
          0.7092607617378235,
          0.7605277299880981,
          0.7605700492858887,
          0.7605912089347839,
          0.7606123089790344,
          0.7606123685836792,
          0.7606546878814697,
          0.7606757879257202,
          0.7606968283653259,
          0.7607179284095764,
          0.760739266872406,
          0.7607815861701965,
          0.760802686214447,
          0.7608873248100281,
          0.7609296441078186,
          0.7614158987998962,
          0.7614582180976868,
          0.7615639567375183,
          0.7615851163864136,
          0.7616274356842041,
          0.7616485953330994,
          0.7616908550262451,
          0.7617120146751404,
          0.7617543339729309,
          0.7617754936218262,
          0.7618177533149719,
          0.7618178129196167,
          0.761902391910553,
          0.8266242146492004,
          0.826666533946991,
          0.8267087936401367,
          0.8267087936401367,
          0.826729953289032,
          0.8267510533332825,
          0.8267722725868225,
          0.826793372631073,
          0.8268143534660339,
          0.8268356919288635,
          0.826856791973114,
          0.8268568515777588,
          0.8268779516220093,
          0.8268991112709045,
          0.8269202709197998,
          0.8269413709640503,
          0.8269836902618408,
          0.8270260095596313,
          0.8270682692527771,
          0.8792397379875183,
          0.8792819976806641,
          0.8793665766716003,
          0.8793877363204956,
          0.8794299960136414,
          0.8794511556625366,
          0.8794934153556824,
          0.8795356750488281,
          0.8795568346977234,
          0.8795990943908691,
          0.8796413540840149,
          0.8796836733818054,
          0.9444440007209778,
          0.9444862604141235,
          0.9445496201515198,
          0.9445707201957703,
          0.9445918798446655,
          0.944612979888916,
          0.9446341395378113,
          0.9446552395820618,
          0.944676399230957,
          0.9446974992752075,
          0.9447186589241028,
          0.9447609186172485,
          0.9448031187057495,
          0.9448031783103943,
          0.9448453783988953,
          0.944887638092041,
          0.9468947052955627,
          0.9469158053398132,
          0.9970255494117737,
          0.9970677495002747,
          0.9971521496772766,
          0.9971732497215271,
          0.9972153902053833,
          0.9972786903381348,
          0.9972997903823853,
          0.9973208904266357,
          0.9973419904708862,
          0.9973630905151367,
          0.9973841905593872,
          0.9974263906478882,
          0.9974263906478882,
          0.9974685907363892,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
         ],
         "y": [
          0,
          0.00004262767834006809,
          0.00008521416020812467,
          0.0001278418640140444,
          0.0001491351140430197,
          0.00017042836407199502,
          0.0001917627960210666,
          0.00021305604605004191,
          0.00023434929607901722,
          0.00025564254610799253,
          0.00027697699260897934,
          0.0002982702280860394,
          0.0003195634635630995,
          0.00034085672814399004,
          0.0003621499636210501,
          0.00036219117464497685,
          0.000404777645599097,
          0.00044736414565704763,
          0.0004474053275771439,
          0.001427304930984974,
          0.0014486394356936216,
          0.05863862857222557,
          0.058681175112724304,
          0.05872371792793274,
          0.05876626446843147,
          0.05878756195306778,
          0.058808814734220505,
          0.05880885571241379,
          0.058830104768276215,
          0.05885139852762222,
          0.05887265130877495,
          0.058893945068120956,
          0.05891519784927368,
          0.05893649160861969,
          0.0589577853679657,
          0.058979034423828125,
          0.05900032818317413,
          0.05904287472367287,
          0.0590854212641716,
          0.11798493564128876,
          0.11806990951299667,
          0.11811237037181854,
          0.11813361942768097,
          0.11815487593412399,
          0.11817612498998642,
          0.11819738149642944,
          0.11821858584880829,
          0.11823984235525131,
          0.11826109141111374,
          0.11828234791755676,
          0.11830359697341919,
          0.11834605783224106,
          0.11838856339454651,
          0.11843102425336838,
          0.1747230738401413,
          0.17476549744606018,
          0.1748291403055191,
          0.17485038936138153,
          0.17487159371376038,
          0.17489281296730042,
          0.17491401731967926,
          0.1749352216720581,
          0.17495644092559814,
          0.17497768998146057,
          0.1749989092350006,
          0.17502011358737946,
          0.1750413179397583,
          0.17508374154567719,
          0.17512616515159607,
          0.17516863346099854,
          0.23575077950954437,
          0.23579315841197968,
          0.23579318821430206,
          0.23583558201789856,
          0.23587799072265625,
          0.2358991652727127,
          0.23592038452625275,
          0.2359415888786316,
          0.23596279323101044,
          0.2359839677810669,
          0.23600518703460693,
          0.23602639138698578,
          0.23604759573936462,
          0.23608998954296112,
          0.23611119389533997,
          0.23615357279777527,
          0.23615361750125885,
          0.23619599640369415,
          0.29078617691993713,
          0.29082855582237244,
          0.29087093472480774,
          0.2908921539783478,
          0.29091331362724304,
          0.2909345328807831,
          0.29095569252967834,
          0.2909769117832184,
          0.29099807143211365,
          0.2910192310810089,
          0.2910192906856537,
          0.29104045033454895,
          0.291061669588089,
          0.29108282923698425,
          0.29112520813941956,
          0.2911463975906372,
          0.2911887764930725,
          0.2912311553955078,
          0.2929687201976776,
          0.2929898798465729,
          0.3535657823085785,
          0.3535658121109009,
          0.3536081612110138,
          0.3536505401134491,
          0.353692889213562,
          0.35371407866477966,
          0.3537352681159973,
          0.3537564277648926,
          0.35377758741378784,
          0.3537776470184326,
          0.3537988066673279,
          0.35381999611854553,
          0.3538411557674408,
          0.35386237502098083,
          0.3538835346698761,
          0.3539259135723114,
          0.3539682626724243,
          0.3540106415748596,
          0.3547731935977936,
          0.35479435324668884,
          0.3548155426979065,
          0.3548579216003418,
          0.3549002707004547,
          0.35494264960289,
          0.4073735475540161,
          0.40838995575904846,
          0.40838998556137085,
          0.4084746539592743,
          0.40853822231292725,
          0.4085593819618225,
          0.4085805416107178,
          0.4086228907108307,
          0.40864405035972595,
          0.4086652398109436,
          0.40868639945983887,
          0.4087076187133789,
          0.40874993801116943,
          0.40879228711128235,
          0.4723586440086365,
          0.4724009931087494,
          0.47242215275764465,
          0.4724433422088623,
          0.47246450185775757,
          0.47248566150665283,
          0.4725068509578705,
          0.47252801060676575,
          0.472549170255661,
          0.47257035970687866,
          0.4725915193557739,
          0.4726126790046692,
          0.47263386845588684,
          0.47267618775367737,
          0.4727185368537903,
          0.4727608859539032,
          0.5249097347259521,
          0.5249520540237427,
          0.5249943733215332,
          0.5250366926193237,
          0.525057852268219,
          0.5250790119171143,
          0.5251213908195496,
          0.5251425504684448,
          0.5251636505126953,
          0.5251848101615906,
          0.5252060294151306,
          0.5252271890640259,
          0.5252483487129211,
          0.5253118276596069,
          0.5253541469573975,
          0.525396466255188,
          0.5901211500167847,
          0.5901634693145752,
          0.5901634693145752,
          0.5902057886123657,
          0.590226948261261,
          0.5902481079101562,
          0.5902692675590515,
          0.5902904272079468,
          0.590311586856842,
          0.5903327465057373,
          0.5903539061546326,
          0.5903751254081726,
          0.5903962254524231,
          0.5904173851013184,
          0.5904385447502136,
          0.5904809236526489,
          0.5905231833457947,
          0.6426958441734314,
          0.6426958441734314,
          0.6427804827690125,
          0.642822802066803,
          0.6428439021110535,
          0.6428439617156982,
          0.6428651213645935,
          0.6428862810134888,
          0.642907440662384,
          0.6429285407066345,
          0.6429497599601746,
          0.6429920792579651,
          0.6430131793022156,
          0.6430343985557556,
          0.6430978178977966,
          0.6431401371955872,
          0.6431824564933777,
          0.7078431844711304,
          0.7088164687156677,
          0.7088587880134583,
          0.7089011073112488,
          0.708922266960144,
          0.708943247795105,
          0.7089645862579346,
          0.7089856863021851,
          0.7090068459510803,
          0.7090280055999756,
          0.7090491652488708,
          0.7090703248977661,
          0.7090914845466614,
          0.7091126441955566,
          0.7091338038444519,
          0.7091761231422424,
          0.7092183828353882,
          0.7092607617378235,
          0.7605277299880981,
          0.7605700492858887,
          0.7605912089347839,
          0.7606123089790344,
          0.7606123685836792,
          0.7606546878814697,
          0.7606757879257202,
          0.7606968283653259,
          0.7607179284095764,
          0.760739266872406,
          0.7607815861701965,
          0.760802686214447,
          0.7608873248100281,
          0.7609296441078186,
          0.7614158987998962,
          0.7614582180976868,
          0.7615639567375183,
          0.7615851163864136,
          0.7616274356842041,
          0.7616485953330994,
          0.7616908550262451,
          0.7617120146751404,
          0.7617543339729309,
          0.7617754936218262,
          0.7618177533149719,
          0.7618178129196167,
          0.761902391910553,
          0.8266242146492004,
          0.826666533946991,
          0.8267087936401367,
          0.8267087936401367,
          0.826729953289032,
          0.8267510533332825,
          0.8267722725868225,
          0.826793372631073,
          0.8268143534660339,
          0.8268356919288635,
          0.826856791973114,
          0.8268568515777588,
          0.8268779516220093,
          0.8268991112709045,
          0.8269202709197998,
          0.8269413709640503,
          0.8269836902618408,
          0.8270260095596313,
          0.8270682692527771,
          0.8792397379875183,
          0.8792819976806641,
          0.8793665766716003,
          0.8793877363204956,
          0.8794299960136414,
          0.8794511556625366,
          0.8794934153556824,
          0.8795356750488281,
          0.8795568346977234,
          0.8795990943908691,
          0.8796413540840149,
          0.8796836733818054,
          0.9444440007209778,
          0.9444862604141235,
          0.9445496201515198,
          0.9445707201957703,
          0.9445918798446655,
          0.944612979888916,
          0.9446341395378113,
          0.9446552395820618,
          0.944676399230957,
          0.9446974992752075,
          0.9447186589241028,
          0.9447609186172485,
          0.9448031187057495,
          0.9448031783103943,
          0.9448453783988953,
          0.944887638092041,
          0.9468947052955627,
          0.9469158053398132,
          0.9970255494117737,
          0.9970677495002747,
          0.9971521496772766,
          0.9971732497215271,
          0.9972153902053833,
          0.9972786903381348,
          0.9972997903823853,
          0.9973208904266357,
          0.9973419904708862,
          0.9973630905151367,
          0.9973841905593872,
          0.9974263906478882,
          0.9974263906478882,
          0.9974685907363892,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
         ]
        }
       ],
       "layout": {
        "height": 520,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 800
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "validaccessor = list(valid)[0]\n",
    "idx = 8\n",
    "ex = (validaccessor[0][idx], validaccessor[1][idx])\n",
    "print(ex[1])\n",
    "plot_from_tensor(ex[0])\n",
    "# print(ex[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "0D or 1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m optim1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(dft\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0009\u001b[39m)\n\u001b[1;32m      7\u001b[0m optim2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(nudft\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.7\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0012\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mcompete\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnudft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnudft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/WISE/./lib/general_trainer.py:191\u001b[0m, in \u001b[0;36mcompete\u001b[0;34m(trainers, epochs, trainloader, validloader, log)\u001b[0m\n\u001b[1;32m    187\u001b[0m out \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[1;32m    189\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 191\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m epoch_loss\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m    194\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/torch/nn/modules/loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/torch/nn/functional.py:3015\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2949\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"This criterion computes the cross entropy loss between input logits and target.\u001b[39;00m\n\u001b[1;32m   2950\u001b[0m \n\u001b[1;32m   2951\u001b[0m \u001b[38;5;124;03mSee :class:`~torch.nn.CrossEntropyLoss` for details.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3012\u001b[0m \u001b[38;5;124;03m    >>> loss.backward()\u001b[39;00m\n\u001b[1;32m   3013\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3014\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, target, weight):\n\u001b[0;32m-> 3015\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3016\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_entropy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3017\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3018\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3020\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3021\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize_average\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize_average\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3022\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3024\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3025\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3026\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3028\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/torch/overrides.py:1534\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_torch_function_mode_enabled():\n\u001b[1;32m   1531\u001b[0m     \u001b[38;5;66;03m# if we're here, the mode must be set to a TorchFunctionStackMode\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m     \u001b[38;5;66;03m# this unsets it and calls directly into TorchFunctionStackMode's torch function\u001b[39;00m\n\u001b[1;32m   1533\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _pop_mode_temporarily() \u001b[38;5;28;01mas\u001b[39;00m mode:\n\u001b[0;32m-> 1534\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mmode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1535\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1536\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/torch/utils/_device.py:62\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/torch/nn/functional.py:3029\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3028\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3029\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: 0D or 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "samples = 256\n",
    "lr = 0.007\n",
    "dft = FourierModelTest(samples,2)\n",
    "nudft = FourierModelTestNU(samples,2)\n",
    "\n",
    "optim1 = torch.optim.Adam(dft.parameters(), lr=lr, weight_decay=0.0009)\n",
    "optim2 = torch.optim.Adam(nudft.parameters(), lr=lr*0.7, weight_decay=0.0012)\n",
    "\n",
    "compete([(\"dft\", dft, optim1), (\"nudft\", nudft, optim2)], 300, train, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "qPbsgAA7OIXE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matteo/.pyenv/versions/3.11.2/lib/python3.11/site-packages/torch/autograd/profiler.py:179: UserWarning:\n",
      "\n",
      "CUDA is not available, disabling CUDA profiling\n",
      "\n",
      "STAGE:2024-01-06 12:29:52 82338:5938829 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2024-01-06 12:30:05 82338:5938829 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2024-01-06 12:30:05 82338:5938829 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                     dd         0.78%     103.484ms       100.00%       13.214s       13.214s             1  \n",
      "                                            aten::empty         0.00%      73.000us         0.00%      73.000us       3.476us            21  \n",
      "                                          aten::random_         0.00%      10.000us         0.00%      10.000us       5.000us             2  \n",
      "                                             aten::item         0.00%     157.000us         0.00%     158.000us      79.000us             2  \n",
      "                              aten::_local_scalar_dense         0.00%       1.000us         0.00%       1.000us       0.500us             2  \n",
      "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...         0.01%     995.000us         0.03%       4.185ms       4.185ms             1  \n",
      "                                         aten::randperm         0.01%     940.000us         0.01%       1.519ms     253.167us             6  \n",
      "                                    aten::scalar_tensor         0.00%       3.000us         0.00%       3.000us       1.000us             3  \n",
      "                                          aten::resize_         0.00%       2.000us         0.00%       2.000us       0.250us             8  \n",
      "                                     aten::resolve_conj         0.00%       1.000us         0.00%       1.000us       0.000us          4381  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 13.214s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = AnomalyDetector().to(device)\n",
    "\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "    with record_function(\"dd\"):\n",
    "        ex = next(iter(train))\n",
    "        out = model(ex[0])\n",
    "        # loss = loss_fn(out, ex[1])\n",
    "        # loss.backward()\n",
    "        # for name, param in model.cpu().named_parameters():\n",
    "        #   print(name, param.grad)\n",
    "        # plot_grad_flow(model.cpu().named_parameters())\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPn/w4j+IUa3ZgM7or7h7ji",
   "gpuType": "T4",
   "mount_file_id": "18k-3VG5eHIKWuvn4cbLSEYkNPYsG3W-J",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02705c67d19b4eb188b228046fbf1e99": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26f8b4836e9d4aa3ab3fe425455cb365": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3df46f544a194a80908e44bf1d394491": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4bcf7e6f9cd2451687e1ba12c74240e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5af5e5934a9c441784a1791a818e3e76": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c2d716c0c134147aa3ca644a3983928": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7a4d438c1bef4707babe8b0293c437ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3df46f544a194a80908e44bf1d394491",
      "placeholder": "",
      "style": "IPY_MODEL_5c2d716c0c134147aa3ca644a3983928",
      "value": " 0/720 [00:00&lt;?, ?it/s]"
     }
    },
    "8d345de5fbd84261a1c8588337db694d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9137e576ff0948b6a5bbef5a146e05da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e06b6fd9a99b4bc283bc942d7517086b",
       "IPY_MODEL_f67d8e102ab84d37a7ed583406539773",
       "IPY_MODEL_7a4d438c1bef4707babe8b0293c437ae"
      ],
      "layout": "IPY_MODEL_02705c67d19b4eb188b228046fbf1e99"
     }
    },
    "e06b6fd9a99b4bc283bc942d7517086b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4bcf7e6f9cd2451687e1ba12c74240e5",
      "placeholder": "",
      "style": "IPY_MODEL_8d345de5fbd84261a1c8588337db694d",
      "value": "Training Progress:   0%"
     }
    },
    "f67d8e102ab84d37a7ed583406539773": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5af5e5934a9c441784a1791a818e3e76",
      "max": 720,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_26f8b4836e9d4aa3ab3fe425455cb365",
      "value": 0
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
