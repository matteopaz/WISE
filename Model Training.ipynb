{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epycmNPr0I3d"
   },
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Dwn1PtIp4058"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matteo/.pyenv/versions/3.11.2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from IPython.display import display, clear_output\n",
    "from tqdm.auto import tqdm\n",
    "import plotly.graph_objs as go\n",
    "from astropy.io import ascii\n",
    "import random\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from sklearn.cluster import OPTICS, DBSCAN\n",
    "import torch.nn.functional as F\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "ROOT = os.path.join(\"./\")\n",
    "sys.path.append(ROOT + \"lib\")\n",
    "\n",
    "import helpers\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7lmg0Noc1nNE"
   },
   "source": [
    "# Flux Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2917,
     "status": "ok",
     "timestamp": 1698123021083,
     "user": {
      "displayName": "Matteo",
      "userId": "07662895649750931658"
     },
     "user_tz": 420
    },
    "id": "0o5bi2-e_n2z",
    "outputId": "1792997b-1077-4089-b8ae-b1b818428b61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<__main__.FluxSet at 0x28a874150>, <__main__.FluxSet at 0x28aa1b450>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FluxSet(Dataset):\n",
    "  def __init__(self, classes, augmentation=None, choose=3, augmentation_frac=3, equalize=False):\n",
    "\n",
    "    self.choose = choose\n",
    "    self.augmentation_frac = augmentation_frac\n",
    "\n",
    "    self.buckets = {\"null\": [], \"nova\": [], \"pulsating_var\": [], \"transit\": []}\n",
    "    for kind in classes:\n",
    "      flux_dicts = classes[kind]\n",
    "      for flux in flux_dicts: # each flux dict\n",
    "\n",
    "\n",
    "        timeseries_array = self.to_np(flux)\n",
    "\n",
    "        self.buckets[kind].append(torch.tensor(timeseries_array))\n",
    "\n",
    "    self.all = []\n",
    "\n",
    "    if augmentation:\n",
    "      for kind in self.buckets:\n",
    "        new = []\n",
    "        new += self.buckets[kind]\n",
    "        for ex in self.buckets[kind]:\n",
    "          for _ in range(self.augmentation_frac):\n",
    "            new += self.apply_pipeline([ex], random.sample(augmentation, choose))\n",
    "\n",
    "        self.buckets[kind] = new\n",
    "\n",
    "      # Equalization\n",
    "      if equalize:\n",
    "        lens = [len(self.buckets[b]) for b in self.buckets]\n",
    "        makeup = [max(lens) - v for v in lens]\n",
    "\n",
    "        for i, count in enumerate(makeup):\n",
    "          key = list(self.buckets.keys())[i]\n",
    "          for ex in self.buckets[key]:\n",
    "            if count <= 0:\n",
    "              break\n",
    "            self.buckets[key] += self.apply_pipeline([ex], random.sample(augmentation, choose))\n",
    "            count -= 1\n",
    "        # print(lens, [len(self.buckets[b]) for b in self.buckets])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for kind in self.buckets: # Data, Label pairing\n",
    "      for i, ex in enumerate(self.buckets[kind]):\n",
    "\n",
    "        label = torch.zeros(4)\n",
    "        label[list(self.buckets.keys()).index(kind)] = 1\n",
    "\n",
    "        self.all.append((ex, label))\n",
    "        self.buckets[kind][i] = ((ex, label))\n",
    "\n",
    "  def apply_pipeline(self, examples, pipeline):\n",
    "    p = copy(pipeline)\n",
    "\n",
    "    if len(p) == 0:\n",
    "      return examples\n",
    "\n",
    "    new = []\n",
    "    fn, times = p.pop(0)\n",
    "    for ex in examples:\n",
    "      for _ in range(times):\n",
    "        new.append(fn(ex))\n",
    "      del ex\n",
    "\n",
    "    return self.apply_pipeline(new, p)\n",
    "\n",
    "  def to_np(self, flux): # IMPORTANT! Defines order of data\n",
    "      # Len(pts) x 5 matrix\n",
    "      w1 = flux[\"norm\"][\"w1\"]\n",
    "      w1sig = flux[\"norm\"][\"w1sig\"]\n",
    "      w2 = flux[\"norm\"][\"w2\"]\n",
    "      w2sig = flux[\"norm\"][\"w2sig\"]\n",
    "      dt = flux[\"norm\"][\"dt\"]\n",
    "      day = flux[\"norm\"][\"day\"]\n",
    "\n",
    "      # Len(pts) x 5 matrix\n",
    "      # IMPORTANT! Defines order of data\n",
    "      return np.stack((w1, w1sig, w2, w2sig, dt, day), axis=0).T\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    # Commented out is random sampling\n",
    "    # key = random.choice(list(self.buckets.keys()))\n",
    "    # item = random.choice(self.buckets[key])\n",
    "    # return item\n",
    "    return self.all[idx]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.all)\n",
    "\n",
    "\n",
    "with open(ROOT + \"processed_datasets/data_train.pt\", \"rb\") as f:\n",
    "  data_train = torch.load(f, map_location=device)\n",
    "with open(ROOT + \"processed_datasets/data_valid.pt\", \"rb\") as f:\n",
    "  data_valid = torch.load(f, map_location=device)\n",
    "\n",
    "data_train, data_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ng-WIENymiCN"
   },
   "source": [
    "We work with convolutions as single results without concatenations here. Thus, at some position $i$ in the data, the convolution with some kernel matrix\n",
    "WRONG\n",
    "$$\\begin{align}\n",
    "K = \\begin{bmatrix}\n",
    "\\rule[0.5ex]{2.5em}{0.4pt} \\text{w1} \\rule[0.5ex]{2.5em}{0.4pt}\\\\\n",
    "\\rule[0.5ex]{2.5em}{0.4pt} \\text{w1}\\sigma \\rule[0.5ex]{2.5em}{0.4pt}\\\\\n",
    "\\rule[0.5ex]{2.5em}{0.4pt} \\text{w2} \\rule[0.5ex]{2.5em}{0.4pt}\\\\\n",
    "\\rule[0.5ex]{2.5em}{0.4pt} \\text{w2}\\sigma \\rule[0.5ex]{2.5em}{0.4pt}\\\\\n",
    "\\rule[0.5ex]{2.5em}{0.4pt} \\text{w1} \\rule[0.5ex]{2.5em}{0.4pt}\\\\\n",
    "\\rule[0.5ex]{2.5em}{0.4pt} \\delta t \\rule[0.5ex]{2.5em}{0.4pt}\\\\\n",
    "\\end{bmatrix} \\in \\mathbb{R}^{6 \\times T}\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PU4Zzbo31tIp"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "gd-gDX5vfwTG"
   },
   "outputs": [],
   "source": [
    "class FluxAnomalyPredictionLSTMDEPRECATED(nn.Module):\n",
    "  def __init__(self, stride, dropout, bn=False, features=6, residual=0, out=4):\n",
    "    super().__init__()\n",
    "\n",
    "    self.stride = stride\n",
    "    self.features = features\n",
    "    self.residual = residual\n",
    "    self.lstm_hidden_state_features = 14 # Needed for batchnorm 3, so defined here\n",
    "\n",
    "    # Need Dropouts, Activation fns\n",
    "    self.he = lambda x: nn.init.kaiming_normal_(x, nonlinearity='relu')\n",
    "    self.av = nn.ReLU()\n",
    "    self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    self.batchnorm1 = lambda x: x\n",
    "    self.batchnorm2 = lambda x: x\n",
    "    self.batchnorm3 = lambda x: x\n",
    "\n",
    "    if bn:\n",
    "      self.batchnorm1 = nn.BatchNorm1d(features)\n",
    "      self.batchnorm2 = nn.BatchNorm1d(features)\n",
    "      self.batchnorm3 = nn.BatchNorm1d(self.lstm_hidden_state_features)\n",
    "\n",
    "      self.bn1 = lambda x: torch.transpose(self.batchnorm1(torch.transpose(x,1,2)),1,2)\n",
    "      self.bn2 = lambda x: torch.transpose(self.batchnorm2(torch.transpose(x,1,2)),1,2)\n",
    "      self.bn3 = lambda x: self.batchnorm3(x)\n",
    "    else:\n",
    "      self.bn1 = lambda x: x\n",
    "      self.bn2 = lambda x: x\n",
    "      self.bn3 = lambda x: x\n",
    "\n",
    "\n",
    "    # Step 1\n",
    "\n",
    "    # 5 x 64 X 64 x 5 -diag-> R^5 Vector\n",
    "    self.conv_kernels_64d = nn.ParameterList([self.he(torch.randn(features, 64)) for i in range(8)])\n",
    "    self.conv_biases_64d = nn.ParameterList([torch.randn(features) for i in range(8)])\n",
    "\n",
    "    self.conv_kernel_16d = nn.Parameter(self.he(torch.randn(features, 16)))\n",
    "    self.conv_bias_16d = nn.Parameter(torch.randn(features))\n",
    "\n",
    "    self.conv_kernel_8d = nn.Parameter(self.he(torch.randn(features,8)))\n",
    "    self.conv_bias_8d = nn.Parameter(torch.randn(features))\n",
    "\n",
    "    self.four_max_pool = nn.MaxPool1d(4)\n",
    "\n",
    "    # Step 1.5\n",
    "    # self.certainty_fc_1 = nn.Parameter(torch.zeros(2,3))\n",
    "    # self.certainty_fc_2 = nn.Parameter(torch.zeros(3,1))\n",
    "\n",
    "    # Step 2\n",
    "    self.widechannel_conv_kernel = nn.Parameter(self.he(torch.randn(features, 3)))\n",
    "    self.widechannel_conv_bias = nn.Parameter(torch.randn(features))\n",
    "\n",
    "    self.midchannel_conv_kernel = nn.Parameter(self.he(torch.randn(features, 3)))\n",
    "    self.midchannel_conv_bias = nn.Parameter(torch.randn(features))\n",
    "\n",
    "    self.narrowchannel_conv_kernel = nn.Parameter(self.he(torch.randn(features, 3)))\n",
    "    self.narrowchannel_conv_bias = nn.Parameter(torch.randn(features))\n",
    "\n",
    "\n",
    "    # Step 3\n",
    "    self.pair_max_pool = nn.MaxPool1d(2)\n",
    "    # Then concat all vectors into v \\in R^24\n",
    "\n",
    "    # Step 3.5 Residual connection\n",
    "    self.__avgpool__ = nn.AvgPool1d(4, stride=4)\n",
    "\n",
    "    # Step 4\n",
    "    self.hidden_fc_1 = nn.Linear(3*4*features,3*2*features)\n",
    "    self.hidden_fc_2 = nn.Linear(3*2*features,2*features)\n",
    "\n",
    "    # Step 5\n",
    "    # LSTM\n",
    "\n",
    "    self.lstm_in_features = 2*self.features\n",
    "\n",
    "    self.lstm = nn.LSTM(self.lstm_in_features, self.lstm_hidden_state_features)\n",
    "\n",
    "    # Step 6\n",
    "    # Softmax\n",
    "\n",
    "    self.to_out_1 = nn.Linear(self.lstm_hidden_state_features, 7)\n",
    "    self.to_out_2 = nn.Linear(7, out, bias=False)\n",
    "\n",
    "    self.prob = nn.Softmax(dim=1)\n",
    "\n",
    "    for param in self.parameters():\n",
    "      if len(param.shape) >= 2:\n",
    "        param = self.he(param)\n",
    "\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    # x = Batches X Time X Channels\n",
    "\n",
    "    N = x.shape[0] # Batches\n",
    "    T = x.shape[1] # Time\n",
    "\n",
    "\n",
    "    # Step 1\n",
    "    # Cursory vision convolution\n",
    "    pad_amt = 40\n",
    "\n",
    "    pad = torch.zeros(N, pad_amt, self.features).to(device)\n",
    "\n",
    "    padded_x = torch.cat((pad, torch.cat((x, pad), dim=1)), dim=1) # catting in time\n",
    "\n",
    "    # padded_x.requires_grad = True\n",
    "\n",
    "    window_centers = [] # AKA 64d Convolve Centers\n",
    "\n",
    "    n=0 # strides\n",
    "    while(True):\n",
    "      next_center = pad_amt + 1 + n * self.stride\n",
    "      if next_center > (pad_amt + T + 1): # If our center isnt in real data\n",
    "        break;\n",
    "      else:\n",
    "        window_centers.append(next_center)\n",
    "        n += 1\n",
    "\n",
    "    window_starts = [self.start_and_end_from_center((64 - 1)/2, i)[0] for i in window_centers]\n",
    "    window_ends = [self.start_and_end_from_center((64 - 1)/2, i)[1] for i in window_centers]\n",
    "\n",
    "    midchannel_centers = []\n",
    "    narrowchannel_centers = []\n",
    "    for start in window_starts:\n",
    "      for n in range(8): # 8 strides of 8 -> 64 units\n",
    "        midchannel_centers.append(start + n * 8)\n",
    "\n",
    "      for n in range(32): # 32 strides of 2 -> 64 units\n",
    "        narrowchannel_centers.append(start + n * 2)\n",
    "\n",
    "\n",
    "    wide_convs = []\n",
    "    mid_convs = []\n",
    "    narrow_convs = []\n",
    "\n",
    "    for i in window_centers:\n",
    "      for j in range(8): # Hard coded 8 here\n",
    "        K = self.conv_kernels_64d[j]\n",
    "        B = self.conv_biases_64d[j].repeat(N,1) # Repeat here\n",
    "        conv = self.convolve(K, padded_x, i) # Features x T\n",
    "        conv += B\n",
    "        wide_convs.append(conv)\n",
    "\n",
    "    for i in midchannel_centers:\n",
    "      conv = self.convolve(self.conv_kernel_16d, padded_x, i)\n",
    "      conv += self.conv_bias_16d.repeat(N,1)\n",
    "      mid_convs.append(conv)\n",
    "\n",
    "    for i in narrowchannel_centers:\n",
    "      conv = self.convolve(self.conv_kernel_8d, padded_x, i)\n",
    "      conv += self.conv_bias_8d.repeat(N,1)\n",
    "      narrow_convs.append(conv)\n",
    "\n",
    "    wide_convs = torch.stack(wide_convs, dim=1).to(device)\n",
    "    mid_convs = torch.stack(mid_convs, dim=1).to(device)\n",
    "    narrow_convs = torch.stack(narrow_convs, dim=1).to(device)\n",
    "\n",
    "    narrow_convs = self.four_max_pool(torch.transpose(narrow_convs, 1,2)) # Inp = N x C x L now\n",
    "    narrow_convs = torch.transpose(narrow_convs,1,2) # Back to N x L x C\n",
    "\n",
    "\n",
    "    wide_convs = self.bn1(self.av(wide_convs))\n",
    "    mid_convs = self.bn1(self.av(mid_convs))\n",
    "    narrow_convs = self.bn1(self.av(narrow_convs))\n",
    "\n",
    "    residual_vectors = self.get_residual_vectors(narrow_convs, mid_convs, wide_convs)\n",
    "\n",
    "\n",
    "    wide_convs = 5 * self.drop(wide_convs)\n",
    "    mid_convs = self.drop(mid_convs)\n",
    "    narrow_convs = self.drop(narrow_convs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # convs = N x L x C\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #####\n",
    "    # STEP 1.5\n",
    "    # Compress our 5vectors to 3 vectors, combining mag and uncertainty indices\n",
    "\n",
    "    # if not (wide_convs.shape[1] == mid_convs.shape[1] == narrow_convs.shape[1]):\n",
    "    #   raise Exception(\"Step 1 output mismatch\")\n",
    "\n",
    "\n",
    "    # compacting_fc = lambda x: self.gelu(torch.matmul(self.gelu(torch.matmul(x, self.certainty_fc_1)), self.certainty_fc_2))\n",
    "\n",
    "    # wide_col_0 = compacting_fc(wide_convs[:, 0:2])\n",
    "    # wide_col_1 = compacting_fc(wide_convs[:, 2:4])\n",
    "\n",
    "    # mid_col_0 = compacting_fc(mid_convs[:, 0:2])\n",
    "    # mid_col_1 = compacting_fc(mid_convs[:, 2:4])\n",
    "\n",
    "    # narrow_col_0 = compacting_fc(mid_convs[:, 0:2])\n",
    "    # narrow_col_1 = compacting_fc(mid_convs[:, 2:4])\n",
    "\n",
    "    # wide_convs = torch.stack((wide_col_0, wide_col_1, wide_convs[:, -1].unsqueeze(1)), dim=1)\n",
    "    # mid_convs = torch.stack((mid_col_0, mid_col_1, mid_convs[:, -1].unsqueeze(1)), dim=1)\n",
    "    # narrow_convs = torch.stack((narrow_col_0, narrow_col_1, narrow_convs[:, -1].unsqueeze(1)), dim=1)\n",
    "\n",
    "    # wide_convs = wide_convs.squeeze()\n",
    "    # mid_convs = mid_convs.squeeze()\n",
    "    # narrow_convs = narrow_convs.squeeze()\n",
    "\n",
    "\n",
    "    #####\n",
    "    # STEP 2\n",
    "    # Second Convolution\n",
    "\n",
    "    pad_amt = 10\n",
    "    stride = 1\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for x in (wide_convs, mid_convs, narrow_convs):\n",
    "      T = x.shape[1]\n",
    "      ker = None\n",
    "      bias = None\n",
    "      if len(results) == 0:\n",
    "        ker = self.widechannel_conv_kernel\n",
    "        bias = self.widechannel_conv_bias.repeat(N, 1)\n",
    "\n",
    "      elif len(results) == 1:\n",
    "        ker = self.midchannel_conv_kernel\n",
    "        bias = self.midchannel_conv_bias.repeat(N, 1)\n",
    "\n",
    "      elif len(results) == 2:\n",
    "        ker = self.narrowchannel_conv_kernel\n",
    "        bias = self.narrowchannel_conv_bias.repeat(N, 1)\n",
    "\n",
    "\n",
    "      pad = torch.zeros(N, pad_amt, self.features).to(device)\n",
    "      padded_x = torch.cat((pad, torch.cat((x, pad), dim=1)), dim=1)\n",
    "\n",
    "\n",
    "      result = []\n",
    "\n",
    "      next = pad_amt\n",
    "      while next <= (pad_amt + T - 1):\n",
    "        v = bias + self.convolve(ker, padded_x, next)\n",
    "        result.append(v)\n",
    "        next += stride\n",
    "\n",
    "\n",
    "      results.append(torch.stack(result, dim=1))\n",
    "\n",
    "\n",
    "    wide_convs = self.bn2(self.av(results[0]))\n",
    "    mid_convs = self.bn2(self.av(results[1]))\n",
    "    narrow_convs = self.bn2(self.av(results[2]))\n",
    "\n",
    "    wide_convs = self.drop(wide_convs)\n",
    "    mid_convs = self.drop(mid_convs)\n",
    "    narrow_convs = self.drop(narrow_convs)\n",
    "\n",
    "\n",
    "\n",
    "    ####\n",
    "    # Step 2.5\n",
    "    # Max Pooling Pairs\n",
    "    wide_convs = self.pair_max_pool(torch.transpose(wide_convs, 1,2)) # to N x C x L\n",
    "    mid_convs = self.pair_max_pool(torch.transpose(mid_convs, 1,2))\n",
    "    narrow_convs = self.pair_max_pool(torch.transpose(narrow_convs, 1,2))\n",
    "\n",
    "    wide_convs = torch.transpose(wide_convs, 1,2) # to N x L x C\n",
    "    mid_convs = torch.transpose(mid_convs, 1,2)\n",
    "    narrow_convs = torch.transpose(narrow_convs, 1,2)\n",
    "\n",
    "\n",
    "    ####\n",
    "    # Step 3\n",
    "\n",
    "    # Now each original window reigon is each corresponding 2 rows from all 3 tensors\n",
    "    # 2 rows evenly divides all possible resulting lengths\n",
    "\n",
    "    if not (wide_convs.shape[1] == mid_convs.shape[1] == narrow_convs.shape[1]):\n",
    "      raise Exception(\"Step 3 output mismatch\")\n",
    "\n",
    "\n",
    "    hidden = []\n",
    "    L = wide_convs.shape[1]\n",
    "\n",
    "    for n in range(L // 4): # Now each sliding window corresponds to 2 rows\n",
    "      wide = wide_convs[:, 4*n:4*n + 4].reshape(N, 4*self.features)\n",
    "      mid = mid_convs[:, 4*n:4*n + 4].reshape(N, 4*self.features)\n",
    "      narrow = narrow_convs[:, 4*n:4*n + 4].reshape(N, 4*self.features)\n",
    "\n",
    "      flat = torch.cat((wide, mid, narrow), dim=1).to(device)\n",
    "      if flat.shape[0] != N or flat.shape[1] != 3*4*self.features:\n",
    "        raise Exception(\"Flat shape err\")\n",
    "\n",
    "      layer_1 = self.hidden_fc_1(flat)\n",
    "      layer_1 = self.av(layer_1)\n",
    "\n",
    "      # RESIDUAL CONNECTION !\n",
    "      res = torch.autograd.Variable(self.residual * residual_vectors[n])\n",
    "      layer_1 = (1-self.residual) * layer_1\n",
    "      layer_1 = layer_1 + res\n",
    "\n",
    "\n",
    "      layer_2 = self.hidden_fc_2(layer_1)\n",
    "      layer_2 = self.av(layer_2)\n",
    "\n",
    "      hidden.append(layer_2)\n",
    "\n",
    "\n",
    "    hidden = torch.stack(hidden, dim=0) # Results in L x N x Hidden\n",
    "\n",
    "    hidden = self.drop(hidden)\n",
    "\n",
    "\n",
    "    ####\n",
    "    # Step 6: LSTM\n",
    "\n",
    "    _, (final_hidden_state, c_n) = self.lstm(hidden)\n",
    "\n",
    "    final_hidden_state = self.av(final_hidden_state.squeeze())\n",
    "    final_hidden_state = self.bn3(final_hidden_state)\n",
    "\n",
    "    final_hidden_state = self.drop(final_hidden_state)\n",
    "\n",
    "\n",
    "    final_layer = self.to_out_1(final_hidden_state)\n",
    "    final_layer = self.av(final_layer)\n",
    "\n",
    "    final_layer = self.drop(final_layer)\n",
    "\n",
    "    final_layer = self.to_out_2(final_layer)\n",
    "\n",
    "    classes = self.prob(final_layer)\n",
    "\n",
    "\n",
    "    return F.log_softmax(final_layer, dim=1)\n",
    "\n",
    "\n",
    "  def start_and_end_from_center(self, width, i):\n",
    "    start = i - np.ceil(width)\n",
    "    end = i + np.floor(width) + 1\n",
    "    return (int(start), int(end))\n",
    "\n",
    "\n",
    "\n",
    "  def convolve(self, Kernel, Data, i):\n",
    "\n",
    "    # i is center index so we take equal on either side\n",
    "    T = Kernel.shape[1]\n",
    "    each_side = (T - 1) / 2\n",
    "\n",
    "    # Moves it backwards 1 if kernel is even\n",
    "    start, end = self.start_and_end_from_center(each_side, i)\n",
    "\n",
    "    adj_data = Data[:, start:end, :]\n",
    "\n",
    "    # So now K is 5 x L and adj_data is N x L X 5\n",
    "\n",
    "\n",
    "    N = adj_data.shape[0]\n",
    "\n",
    "    m = torch.bmm(Kernel.repeat(N,1,1), adj_data) # bij, bjk -> bik Slightly faster than einsum\n",
    "\n",
    "    # m = torch.einsum(\"ij, bjk -> bik\", Kernel, adj_data) #identical batch matmul\n",
    "\n",
    "    diag = torch.einsum(\"bii->bi\", m)\n",
    "    # diags = []\n",
    "    # for res in m:\n",
    "    #   diags.append(torch.diag(res))\n",
    "\n",
    "\n",
    "    return diag\n",
    "\n",
    "  def get_residual_vectors(self, narrow, mid, wide):\n",
    "    # Should be N x 8m x Features\n",
    "    # print(narrow.shape, mid.shape, wide.shape)\n",
    "    N = wide.shape[0]\n",
    "    L = wide.shape[1]\n",
    "\n",
    "    apply_avg = lambda matrix: torch.transpose(self.__avgpool__(torch.transpose(matrix, 1,2)), 1,2)\n",
    "\n",
    "    vectors = []\n",
    "\n",
    "    if L % 8:\n",
    "      raise Exception(\"Something went wrong, convs are not mult of 8\")\n",
    "    for i in range(L // 8):\n",
    "\n",
    "      n = torch.autograd.Variable(narrow[:, 8*i:8*(i+1), :])\n",
    "      m = torch.autograd.Variable(mid[:, 8*i:8*(i+1), :])\n",
    "      w = torch.autograd.Variable(wide[:, 8*i:8*(i+1), :])\n",
    "\n",
    "      n = apply_avg(n)\n",
    "      m = apply_avg(m)\n",
    "      w = apply_avg(w)\n",
    "\n",
    "      n = n.reshape(N, 2*self.features)\n",
    "      m = m.reshape(N, 2*self.features)\n",
    "      w = w.reshape(N, 2*self.features)\n",
    "      # gives N x 2 * Features\n",
    "\n",
    "      vectors.append(torch.autograd.Variable(torch.cat((n,m,w), dim=1))) # N x 6 * features\n",
    "\n",
    "    return vectors\n",
    "\n",
    "class FluxAnomalyPredictionTF(nn.Module):\n",
    "  def __init__(self, stride, dropout, bn=False, features=3, residual=0, out=4):\n",
    "    super().__init__()\n",
    "\n",
    "    self.stride = stride\n",
    "    self.features = features\n",
    "    self.residual = residual\n",
    "    self.transformer_hidden_dim = 2*features # Needed for batchnorm 3, so defined here\n",
    "\n",
    "    # Need Dropouts, Activation fns\n",
    "    self.he = lambda x: nn.init.kaiming_normal_(x, nonlinearity='relu')\n",
    "    self.av = nn.ReLU()\n",
    "    self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    self.batchnorm1 = lambda x: x\n",
    "    self.batchnorm2 = lambda x: x\n",
    "    self.batchnorm3 = lambda x: x\n",
    "\n",
    "    if bn:\n",
    "      self.batchnorm1 = nn.BatchNorm1d(features)\n",
    "      self.batchnorm2 = nn.BatchNorm1d(features)\n",
    "      self.batchnorm3 = nn.BatchNorm1d(self.transformer_hidden_dim)\n",
    "\n",
    "      self.bn1 = lambda x: torch.transpose(self.batchnorm1(torch.transpose(x,1,2)),1,2)\n",
    "      self.bn2 = lambda x: torch.transpose(self.batchnorm2(torch.transpose(x,1,2)),1,2)\n",
    "      self.bn3 = lambda x: self.batchnorm3(x)\n",
    "    else:\n",
    "      self.bn1 = lambda x: x\n",
    "      self.bn2 = lambda x: x\n",
    "      self.bn3 = lambda x: x\n",
    "\n",
    "\n",
    "    # Step 1\n",
    "\n",
    "    # 5 x 64 X 64 x 5 -diag-> R^5 Vector\n",
    "    self.conv_kernels_64d = nn.ParameterList([self.he(torch.randn(features, 64)) for i in range(8)])\n",
    "    self.conv_biases_64d = nn.ParameterList([torch.randn(features) for i in range(8)])\n",
    "\n",
    "    self.conv_kernel_16d = nn.Parameter(self.he(torch.randn(features, 16)))\n",
    "    self.conv_bias_16d = nn.Parameter(torch.randn(features))\n",
    "\n",
    "    self.conv_kernel_8d = nn.Parameter(self.he(torch.randn(features,8)))\n",
    "    self.conv_bias_8d = nn.Parameter(torch.randn(features))\n",
    "\n",
    "    self.four_max_pool = nn.MaxPool1d(4)\n",
    "\n",
    "    # Step 1.5\n",
    "    # self.certainty_fc_1 = nn.Parameter(torch.zeros(2,3))\n",
    "    # self.certainty_fc_2 = nn.Parameter(torch.zeros(3,1))\n",
    "\n",
    "    # Step 2\n",
    "    self.widechannel_conv_kernel = nn.Parameter(self.he(torch.randn(features, 3)))\n",
    "    self.widechannel_conv_bias = nn.Parameter(torch.randn(features))\n",
    "\n",
    "    self.midchannel_conv_kernel = nn.Parameter(self.he(torch.randn(features, 3)))\n",
    "    self.midchannel_conv_bias = nn.Parameter(torch.randn(features))\n",
    "\n",
    "    self.narrowchannel_conv_kernel = nn.Parameter(self.he(torch.randn(features, 3)))\n",
    "    self.narrowchannel_conv_bias = nn.Parameter(torch.randn(features))\n",
    "\n",
    "\n",
    "    # Step 3\n",
    "    self.pair_max_pool = nn.MaxPool1d(2)\n",
    "    # Then concat all vectors into v \\in R^24\n",
    "\n",
    "    # Step 3.5 Residual connection\n",
    "    self.__avgpool__ = nn.AvgPool1d(4, stride=4)\n",
    "\n",
    "    # Step 4\n",
    "    self.hidden_fc_1 = nn.Linear(3*4*features, 3*2*features)\n",
    "    self.hidden_fc_2 = nn.Linear(3*2*features, self.transformer_hidden_dim)\n",
    "\n",
    "    # Step 5\n",
    "    # Transformer\n",
    "    self.transformer_encoder_layer = nn.TransformerEncoderLayer(d_model=self.transformer_hidden_dim, nhead=self.features)\n",
    "    self.transformer_encoder = nn.TransformerEncoder(self.transformer_encoder_layer, 2)\n",
    "\n",
    "\n",
    "    # Step 6\n",
    "    # Softmax\n",
    "\n",
    "    self.to_out_1 = nn.Linear(self.transformer_hidden_dim, 7)\n",
    "    self.to_out_2 = nn.Linear(7, out, bias=False)\n",
    "\n",
    "    self.prob = nn.Softmax(dim=1)\n",
    "\n",
    "    for param in self.parameters():\n",
    "      if len(param.shape) >= 2:\n",
    "        param = self.he(param)\n",
    "\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    # x = Batches X Time X Channels\n",
    "\n",
    "    N = x.shape[0] # Batches\n",
    "    T = x.shape[1] # Time\n",
    "\n",
    "    if x.shape[2] != self.features:\n",
    "      raise Exception(\"Feature dimension mismatch\")\n",
    "\n",
    "    # Step 1\n",
    "    # Cursory vision convolution\n",
    "    pad_amt = 40\n",
    "\n",
    "    pad = torch.zeros(N, pad_amt, self.features).to(device)\n",
    "  \n",
    "\n",
    "    padded_x = torch.cat((pad, torch.cat((x, pad), dim=1)), dim=1) # catting in time\n",
    "\n",
    "    # padded_x.requires_grad = True\n",
    "\n",
    "    window_centers = [] # AKA 64d Convolve Centers\n",
    "\n",
    "    n=0 # strides\n",
    "    while(True):\n",
    "      next_center = pad_amt + 1 + n * self.stride\n",
    "      if next_center > (pad_amt + T + 1): # If our center isnt in real data\n",
    "        break;\n",
    "      else:\n",
    "        window_centers.append(next_center)\n",
    "        n += 1\n",
    "\n",
    "    window_starts = [self.start_and_end_from_center((64 - 1)/2, i)[0] for i in window_centers]\n",
    "    window_ends = [self.start_and_end_from_center((64 - 1)/2, i)[1] for i in window_centers]\n",
    "\n",
    "    midchannel_centers = []\n",
    "    narrowchannel_centers = []\n",
    "    for start in window_starts:\n",
    "      for n in range(8): # 8 strides of 8 -> 64 units\n",
    "        midchannel_centers.append(start + n * 8)\n",
    "\n",
    "      for n in range(32): # 32 strides of 2 -> 64 units\n",
    "        narrowchannel_centers.append(start + n * 2)\n",
    "\n",
    "\n",
    "    wide_convs = []\n",
    "    mid_convs = []\n",
    "    narrow_convs = []\n",
    "\n",
    "    for i in window_centers:\n",
    "      for j in range(8): # Hard coded 8 here\n",
    "        K = self.conv_kernels_64d[j]\n",
    "        B = self.conv_biases_64d[j].repeat(N,1) # Repeat here\n",
    "        conv = self.convolve(K, padded_x, i) # Features x T\n",
    "        conv += B\n",
    "        wide_convs.append(conv)\n",
    "\n",
    "    for i in midchannel_centers:\n",
    "      conv = self.convolve(self.conv_kernel_16d, padded_x, i)\n",
    "      conv += self.conv_bias_16d.repeat(N,1)\n",
    "      mid_convs.append(conv)\n",
    "\n",
    "    for i in narrowchannel_centers:\n",
    "      conv = self.convolve(self.conv_kernel_8d, padded_x, i)\n",
    "      conv += self.conv_bias_8d.repeat(N,1)\n",
    "      narrow_convs.append(conv)\n",
    "\n",
    "    wide_convs = torch.stack(wide_convs, dim=1).to(device)\n",
    "    mid_convs = torch.stack(mid_convs, dim=1).to(device)\n",
    "    narrow_convs = torch.stack(narrow_convs, dim=1).to(device)\n",
    "\n",
    "    narrow_convs = self.four_max_pool(torch.transpose(narrow_convs, 1,2)) # Inp = N x C x L now\n",
    "    narrow_convs = torch.transpose(narrow_convs,1,2) # Back to N x L x C\n",
    "\n",
    "\n",
    "    wide_convs = self.bn1(self.av(wide_convs))\n",
    "    mid_convs = self.bn1(self.av(mid_convs))\n",
    "    narrow_convs = self.bn1(self.av(narrow_convs))\n",
    "\n",
    "    residual_vectors = self.get_residual_vectors(narrow_convs, mid_convs, wide_convs)\n",
    "\n",
    "\n",
    "    wide_convs = 5 * self.drop(wide_convs)\n",
    "    mid_convs = self.drop(mid_convs)\n",
    "    narrow_convs = self.drop(narrow_convs)\n",
    "\n",
    "\n",
    "\n",
    "    #####\n",
    "    # STEP 2\n",
    "    # Second Convolution\n",
    "\n",
    "    pad_amt = 10\n",
    "    stride = 1\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for x in (wide_convs, mid_convs, narrow_convs):\n",
    "      T = x.shape[1]\n",
    "      ker = None\n",
    "      bias = None\n",
    "      if len(results) == 0:\n",
    "        ker = self.widechannel_conv_kernel\n",
    "        bias = self.widechannel_conv_bias.repeat(N, 1)\n",
    "\n",
    "      elif len(results) == 1:\n",
    "        ker = self.midchannel_conv_kernel\n",
    "        bias = self.midchannel_conv_bias.repeat(N, 1)\n",
    "\n",
    "      elif len(results) == 2:\n",
    "        ker = self.narrowchannel_conv_kernel\n",
    "        bias = self.narrowchannel_conv_bias.repeat(N, 1)\n",
    "\n",
    "\n",
    "      pad = torch.zeros(N, pad_amt, self.features).to(device)\n",
    "      padded_x = torch.cat((pad, torch.cat((x, pad), dim=1)), dim=1)\n",
    "\n",
    "\n",
    "      result = []\n",
    "\n",
    "      next = pad_amt\n",
    "      while next <= (pad_amt + T - 1):\n",
    "        v = bias + self.convolve(ker, padded_x, next)\n",
    "        result.append(v)\n",
    "        next += stride\n",
    "\n",
    "\n",
    "      results.append(torch.stack(result, dim=1))\n",
    "\n",
    "\n",
    "    wide_convs = self.bn2(self.av(results[0]))\n",
    "    mid_convs = self.bn2(self.av(results[1]))\n",
    "    narrow_convs = self.bn2(self.av(results[2]))\n",
    "\n",
    "    wide_convs = self.drop(wide_convs)\n",
    "    mid_convs = self.drop(mid_convs)\n",
    "    narrow_convs = self.drop(narrow_convs)\n",
    "\n",
    "\n",
    "\n",
    "    ####\n",
    "    # Step 2.5\n",
    "    # Max Pooling Pairs\n",
    "    wide_convs = self.pair_max_pool(torch.transpose(wide_convs, 1,2)) # to N x C x L\n",
    "    mid_convs = self.pair_max_pool(torch.transpose(mid_convs, 1,2))\n",
    "    narrow_convs = self.pair_max_pool(torch.transpose(narrow_convs, 1,2))\n",
    "\n",
    "    wide_convs = torch.transpose(wide_convs, 1,2) # to N x L x C\n",
    "    mid_convs = torch.transpose(mid_convs, 1,2)\n",
    "    narrow_convs = torch.transpose(narrow_convs, 1,2)\n",
    "\n",
    "\n",
    "    ####\n",
    "    # Step 3\n",
    "\n",
    "    # Now each original window reigon is each corresponding 2 rows from all 3 tensors\n",
    "    # 2 rows evenly divides all possible resulting lengths\n",
    "\n",
    "    if not (wide_convs.shape[1] == mid_convs.shape[1] == narrow_convs.shape[1]):\n",
    "      raise Exception(\"Step 3 output mismatch\")\n",
    "\n",
    "\n",
    "    hidden = []\n",
    "    L = wide_convs.shape[1]\n",
    "\n",
    "    for n in range(L // 4): # Now each sliding window corresponds to 2 rows\n",
    "      wide = wide_convs[:, 4*n:4*n + 4].reshape(N, 4*self.features)\n",
    "      mid = mid_convs[:, 4*n:4*n + 4].reshape(N, 4*self.features)\n",
    "      narrow = narrow_convs[:, 4*n:4*n + 4].reshape(N, 4*self.features)\n",
    "\n",
    "      flat = torch.cat((wide, mid, narrow), dim=1).to(device)\n",
    "      if flat.shape[0] != N or flat.shape[1] != 3*4*self.features:\n",
    "        raise Exception(\"Flat shape err\")\n",
    "\n",
    "      layer_1 = self.hidden_fc_1(flat)\n",
    "      layer_1 = self.av(layer_1)\n",
    "\n",
    "      # RESIDUAL CONNECTION !\n",
    "      res = torch.autograd.Variable(self.residual * residual_vectors[n])\n",
    "      layer_1 = (1-self.residual) * layer_1\n",
    "      layer_1 = layer_1 + res\n",
    "\n",
    "      layer_2 = self.hidden_fc_2(layer_1)\n",
    "      layer_2 = self.av(layer_2)\n",
    "\n",
    "      hidden.append(layer_2)\n",
    "\n",
    "    hidden = torch.stack(hidden, dim=0) # Results in L x N x Hidden\n",
    "    hidden = self.drop(hidden)\n",
    "\n",
    "    print(\"hidden shape\", hidden.shape)\n",
    "\n",
    "\n",
    "    seq = self.transformer_encoder(hidden)\n",
    "\n",
    "    print(\"after transformer shape: \", seq.shape)\n",
    "\n",
    "\n",
    "\n",
    "    transformed = nn.AvgPool1d(seq.shape[0])(torch.transpose(seq, 0, 2))\n",
    "\n",
    "    transformed = transformed.squeeze() # Should now be N x 6*features\n",
    "    transformed = torch.transpose(transformed, 0, 1)\n",
    "\n",
    "    transformed = self.av(transformed)\n",
    "    transformed = self.bn3(transformed)\n",
    "    transformed = self.drop(transformed)\n",
    "\n",
    "\n",
    "    final_layer = self.to_out_1(transformed)\n",
    "    final_layer = self.av(final_layer)\n",
    "    final_layer = self.drop(final_layer)\n",
    "    final_layer = self.to_out_2(final_layer)\n",
    "\n",
    "    # classes = self.prob(final_layer) # Dont use, use CEL instead\n",
    "\n",
    "    return F.log_softmax(final_layer, dim=1)\n",
    "\n",
    "\n",
    "  def start_and_end_from_center(self, width, i):\n",
    "    start = i - np.ceil(width)\n",
    "    end = i + np.floor(width) + 1\n",
    "    return (int(start), int(end))\n",
    "\n",
    "\n",
    "\n",
    "  def convolve(self, Kernel, Data, i):\n",
    "\n",
    "    # i is center index so we take equal on either side\n",
    "    T = Kernel.shape[1]\n",
    "    each_side = (T - 1) / 2\n",
    "\n",
    "    # Moves it backwards 1 if kernel is even\n",
    "    start, end = self.start_and_end_from_center(each_side, i)\n",
    "\n",
    "    adj_data = Data[:, start:end, :]\n",
    "\n",
    "    # So now K is 5 x L and adj_data is N x L X 5\n",
    "\n",
    "\n",
    "    N = adj_data.shape[0]\n",
    "\n",
    "    m = torch.bmm(Kernel.repeat(N,1,1), adj_data) # bij, bjk -> bik Slightly faster than einsum\n",
    "\n",
    "    # m = torch.einsum(\"ij, bjk -> bik\", Kernel, adj_data) #identical batch matmul\n",
    "\n",
    "    diag = torch.einsum(\"bii->bi\", m)\n",
    "    # diags = []\n",
    "    # for res in m:\n",
    "    #   diags.append(torch.diag(res))\n",
    "\n",
    "\n",
    "    return diag\n",
    "\n",
    "  def get_residual_vectors(self, narrow, mid, wide):\n",
    "    # Should be N x 8m x Features\n",
    "    # print(narrow.shape, mid.shape, wide.shape)\n",
    "    N = wide.shape[0]\n",
    "    L = wide.shape[1]\n",
    "\n",
    "    apply_avg = lambda matrix: torch.transpose(self.__avgpool__(torch.transpose(matrix, 1,2)), 1,2)\n",
    "\n",
    "    vectors = []\n",
    "\n",
    "    if L % 8:\n",
    "      raise Exception(\"Something went wrong, convs are not mult of 8\")\n",
    "    for i in range(L // 8):\n",
    "\n",
    "      n = torch.autograd.Variable(narrow[:, 8*i:8*(i+1), :])\n",
    "      m = torch.autograd.Variable(mid[:, 8*i:8*(i+1), :])\n",
    "      w = torch.autograd.Variable(wide[:, 8*i:8*(i+1), :])\n",
    "\n",
    "      n = apply_avg(n)\n",
    "      m = apply_avg(m)\n",
    "      w = apply_avg(w)\n",
    "\n",
    "      n = n.reshape(N, 2*self.features)\n",
    "      m = m.reshape(N, 2*self.features)\n",
    "      w = w.reshape(N, 2*self.features)\n",
    "      # gives N x 2 * Features\n",
    "\n",
    "      vectors.append(torch.autograd.Variable(torch.cat((n,m,w), dim=1))) # N x 6 * features\n",
    "\n",
    "    return vectors\n",
    "\n",
    "class lstm(nn.Module):\n",
    "  def __init__(self, into, hidden, out):\n",
    "    super().__init__()\n",
    "\n",
    "    self.rl = nn.functional.sigmoid\n",
    "    self.ls = nn.LSTM(into, hidden, batch_first=True)\n",
    "    self.to_out = nn.Linear(hidden,out)\n",
    "    self.prob = nn.Softmax(dim=1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    _, (f, __) = self.ls(x)\n",
    "\n",
    "    return self.to_out(f.squeeze())\n",
    "\n",
    "class lstm2(nn.Module):\n",
    "  def __init__(self, into, hidden, out):\n",
    "    super().__init__()\n",
    "\n",
    "    self.rl = nn.functional.sigmoid\n",
    "    self.ls = nn.LSTM(into, hidden, batch_first=True, num_layers=2)\n",
    "    self.to_out = nn.Linear(hidden,out)\n",
    "    self.prob = nn.Softmax(dim=1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    _, (f, __) = self.ls(x)\n",
    "\n",
    "    return self.to_out(f[1, :].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1698123021980,
     "user": {
      "displayName": "Matteo",
      "userId": "07662895649750931658"
     },
     "user_tz": 420
    },
    "id": "QCaXFn0b4T4E",
    "outputId": "046486bb-7ddf-4d47-ff86-8c8da5e3c5eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82997\n"
     ]
    }
   ],
   "source": [
    "model = FluxAnomalyPredictionTF(20, 0.15, bn=False, features=3, residual=0).to(device)\n",
    "# model = lstm(6, 20, 4).to(device)\n",
    "\n",
    "model_pars = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_pars])\n",
    "\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H_b1-I0j1wFp"
   },
   "source": [
    "# Trainloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 202,
     "status": "ok",
     "timestamp": 1698123023002,
     "user": {
      "displayName": "Matteo",
      "userId": "07662895649750931658"
     },
     "user_tz": 420
    },
    "id": "BOJnl8dTJEoi",
    "outputId": "4aa465eb-c350-44e1-9ba4-8fb3b276d6dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 480, 3])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def padded_collate(tensors):\n",
    "  datas = []\n",
    "  labels = []\n",
    "  for tensor, label in tensors:\n",
    "    datas.append(tensor)\n",
    "    labels.append(label)\n",
    "\n",
    "  batched = nn.utils.rnn.pad_sequence(datas, batch_first=True).to(device)\n",
    "  labels = torch.stack(labels, dim=0)\n",
    "\n",
    "\n",
    "  return (batched, labels)\n",
    "\n",
    "\n",
    "\n",
    "train = DataLoader(data_train, batch_size=1, shuffle=True, collate_fn=padded_collate)\n",
    "valid = DataLoader(data_valid, batch_size=len(data_valid), shuffle=True, collate_fn=padded_collate)\n",
    "# test = DataLoader(data_test, batch_size=None, shuffle=True)\n",
    "next(iter(train))[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYgdIa8hkwmg"
   },
   "source": [
    "# General Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "8Do4g3HOWOQr"
   },
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "def compete(trainers, epochs, trainloader, validloader):\n",
    "  # trainers are model-optimizer pairs\n",
    "\n",
    "  progress_bar = tqdm(total=epochs, desc=\"Training Progress\")\n",
    "  loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "\n",
    "  trainloss = {}\n",
    "  validloss = {}\n",
    "\n",
    "  nullts = {}\n",
    "  novats = {}\n",
    "  pulsatingts = {}\n",
    "  transitts = {}\n",
    "  accuracyts = {}\n",
    "\n",
    "  for name, _, __ in trainers:\n",
    "    trainloss[name] = []\n",
    "    validloss[name] = []\n",
    "    nullts[name] = []\n",
    "    novats[name] = []\n",
    "    pulsatingts[name] = []\n",
    "    transitts[name] = []\n",
    "    accuracyts[name] = []\n",
    "\n",
    "\n",
    "  for e in range(epochs):\n",
    "    t1 = perf_counter()\n",
    "\n",
    "\n",
    "    for name, model, optim in trainers:\n",
    "      epoch_loss = []\n",
    "      valid_loss = []\n",
    "\n",
    "      null_correct = 0\n",
    "      nova_correct = 0\n",
    "      pulsating_correct = 0\n",
    "      transit_correct = 0\n",
    "      correct = 0\n",
    "\n",
    "\n",
    "      novas = 0\n",
    "      pulsators = 0\n",
    "      transits = 0\n",
    "      nulls = 0\n",
    "      exs = 0\n",
    "\n",
    "      for data, label in trainloader:\n",
    "        model.train()\n",
    "        out = model(data)\n",
    "\n",
    "        optim.zero_grad()\n",
    "\n",
    "        loss = loss_fn(out, label)\n",
    "        epoch_loss.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        print(out, label)\n",
    "        print(loss)\n",
    "        optim.step()\n",
    "\n",
    "\n",
    "      for data, label in validloader:\n",
    "        model.eval()\n",
    "        out = model(data)\n",
    "        loss = loss_fn(out, label)\n",
    "        valid_loss.append(loss.item())\n",
    "        i = torch.argmax(out, dim=1).cpu()\n",
    "        j = torch.argmax(label, dim=1).cpu()\n",
    "\n",
    "        for idx, jdx in zip(i,j):\n",
    "          exs+=1\n",
    "          if idx == jdx:\n",
    "            correct += 1\n",
    "\n",
    "          if jdx == 0:\n",
    "            nulls += 1\n",
    "            if idx == jdx:\n",
    "              null_correct += 1\n",
    "\n",
    "          if jdx == 1:\n",
    "            novas += 1\n",
    "            if idx == jdx:\n",
    "              nova_correct +=1\n",
    "          if jdx == 2:\n",
    "            pulsators += 1\n",
    "            if idx == jdx:\n",
    "              pulsating_correct +=1\n",
    "          if jdx == 3:\n",
    "            transits += 1\n",
    "            if idx == jdx:\n",
    "              transit_correct +=1\n",
    "\n",
    "      training_loss_epoch = np.mean(epoch_loss)\n",
    "      validation_loss_epoch = np.mean(valid_loss)\n",
    "\n",
    "      nullac = null_correct / (nulls + 0.000001)\n",
    "      novacc = nova_correct / (novas + 0.000001)\n",
    "      pulsatoracc = pulsating_correct / (pulsators + 0.00001)\n",
    "      transitacc = transit_correct / (transits + 0.00001)\n",
    "      accuracy = correct / exs\n",
    "\n",
    "      trainloss[name].append(training_loss_epoch)\n",
    "      validloss[name].append(validation_loss_epoch)\n",
    "\n",
    "      nullts[name].append(nullac)\n",
    "      novats[name].append(novacc)\n",
    "      pulsatingts[name].append(pulsatoracc)\n",
    "      transitts[name].append(transitacc)\n",
    "      accuracyts[name].append(accuracy)\n",
    "\n",
    "\n",
    "\n",
    "    dt = perf_counter() - t1\n",
    "    if dt < 0.65:\n",
    "      if e % int(1.75/dt) == 0:\n",
    "        for name, _, __ in trainers:\n",
    "          clear_output()\n",
    "          fig = getprogressplot(trainloss[name], validloss[name], accuracyts[name], nullts[name], novats[name], pulsatingts[name], transitts[name], epochs, e)\n",
    "          fig.update_layout(title=name+' Statistics: {}/{}'.format(e, epochs),\n",
    "                        xaxis_title='Epochs',\n",
    "                        yaxis_title='Loss',\n",
    "                        width=650)\n",
    "          display(fig)\n",
    "    else:\n",
    "      for name, _, __ in trainers:\n",
    "        clear_output()\n",
    "        fig = getprogressplot(trainloss[name], validloss[name], accuracyts[name], nullts[name], novats[name], pulsatingts[name], transitts[name], epochs, e)\n",
    "        fig.update_layout(title=name+' Statistics: {}/{}'.format(e, epochs),\n",
    "                      xaxis_title='Epochs',\n",
    "                      yaxis_title='Loss',\n",
    "                      width=1000)\n",
    "        display(fig)\n",
    "\n",
    "    progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 648,
     "referenced_widgets": [
      "9137e576ff0948b6a5bbef5a146e05da",
      "e06b6fd9a99b4bc283bc942d7517086b",
      "f67d8e102ab84d37a7ed583406539773",
      "7a4d438c1bef4707babe8b0293c437ae",
      "02705c67d19b4eb188b228046fbf1e99",
      "4bcf7e6f9cd2451687e1ba12c74240e5",
      "8d345de5fbd84261a1c8588337db694d",
      "5af5e5934a9c441784a1791a818e3e76",
      "26f8b4836e9d4aa3ab3fe425455cb365",
      "3df46f544a194a80908e44bf1d394491",
      "5c2d716c0c134147aa3ca644a3983928"
     ]
    },
    "executionInfo": {
     "elapsed": 1677,
     "status": "error",
     "timestamp": 1698124533926,
     "user": {
      "displayName": "Matteo",
      "userId": "07662895649750931658"
     },
     "user_tz": 420
    },
    "id": "sqSYmDNR0tNC",
    "outputId": "2b710e03-c1b3-4198-8629-937b90f7b9a8"
   },
   "outputs": [],
   "source": [
    "# model = FluxAnomalyPredictionTF(14, 0.15, bn=False, features=3, residual=0).to(device)\n",
    "# model.train()\n",
    "# model = FluxAnomalyPredictionLSTM(14, 0.15, bn=False, features=3, residual=0).to(device)\n",
    "# model = lstm(3,10,4).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "compete([(\"TF\", model, optimizer)], 720, train, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bErp_JdkDUfg"
   },
   "outputs": [],
   "source": [
    "with open(ROOT + \"models/tf_str14_dp015_bnF_f3_res0.pt\", \"wb\") as f:\n",
    "  torch.save(model.state_dict(),f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XX8cN71g14oT"
   },
   "source": [
    "# Training Loop (Single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "DmGh2Yd4kclP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/500 [01:13<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 148, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     41\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 42\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(out, label)\n\u001b[1;32m     47\u001b[0m epoch_loss\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[74], line 698\u001b[0m, in \u001b[0;36mFluxAnomalyPredictionTF.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    695\u001b[0m transformed \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mAvgPool1d(seq\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])(torch\u001b[38;5;241m.\u001b[39mtranspose(seq, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m    697\u001b[0m transformed \u001b[38;5;241m=\u001b[39m transformed\u001b[38;5;241m.\u001b[39msqueeze() \u001b[38;5;66;03m# Should now be N x 6*features\u001b[39;00m\n\u001b[0;32m--> 698\u001b[0m transformed \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    700\u001b[0m transformed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mav(transformed)\n\u001b[1;32m    701\u001b[0m transformed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn3(transformed)\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "EPOCHS = 500\n",
    "lr = 0.007\n",
    "\n",
    "model = FluxAnomalyPredictionTF(20, 0.15, bn=False, features=3, residual=0).to(device)\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "progress_bar = tqdm(total=EPOCHS, desc=\"Training Progress\")\n",
    "\n",
    "trainloss = []\n",
    "validloss = []\n",
    "\n",
    "nullts = []\n",
    "novats = []\n",
    "pulsatingts = []\n",
    "transitts = []\n",
    "accuracyts = []\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "  epoch_loss = []\n",
    "  valid_loss = []\n",
    "\n",
    "  null_correct = 0\n",
    "  nova_correct = 0\n",
    "  pulsating_correct = 0\n",
    "  transit_correct = 0\n",
    "  correct = 0\n",
    "\n",
    "\n",
    "  novas = 0\n",
    "  pulsators = 0\n",
    "  transits = 0\n",
    "  nulls = 0\n",
    "  exs = 0\n",
    "\n",
    "  for data, label in train:\n",
    "\n",
    "    print(data.shape)\n",
    "\n",
    "    model.train()\n",
    "    out = model(data)\n",
    "\n",
    "\n",
    "\n",
    "    loss = loss_fn(out, label)\n",
    "    epoch_loss.append(loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    optim.zero_grad()\n",
    "\n",
    "\n",
    "  for data, label in valid:\n",
    "    model.eval()\n",
    "    out = model(data)\n",
    "    loss = loss_fn(out, label)\n",
    "    valid_loss.append(loss.item())\n",
    "    i = torch.argmax(out, dim=1).cpu()\n",
    "    j = torch.argmax(label, dim=1).cpu()\n",
    "\n",
    "    for idx, jdx in zip(i,j):\n",
    "      exs += 1\n",
    "      if idx == jdx:\n",
    "        correct += 1\n",
    "\n",
    "      if jdx == 0:\n",
    "        nulls += 1\n",
    "        if idx == jdx:\n",
    "          null_correct += 1\n",
    "\n",
    "      if jdx == 1:\n",
    "        novas += 1\n",
    "        if idx == jdx:\n",
    "          nova_correct +=1\n",
    "      if jdx == 2:\n",
    "        pulsators += 1\n",
    "        if idx == jdx:\n",
    "          pulsating_correct +=1\n",
    "      if jdx == 3:\n",
    "        transits += 1\n",
    "        if idx == jdx:\n",
    "          transit_correct +=1\n",
    "\n",
    "  training_loss_epoch = np.mean(epoch_loss)\n",
    "  validation_loss_epoch = np.mean(valid_loss)\n",
    "\n",
    "  nullac = null_correct / (nulls + 0.000001)\n",
    "  novacc = nova_correct / (novas + 0.000001)\n",
    "  pulsatoracc = pulsating_correct / (pulsators + 0.00001)\n",
    "  transitacc = transit_correct / (transits + 0.00001)\n",
    "  accuracy = correct / exs\n",
    "\n",
    "  trainloss.append(training_loss_epoch)\n",
    "  validloss.append(validation_loss_epoch)\n",
    "\n",
    "  nullts.append(nullac)\n",
    "  novats.append(novacc)\n",
    "  pulsatingts.append(pulsatoracc)\n",
    "  transitts.append(transitacc)\n",
    "  accuracyts.append(accuracy)\n",
    "\n",
    "\n",
    "  progress_bar.update(1)\n",
    "  p = getprogressplot(trainloss, validloss, accuracyts, nullts, novats, pulsatingts, transitts, EPOCHS, e)\n",
    "  clear_output(wait=False)\n",
    "  display(p)\n",
    "\n",
    "  if e % 50 != 0:\n",
    "    continue\n",
    "  print(\"Epoch \", e, \": \", training_loss_epoch)\n",
    "  print(\"nulls:\", nullac, \"novas: \", novacc, \"pulsators: \", pulsatoracc, \"transits: \", transitacc)\n",
    "\n",
    "x = range(EPOCHS)\n",
    "\n",
    "p = getprogressplot(trainloss, validloss, accuracyts, nullts, novats, pulsatingts, transitts, EPOCHS, e)\n",
    "clear_output(wait=True)\n",
    "display(p)\n",
    "\n",
    "with open(ROOT + \"models/model.pt\", \"wb\") as f:\n",
    "  torch.save(model.named_parameters(),f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kLEfU1iE1700"
   },
   "source": [
    "# Diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ibQBwjauUKk"
   },
   "outputs": [],
   "source": [
    "first = next(iter(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hd7lTexPrTDo"
   },
   "outputs": [],
   "source": [
    "model = FluxAnomalyPrediction(32, 0, True, residual=0).to(device)\n",
    "loss = loss_fn(model(first[0]), first[1])\n",
    "optim.zero_grad()\n",
    "loss.backward()\n",
    "# for p, t in model.cpu().named_parameters():\n",
    "#   print(p, t.grad)\n",
    "plot_grad_flow(model.cpu().named_parameters())\n",
    "plt.show()\n",
    "\n",
    "model = FluxAnomalyPrediction(32, 0, True, residual=0.5).to(device)\n",
    "loss = loss_fn(model(first[0]), first[1])\n",
    "optim.zero_grad()\n",
    "loss.backward()\n",
    "# for p, t in model.cpu().named_parameters():\n",
    "#   print(p, t.grad)\n",
    "plot_grad_flow(model.cpu().named_parameters())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qPbsgAA7OIXE"
   },
   "outputs": [],
   "source": [
    "model = FluxAnomalyPrediction(32, 0.1).to(device)\n",
    "\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "    with record_function(\"dd\"):\n",
    "        ex = next(iter(train))\n",
    "        out = model(ex[0])\n",
    "        loss = loss_fn(out, ex[1])\n",
    "        loss.backward()\n",
    "        for name, param in model.cpu().named_parameters():\n",
    "          print(name, param.grad)\n",
    "        plot_grad_flow(model.cpu().named_parameters())\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJFFK8gXQDHd"
   },
   "source": [
    "# Testing / Toy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t3ICnHudps2w"
   },
   "outputs": [],
   "source": [
    "class bigboy(nn.Module):\n",
    "  def __init__(self, out):\n",
    "    super().__init__()\n",
    "    self.av = nn.ReLU()\n",
    "\n",
    "    self.to_one = nn.Parameter(torch.zeros(6))\n",
    "\n",
    "    self.fc1 = nn.Linear(350, 200)\n",
    "    self.fc2 = nn.Linear(200, 100)\n",
    "    self.fc3 = nn.Linear(100, 10)\n",
    "\n",
    "\n",
    "\n",
    "    self.fc4 = nn.Linear(10, out)\n",
    "\n",
    "    self.prob = nn.Softmax(dim=1)\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "    # x = torch.einsum(\"bij,j->bi\", x, self.to_one)\n",
    "    x = x[:, :, 0]\n",
    "    T = x.shape[1]\n",
    "\n",
    "    pad = torch.zeros(x.shape[0], 350 - T).to(device)\n",
    "\n",
    "    padded = torch.cat((x, pad), dim=1)\n",
    "\n",
    "\n",
    "    current = padded\n",
    "\n",
    "    for f in (self.fc1, self.fc2, self.fc3, self.fc4):\n",
    "      current = self.av(f(current))\n",
    "\n",
    "    return self.prob(current)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W6V1hf9PXn_n"
   },
   "outputs": [],
   "source": [
    "class PseudoSet(Dataset):\n",
    "  def __init__(self, classes):\n",
    "    self.classes = classes\n",
    "\n",
    "    self.all = []\n",
    "    for i, class_ in enumerate(self.classes):\n",
    "      label = torch.zeros(len(self.classes))\n",
    "      label[i] = 1\n",
    "      for ex in class_:\n",
    "        self.all.append((ex, label))\n",
    "\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.all[idx]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.all)\n",
    "\n",
    "with open(ROOT + \"datasets/toy_data_train.pt\", \"rb\") as f:\n",
    "  toydata_train = torch.load(f, map_location=device)\n",
    "with open(ROOT + \"datasets/toy_data_valid.pt\", \"rb\") as f:\n",
    "  toydata_valid = torch.load(f, map_location=device)\n",
    "\n",
    "toytrain = DataLoader(toydata_train, batch_size=len(toydata_train), collate_fn=padded_collate, shuffle=True)\n",
    "toyvalid = DataLoader(toydata_valid, batch_size=len(toydata_valid), collate_fn=padded_collate, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ha3x9Psl2T-A"
   },
   "outputs": [],
   "source": [
    "ex = toydata_train[100][0].cpu()\n",
    "plt.scatter(ex[:, -2], ex[:, 0])\n",
    "print(toydata_train[200][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WOaRghgDbNGP"
   },
   "outputs": [],
   "source": [
    "model = FluxAnomalyPredictionLSTM(15, 0.15, residual=0, features=6, out=3).to(device)\n",
    "# model = lstm(6, 20, 3).to(device)\n",
    "# model = bigboy(3).to(device)\n",
    "\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=10**-6.5)\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "trainers = [\n",
    "    (\"Flux Anomaly Predictor\", model, optim)\n",
    "]\n",
    "\n",
    "compete(trainers, 150, train, valid)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPn/w4j+IUa3ZgM7or7h7ji",
   "gpuType": "T4",
   "mount_file_id": "18k-3VG5eHIKWuvn4cbLSEYkNPYsG3W-J",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02705c67d19b4eb188b228046fbf1e99": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26f8b4836e9d4aa3ab3fe425455cb365": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3df46f544a194a80908e44bf1d394491": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4bcf7e6f9cd2451687e1ba12c74240e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5af5e5934a9c441784a1791a818e3e76": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c2d716c0c134147aa3ca644a3983928": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7a4d438c1bef4707babe8b0293c437ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3df46f544a194a80908e44bf1d394491",
      "placeholder": "​",
      "style": "IPY_MODEL_5c2d716c0c134147aa3ca644a3983928",
      "value": " 0/720 [00:00&lt;?, ?it/s]"
     }
    },
    "8d345de5fbd84261a1c8588337db694d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9137e576ff0948b6a5bbef5a146e05da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e06b6fd9a99b4bc283bc942d7517086b",
       "IPY_MODEL_f67d8e102ab84d37a7ed583406539773",
       "IPY_MODEL_7a4d438c1bef4707babe8b0293c437ae"
      ],
      "layout": "IPY_MODEL_02705c67d19b4eb188b228046fbf1e99"
     }
    },
    "e06b6fd9a99b4bc283bc942d7517086b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4bcf7e6f9cd2451687e1ba12c74240e5",
      "placeholder": "​",
      "style": "IPY_MODEL_8d345de5fbd84261a1c8588337db694d",
      "value": "Training Progress:   0%"
     }
    },
    "f67d8e102ab84d37a7ed583406539773": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5af5e5934a9c441784a1791a818e3e76",
      "max": 720,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_26f8b4836e9d4aa3ab3fe425455cb365",
      "value": 0
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
