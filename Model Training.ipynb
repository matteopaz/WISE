{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epycmNPr0I3d"
   },
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Dwn1PtIp4058"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matteo/.pyenv/versions/3.11.2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from IPython.display import display, clear_output\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "\n",
    "ROOT = os.path.join(\"./\")\n",
    "sys.path.append(ROOT + \"lib\")\n",
    "\n",
    "from helpers import *\n",
    "from sourceset import SourceSet\n",
    "from general_trainer import compete\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_default_device(device)\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2917,
     "status": "ok",
     "timestamp": 1698123021083,
     "user": {
      "displayName": "Matteo",
      "userId": "07662895649750931658"
     },
     "user_tz": 420
    },
    "id": "0o5bi2-e_n2z",
    "outputId": "1792997b-1077-4089-b8ae-b1b818428b61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<sourceset.SourceSet at 0x1656d1ad0>, <sourceset.SourceSet at 0x165787b10>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(ROOT + \"processed_datasets/data_train.pt\", \"rb\") as f:\n",
    "  data_train = torch.load(f, map_location=device)\n",
    "with open(ROOT + \"processed_datasets/data_valid.pt\", \"rb\") as f:\n",
    "  data_valid = torch.load(f, map_location=device)\n",
    "\n",
    "data_train, data_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PU4Zzbo31tIp"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gd-gDX5vfwTG"
   },
   "outputs": [],
   "source": [
    "class FluxAnomalyPredictionLSTMDEPRECATED(nn.Module):\n",
    "  def __init__(self, stride, dropout, bn=False, features=6, residual=0, out=4):\n",
    "    super().__init__()\n",
    "\n",
    "    self.stride = stride\n",
    "    self.features = features\n",
    "    self.residual = residual\n",
    "    self.lstm_hidden_state_features = 14 # Needed for batchnorm 3, so defined here\n",
    "\n",
    "    # Need Dropouts, Activation fns\n",
    "    self.he = lambda x: nn.init.kaiming_normal_(x, nonlinearity='relu')\n",
    "    self.av = nn.ReLU()\n",
    "    self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    self.batchnorm1 = lambda x: x\n",
    "    self.batchnorm2 = lambda x: x\n",
    "    self.batchnorm3 = lambda x: x\n",
    "\n",
    "    if bn:\n",
    "      self.batchnorm1 = nn.BatchNorm1d(features)\n",
    "      self.batchnorm2 = nn.BatchNorm1d(features)\n",
    "      self.batchnorm3 = nn.BatchNorm1d(self.lstm_hidden_state_features)\n",
    "\n",
    "      self.bn1 = lambda x: torch.transpose(self.batchnorm1(torch.transpose(x,1,2)),1,2)\n",
    "      self.bn2 = lambda x: torch.transpose(self.batchnorm2(torch.transpose(x,1,2)),1,2)\n",
    "      self.bn3 = lambda x: self.batchnorm3(x)\n",
    "    else:\n",
    "      self.bn1 = lambda x: x\n",
    "      self.bn2 = lambda x: x\n",
    "      self.bn3 = lambda x: x\n",
    "\n",
    "\n",
    "    # Step 1\n",
    "\n",
    "    # 5 x 64 X 64 x 5 -diag-> R^5 Vector\n",
    "    self.conv_kernels_64d = nn.ParameterList([self.he(torch.randn(features, 64)) for i in range(8)])\n",
    "    self.conv_biases_64d = nn.ParameterList([torch.randn(features) for i in range(8)])\n",
    "\n",
    "    self.conv_kernel_16d = nn.Parameter(self.he(torch.randn(features, 16)))\n",
    "    self.conv_bias_16d = nn.Parameter(torch.randn(features))\n",
    "\n",
    "    self.conv_kernel_8d = nn.Parameter(self.he(torch.randn(features,8)))\n",
    "    self.conv_bias_8d = nn.Parameter(torch.randn(features))\n",
    "\n",
    "    self.four_max_pool = nn.MaxPool1d(4)\n",
    "\n",
    "    # Step 1.5\n",
    "    # self.certainty_fc_1 = nn.Parameter(torch.zeros(2,3))\n",
    "    # self.certainty_fc_2 = nn.Parameter(torch.zeros(3,1))\n",
    "\n",
    "    # Step 2\n",
    "    self.widechannel_conv_kernel = nn.Parameter(self.he(torch.randn(features, 3)))\n",
    "    self.widechannel_conv_bias = nn.Parameter(torch.randn(features))\n",
    "\n",
    "    self.midchannel_conv_kernel = nn.Parameter(self.he(torch.randn(features, 3)))\n",
    "    self.midchannel_conv_bias = nn.Parameter(torch.randn(features))\n",
    "\n",
    "    self.narrowchannel_conv_kernel = nn.Parameter(self.he(torch.randn(features, 3)))\n",
    "    self.narrowchannel_conv_bias = nn.Parameter(torch.randn(features))\n",
    "\n",
    "\n",
    "    # Step 3\n",
    "    self.pair_max_pool = nn.MaxPool1d(2)\n",
    "    # Then concat all vectors into v \\in R^24\n",
    "\n",
    "    # Step 3.5 Residual connection\n",
    "    self.__avgpool__ = nn.AvgPool1d(4, stride=4)\n",
    "\n",
    "    # Step 4\n",
    "    self.hidden_fc_1 = nn.Linear(3*4*features,3*2*features)\n",
    "    self.hidden_fc_2 = nn.Linear(3*2*features,2*features)\n",
    "\n",
    "    # Step 5\n",
    "    # LSTM\n",
    "\n",
    "    self.lstm_in_features = 2*self.features\n",
    "\n",
    "    self.lstm = nn.LSTM(self.lstm_in_features, self.lstm_hidden_state_features)\n",
    "\n",
    "    # Step 6\n",
    "    # Softmax\n",
    "\n",
    "    self.to_out_1 = nn.Linear(self.lstm_hidden_state_features, 7)\n",
    "    self.to_out_2 = nn.Linear(7, out, bias=False)\n",
    "\n",
    "    self.prob = nn.Softmax(dim=1)\n",
    "\n",
    "    for param in self.parameters():\n",
    "      if len(param.shape) >= 2:\n",
    "        param = self.he(param)\n",
    "\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    # x = Batches X Time X Channels\n",
    "\n",
    "    N = x.shape[0] # Batches\n",
    "    T = x.shape[1] # Time\n",
    "\n",
    "\n",
    "    # Step 1\n",
    "    # Cursory vision convolution\n",
    "    pad_amt = 40\n",
    "\n",
    "    pad = torch.zeros(N, pad_amt, self.features).to(device)\n",
    "\n",
    "    padded_x = torch.cat((pad, torch.cat((x, pad), dim=1)), dim=1) # catting in time\n",
    "\n",
    "    # padded_x.requires_grad = True\n",
    "\n",
    "    window_centers = [] # AKA 64d Convolve Centers\n",
    "\n",
    "    n=0 # strides\n",
    "    while(True):\n",
    "      next_center = pad_amt + 1 + n * self.stride\n",
    "      if next_center > (pad_amt + T + 1): # If our center isnt in real data\n",
    "        break;\n",
    "      else:\n",
    "        window_centers.append(next_center)\n",
    "        n += 1\n",
    "\n",
    "    window_starts = [self.start_and_end_from_center((64 - 1)/2, i)[0] for i in window_centers]\n",
    "    window_ends = [self.start_and_end_from_center((64 - 1)/2, i)[1] for i in window_centers]\n",
    "\n",
    "    midchannel_centers = []\n",
    "    narrowchannel_centers = []\n",
    "    for start in window_starts:\n",
    "      for n in range(8): # 8 strides of 8 -> 64 units\n",
    "        midchannel_centers.append(start + n * 8)\n",
    "\n",
    "      for n in range(32): # 32 strides of 2 -> 64 units\n",
    "        narrowchannel_centers.append(start + n * 2)\n",
    "\n",
    "\n",
    "    wide_convs = []\n",
    "    mid_convs = []\n",
    "    narrow_convs = []\n",
    "\n",
    "    for i in window_centers:\n",
    "      for j in range(8): # Hard coded 8 here\n",
    "        K = self.conv_kernels_64d[j]\n",
    "        B = self.conv_biases_64d[j].repeat(N,1) # Repeat here\n",
    "        conv = self.convolve(K, padded_x, i) # Features x T\n",
    "        conv += B\n",
    "        wide_convs.append(conv)\n",
    "\n",
    "    for i in midchannel_centers:\n",
    "      conv = self.convolve(self.conv_kernel_16d, padded_x, i)\n",
    "      conv += self.conv_bias_16d.repeat(N,1)\n",
    "      mid_convs.append(conv)\n",
    "\n",
    "    for i in narrowchannel_centers:\n",
    "      conv = self.convolve(self.conv_kernel_8d, padded_x, i)\n",
    "      conv += self.conv_bias_8d.repeat(N,1)\n",
    "      narrow_convs.append(conv)\n",
    "\n",
    "    wide_convs = torch.stack(wide_convs, dim=1).to(device)\n",
    "    mid_convs = torch.stack(mid_convs, dim=1).to(device)\n",
    "    narrow_convs = torch.stack(narrow_convs, dim=1).to(device)\n",
    "\n",
    "    narrow_convs = self.four_max_pool(torch.transpose(narrow_convs, 1,2)) # Inp = N x C x L now\n",
    "    narrow_convs = torch.transpose(narrow_convs,1,2) # Back to N x L x C\n",
    "\n",
    "\n",
    "    wide_convs = self.bn1(self.av(wide_convs))\n",
    "    mid_convs = self.bn1(self.av(mid_convs))\n",
    "    narrow_convs = self.bn1(self.av(narrow_convs))\n",
    "\n",
    "    residual_vectors = self.get_residual_vectors(narrow_convs, mid_convs, wide_convs)\n",
    "\n",
    "\n",
    "    wide_convs = 5 * self.drop(wide_convs)\n",
    "    mid_convs = self.drop(mid_convs)\n",
    "    narrow_convs = self.drop(narrow_convs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # convs = N x L x C\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #####\n",
    "    # STEP 1.5\n",
    "    # Compress our 5vectors to 3 vectors, combining mag and uncertainty indices\n",
    "\n",
    "    # if not (wide_convs.shape[1] == mid_convs.shape[1] == narrow_convs.shape[1]):\n",
    "    #   raise Exception(\"Step 1 output mismatch\")\n",
    "\n",
    "\n",
    "    # compacting_fc = lambda x: self.gelu(torch.matmul(self.gelu(torch.matmul(x, self.certainty_fc_1)), self.certainty_fc_2))\n",
    "\n",
    "    # wide_col_0 = compacting_fc(wide_convs[:, 0:2])\n",
    "    # wide_col_1 = compacting_fc(wide_convs[:, 2:4])\n",
    "\n",
    "    # mid_col_0 = compacting_fc(mid_convs[:, 0:2])\n",
    "    # mid_col_1 = compacting_fc(mid_convs[:, 2:4])\n",
    "\n",
    "    # narrow_col_0 = compacting_fc(mid_convs[:, 0:2])\n",
    "    # narrow_col_1 = compacting_fc(mid_convs[:, 2:4])\n",
    "\n",
    "    # wide_convs = torch.stack((wide_col_0, wide_col_1, wide_convs[:, -1].unsqueeze(1)), dim=1)\n",
    "    # mid_convs = torch.stack((mid_col_0, mid_col_1, mid_convs[:, -1].unsqueeze(1)), dim=1)\n",
    "    # narrow_convs = torch.stack((narrow_col_0, narrow_col_1, narrow_convs[:, -1].unsqueeze(1)), dim=1)\n",
    "\n",
    "    # wide_convs = wide_convs.squeeze()\n",
    "    # mid_convs = mid_convs.squeeze()\n",
    "    # narrow_convs = narrow_convs.squeeze()\n",
    "\n",
    "\n",
    "    #####\n",
    "    # STEP 2\n",
    "    # Second Convolution\n",
    "\n",
    "    pad_amt = 10\n",
    "    stride = 1\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for x in (wide_convs, mid_convs, narrow_convs):\n",
    "      T = x.shape[1]\n",
    "      ker = None\n",
    "      bias = None\n",
    "      if len(results) == 0:\n",
    "        ker = self.widechannel_conv_kernel\n",
    "        bias = self.widechannel_conv_bias.repeat(N, 1)\n",
    "\n",
    "      elif len(results) == 1:\n",
    "        ker = self.midchannel_conv_kernel\n",
    "        bias = self.midchannel_conv_bias.repeat(N, 1)\n",
    "\n",
    "      elif len(results) == 2:\n",
    "        ker = self.narrowchannel_conv_kernel\n",
    "        bias = self.narrowchannel_conv_bias.repeat(N, 1)\n",
    "\n",
    "\n",
    "      pad = torch.zeros(N, pad_amt, self.features).to(device)\n",
    "      padded_x = torch.cat((pad, torch.cat((x, pad), dim=1)), dim=1)\n",
    "\n",
    "\n",
    "      result = []\n",
    "\n",
    "      next = pad_amt\n",
    "      while next <= (pad_amt + T - 1):\n",
    "        v = bias + self.convolve(ker, padded_x, next)\n",
    "        result.append(v)\n",
    "        next += stride\n",
    "\n",
    "\n",
    "      results.append(torch.stack(result, dim=1))\n",
    "\n",
    "\n",
    "    wide_convs = self.bn2(self.av(results[0]))\n",
    "    mid_convs = self.bn2(self.av(results[1]))\n",
    "    narrow_convs = self.bn2(self.av(results[2]))\n",
    "\n",
    "    wide_convs = self.drop(wide_convs)\n",
    "    mid_convs = self.drop(mid_convs)\n",
    "    narrow_convs = self.drop(narrow_convs)\n",
    "\n",
    "\n",
    "\n",
    "    ####\n",
    "    # Step 2.5\n",
    "    # Max Pooling Pairs\n",
    "    wide_convs = self.pair_max_pool(torch.transpose(wide_convs, 1,2)) # to N x C x L\n",
    "    mid_convs = self.pair_max_pool(torch.transpose(mid_convs, 1,2))\n",
    "    narrow_convs = self.pair_max_pool(torch.transpose(narrow_convs, 1,2))\n",
    "\n",
    "    wide_convs = torch.transpose(wide_convs, 1,2) # to N x L x C\n",
    "    mid_convs = torch.transpose(mid_convs, 1,2)\n",
    "    narrow_convs = torch.transpose(narrow_convs, 1,2)\n",
    "\n",
    "\n",
    "    ####\n",
    "    # Step 3\n",
    "\n",
    "    # Now each original window reigon is each corresponding 2 rows from all 3 tensors\n",
    "    # 2 rows evenly divides all possible resulting lengths\n",
    "\n",
    "    if not (wide_convs.shape[1] == mid_convs.shape[1] == narrow_convs.shape[1]):\n",
    "      raise Exception(\"Step 3 output mismatch\")\n",
    "\n",
    "\n",
    "    hidden = []\n",
    "    L = wide_convs.shape[1]\n",
    "\n",
    "    for n in range(L // 4): # Now each sliding window corresponds to 2 rows\n",
    "      wide = wide_convs[:, 4*n:4*n + 4].reshape(N, 4*self.features)\n",
    "      mid = mid_convs[:, 4*n:4*n + 4].reshape(N, 4*self.features)\n",
    "      narrow = narrow_convs[:, 4*n:4*n + 4].reshape(N, 4*self.features)\n",
    "\n",
    "      flat = torch.cat((wide, mid, narrow), dim=1).to(device)\n",
    "      if flat.shape[0] != N or flat.shape[1] != 3*4*self.features:\n",
    "        raise Exception(\"Flat shape err\")\n",
    "\n",
    "      layer_1 = self.hidden_fc_1(flat)\n",
    "      layer_1 = self.av(layer_1)\n",
    "\n",
    "      # RESIDUAL CONNECTION !\n",
    "      res = torch.autograd.Variable(self.residual * residual_vectors[n])\n",
    "      layer_1 = (1-self.residual) * layer_1\n",
    "      layer_1 = layer_1 + res\n",
    "\n",
    "\n",
    "      layer_2 = self.hidden_fc_2(layer_1)\n",
    "      layer_2 = self.av(layer_2)\n",
    "\n",
    "      hidden.append(layer_2)\n",
    "\n",
    "\n",
    "    hidden = torch.stack(hidden, dim=0) # Results in L x N x Hidden\n",
    "\n",
    "    hidden = self.drop(hidden)\n",
    "\n",
    "\n",
    "    ####\n",
    "    # Step 6: LSTM\n",
    "\n",
    "    _, (final_hidden_state, c_n) = self.lstm(hidden)\n",
    "\n",
    "    final_hidden_state = self.av(final_hidden_state.squeeze())\n",
    "    final_hidden_state = self.bn3(final_hidden_state)\n",
    "\n",
    "    final_hidden_state = self.drop(final_hidden_state)\n",
    "\n",
    "\n",
    "    final_layer = self.to_out_1(final_hidden_state)\n",
    "    final_layer = self.av(final_layer)\n",
    "\n",
    "    final_layer = self.drop(final_layer)\n",
    "\n",
    "    final_layer = self.to_out_2(final_layer)\n",
    "\n",
    "    classes = self.prob(final_layer)\n",
    "\n",
    "\n",
    "    return F.log_softmax(final_layer, dim=1)\n",
    "\n",
    "\n",
    "  def start_and_end_from_center(self, width, i):\n",
    "    start = i - np.ceil(width)\n",
    "    end = i + np.floor(width) + 1\n",
    "    return (int(start), int(end))\n",
    "\n",
    "\n",
    "\n",
    "  def convolve(self, Kernel, Data, i):\n",
    "\n",
    "    # i is center index so we take equal on either side\n",
    "    T = Kernel.shape[1]\n",
    "    each_side = (T - 1) / 2\n",
    "\n",
    "    # Moves it backwards 1 if kernel is even\n",
    "    start, end = self.start_and_end_from_center(each_side, i)\n",
    "\n",
    "    adj_data = Data[:, start:end, :]\n",
    "\n",
    "    # So now K is 5 x L and adj_data is N x L X 5\n",
    "\n",
    "\n",
    "    N = adj_data.shape[0]\n",
    "\n",
    "    m = torch.bmm(Kernel.repeat(N,1,1), adj_data) # bij, bjk -> bik Slightly faster than einsum\n",
    "\n",
    "    # m = torch.einsum(\"ij, bjk -> bik\", Kernel, adj_data) #identical batch matmul\n",
    "\n",
    "    diag = torch.einsum(\"bii->bi\", m)\n",
    "    # diags = []\n",
    "    # for res in m:\n",
    "    #   diags.append(torch.diag(res))\n",
    "\n",
    "\n",
    "    return diag\n",
    "\n",
    "  def get_residual_vectors(self, narrow, mid, wide):\n",
    "    # Should be N x 8m x Features\n",
    "    # print(narrow.shape, mid.shape, wide.shape)\n",
    "    N = wide.shape[0]\n",
    "    L = wide.shape[1]\n",
    "\n",
    "    apply_avg = lambda matrix: torch.transpose(self.__avgpool__(torch.transpose(matrix, 1,2)), 1,2)\n",
    "\n",
    "    vectors = []\n",
    "\n",
    "    if L % 8:\n",
    "      raise Exception(\"Something went wrong, convs are not mult of 8\")\n",
    "    for i in range(L // 8):\n",
    "\n",
    "      n = torch.autograd.Variable(narrow[:, 8*i:8*(i+1), :])\n",
    "      m = torch.autograd.Variable(mid[:, 8*i:8*(i+1), :])\n",
    "      w = torch.autograd.Variable(wide[:, 8*i:8*(i+1), :])\n",
    "\n",
    "      n = apply_avg(n)\n",
    "      m = apply_avg(m)\n",
    "      w = apply_avg(w)\n",
    "\n",
    "      n = n.reshape(N, 2*self.features)\n",
    "      m = m.reshape(N, 2*self.features)\n",
    "      w = w.reshape(N, 2*self.features)\n",
    "      # gives N x 2 * Features\n",
    "\n",
    "      vectors.append(torch.autograd.Variable(torch.cat((n,m,w), dim=1))) # N x 6 * features\n",
    "\n",
    "    return vectors\n",
    "\n",
    "class FluxAnomalyPredictionTF(nn.Module):\n",
    "  def __init__(self, stride, dropout, bn=False, features=3, residual=0, out=4):\n",
    "    super().__init__()\n",
    "\n",
    "    self.stride = stride\n",
    "    self.features = features\n",
    "    self.residual = residual\n",
    "    self.transformer_hidden_dim = 2*features # Needed for batchnorm 3, so defined here\n",
    "\n",
    "    # Need Dropouts, Activation fns\n",
    "    self.he = lambda x: nn.init.kaiming_normal_(x, nonlinearity='relu')\n",
    "    self.av = nn.ReLU()\n",
    "    self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    self.batchnorm1 = lambda x: x\n",
    "    self.batchnorm2 = lambda x: x\n",
    "    self.batchnorm3 = lambda x: x\n",
    "\n",
    "    if bn:\n",
    "      self.batchnorm1 = nn.BatchNorm1d(features)\n",
    "      self.batchnorm2 = nn.BatchNorm1d(features)\n",
    "      self.batchnorm3 = nn.BatchNorm1d(self.transformer_hidden_dim)\n",
    "\n",
    "      self.bn1 = lambda x: torch.transpose(self.batchnorm1(torch.transpose(x,1,2)),1,2)\n",
    "      self.bn2 = lambda x: torch.transpose(self.batchnorm2(torch.transpose(x,1,2)),1,2)\n",
    "      self.bn3 = lambda x: self.batchnorm3(x)\n",
    "    else:\n",
    "      self.bn1 = lambda x: x\n",
    "      self.bn2 = lambda x: x\n",
    "      self.bn3 = lambda x: x\n",
    "\n",
    "\n",
    "    # Step 1\n",
    "\n",
    "    # 5 x 64 X 64 x 5 -diag-> R^5 Vector\n",
    "    self.conv_kernels_64d = nn.ParameterList([self.he(torch.randn(features, 64)) for i in range(8)])\n",
    "    self.conv_biases_64d = nn.ParameterList([torch.randn(features) for i in range(8)])\n",
    "\n",
    "    self.conv_kernel_16d = nn.Parameter(self.he(torch.randn(features, 16)))\n",
    "    self.conv_bias_16d = nn.Parameter(torch.randn(features))\n",
    "\n",
    "    self.conv_kernel_8d = nn.Parameter(self.he(torch.randn(features,8)))\n",
    "    self.conv_bias_8d = nn.Parameter(torch.randn(features))\n",
    "\n",
    "    self.four_max_pool = nn.MaxPool1d(4)\n",
    "\n",
    "    # Step 1.5\n",
    "    # self.certainty_fc_1 = nn.Parameter(torch.zeros(2,3))\n",
    "    # self.certainty_fc_2 = nn.Parameter(torch.zeros(3,1))\n",
    "\n",
    "    # Step 2\n",
    "    self.widechannel_conv_kernel = nn.Parameter(self.he(torch.randn(features, 3)))\n",
    "    self.widechannel_conv_bias = nn.Parameter(torch.randn(features))\n",
    "\n",
    "    self.midchannel_conv_kernel = nn.Parameter(self.he(torch.randn(features, 3)))\n",
    "    self.midchannel_conv_bias = nn.Parameter(torch.randn(features))\n",
    "\n",
    "    self.narrowchannel_conv_kernel = nn.Parameter(self.he(torch.randn(features, 3)))\n",
    "    self.narrowchannel_conv_bias = nn.Parameter(torch.randn(features))\n",
    "\n",
    "\n",
    "    # Step 3\n",
    "    self.pair_max_pool = nn.MaxPool1d(2)\n",
    "    # Then concat all vectors into v \\in R^24\n",
    "\n",
    "    # Step 3.5 Residual connection\n",
    "    self.__avgpool__ = nn.AvgPool1d(4, stride=4)\n",
    "\n",
    "    # Step 4\n",
    "    self.hidden_fc_1 = nn.Linear(3*4*features, 3*2*features)\n",
    "    self.hidden_fc_2 = nn.Linear(3*2*features, self.transformer_hidden_dim)\n",
    "\n",
    "    # Step 5\n",
    "    # Transformer\n",
    "    self.transformer_encoder_layer = nn.TransformerEncoderLayer(d_model=self.transformer_hidden_dim, nhead=self.features)\n",
    "    self.transformer_encoder = nn.TransformerEncoder(self.transformer_encoder_layer, 2)\n",
    "\n",
    "\n",
    "    # Step 6\n",
    "    # Softmax\n",
    "\n",
    "    self.to_out_1 = nn.Linear(self.transformer_hidden_dim, 7)\n",
    "    self.to_out_2 = nn.Linear(7, out, bias=False)\n",
    "\n",
    "    self.prob = nn.Softmax(dim=1)\n",
    "\n",
    "    for param in self.parameters():\n",
    "      if len(param.shape) >= 2:\n",
    "        param = self.he(param)\n",
    "\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    # x = Batches X Time X Channels\n",
    "\n",
    "    N = x.shape[0] # Batches\n",
    "    T = x.shape[1] # Time\n",
    "\n",
    "    if x.shape[2] != self.features:\n",
    "      raise Exception(\"Feature dimension mismatch\")\n",
    "\n",
    "    # Step 1\n",
    "    # Cursory vision convolution\n",
    "    pad_amt = 40\n",
    "\n",
    "    pad = torch.zeros(N, pad_amt, self.features).to(device)\n",
    "  \n",
    "\n",
    "    padded_x = torch.cat((pad, torch.cat((x, pad), dim=1)), dim=1) # catting in time\n",
    "\n",
    "    # padded_x.requires_grad = True\n",
    "\n",
    "    window_centers = [] # AKA 64d Convolve Centers\n",
    "\n",
    "    n=0 # strides\n",
    "    while(True):\n",
    "      next_center = pad_amt + 1 + n * self.stride\n",
    "      if next_center > (pad_amt + T + 1): # If our center isnt in real data\n",
    "        break;\n",
    "      else:\n",
    "        window_centers.append(next_center)\n",
    "        n += 1\n",
    "\n",
    "    window_starts = [self.start_and_end_from_center((64 - 1)/2, i)[0] for i in window_centers]\n",
    "    window_ends = [self.start_and_end_from_center((64 - 1)/2, i)[1] for i in window_centers]\n",
    "\n",
    "    midchannel_centers = []\n",
    "    narrowchannel_centers = []\n",
    "    for start in window_starts:\n",
    "      for n in range(8): # 8 strides of 8 -> 64 units\n",
    "        midchannel_centers.append(start + n * 8)\n",
    "\n",
    "      for n in range(32): # 32 strides of 2 -> 64 units\n",
    "        narrowchannel_centers.append(start + n * 2)\n",
    "\n",
    "\n",
    "    wide_convs = []\n",
    "    mid_convs = []\n",
    "    narrow_convs = []\n",
    "\n",
    "    for i in window_centers:\n",
    "      for j in range(8): # Hard coded 8 here\n",
    "        K = self.conv_kernels_64d[j]\n",
    "        B = self.conv_biases_64d[j].repeat(N,1) # Repeat here\n",
    "        conv = self.convolve(K, padded_x, i) # Features x T\n",
    "        conv += B\n",
    "        wide_convs.append(conv)\n",
    "\n",
    "    for i in midchannel_centers:\n",
    "      conv = self.convolve(self.conv_kernel_16d, padded_x, i)\n",
    "      conv += self.conv_bias_16d.repeat(N,1)\n",
    "      mid_convs.append(conv)\n",
    "\n",
    "    for i in narrowchannel_centers:\n",
    "      conv = self.convolve(self.conv_kernel_8d, padded_x, i)\n",
    "      conv += self.conv_bias_8d.repeat(N,1)\n",
    "      narrow_convs.append(conv)\n",
    "\n",
    "    wide_convs = torch.stack(wide_convs, dim=1).to(device)\n",
    "    mid_convs = torch.stack(mid_convs, dim=1).to(device)\n",
    "    narrow_convs = torch.stack(narrow_convs, dim=1).to(device)\n",
    "\n",
    "    narrow_convs = self.four_max_pool(torch.transpose(narrow_convs, 1,2)) # Inp = N x C x L now\n",
    "    narrow_convs = torch.transpose(narrow_convs,1,2) # Back to N x L x C\n",
    "\n",
    "\n",
    "    wide_convs = self.bn1(self.av(wide_convs))\n",
    "    mid_convs = self.bn1(self.av(mid_convs))\n",
    "    narrow_convs = self.bn1(self.av(narrow_convs))\n",
    "\n",
    "    residual_vectors = self.get_residual_vectors(narrow_convs, mid_convs, wide_convs)\n",
    "\n",
    "\n",
    "    wide_convs = 5 * self.drop(wide_convs)\n",
    "    mid_convs = self.drop(mid_convs)\n",
    "    narrow_convs = self.drop(narrow_convs)\n",
    "\n",
    "\n",
    "\n",
    "    #####\n",
    "    # STEP 2\n",
    "    # Second Convolution\n",
    "\n",
    "    pad_amt = 10\n",
    "    stride = 1\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for x in (wide_convs, mid_convs, narrow_convs):\n",
    "      T = x.shape[1]\n",
    "      ker = None\n",
    "      bias = None\n",
    "      if len(results) == 0:\n",
    "        ker = self.widechannel_conv_kernel\n",
    "        bias = self.widechannel_conv_bias.repeat(N, 1)\n",
    "\n",
    "      elif len(results) == 1:\n",
    "        ker = self.midchannel_conv_kernel\n",
    "        bias = self.midchannel_conv_bias.repeat(N, 1)\n",
    "\n",
    "      elif len(results) == 2:\n",
    "        ker = self.narrowchannel_conv_kernel\n",
    "        bias = self.narrowchannel_conv_bias.repeat(N, 1)\n",
    "\n",
    "\n",
    "      pad = torch.zeros(N, pad_amt, self.features).to(device)\n",
    "      padded_x = torch.cat((pad, torch.cat((x, pad), dim=1)), dim=1)\n",
    "\n",
    "\n",
    "      result = []\n",
    "\n",
    "      next = pad_amt\n",
    "      while next <= (pad_amt + T - 1):\n",
    "        v = bias + self.convolve(ker, padded_x, next)\n",
    "        result.append(v)\n",
    "        next += stride\n",
    "\n",
    "\n",
    "      results.append(torch.stack(result, dim=1))\n",
    "\n",
    "\n",
    "    wide_convs = self.bn2(self.av(results[0]))\n",
    "    mid_convs = self.bn2(self.av(results[1]))\n",
    "    narrow_convs = self.bn2(self.av(results[2]))\n",
    "\n",
    "    wide_convs = self.drop(wide_convs)\n",
    "    mid_convs = self.drop(mid_convs)\n",
    "    narrow_convs = self.drop(narrow_convs)\n",
    "\n",
    "\n",
    "\n",
    "    ####\n",
    "    # Step 2.5\n",
    "    # Max Pooling Pairs\n",
    "    wide_convs = self.pair_max_pool(torch.transpose(wide_convs, 1,2)) # to N x C x L\n",
    "    mid_convs = self.pair_max_pool(torch.transpose(mid_convs, 1,2))\n",
    "    narrow_convs = self.pair_max_pool(torch.transpose(narrow_convs, 1,2))\n",
    "\n",
    "    wide_convs = torch.transpose(wide_convs, 1,2) # to N x L x C\n",
    "    mid_convs = torch.transpose(mid_convs, 1,2)\n",
    "    narrow_convs = torch.transpose(narrow_convs, 1,2)\n",
    "\n",
    "\n",
    "    ####\n",
    "    # Step 3\n",
    "\n",
    "    # Now each original window reigon is each corresponding 2 rows from all 3 tensors\n",
    "    # 2 rows evenly divides all possible resulting lengths\n",
    "\n",
    "    if not (wide_convs.shape[1] == mid_convs.shape[1] == narrow_convs.shape[1]):\n",
    "      raise Exception(\"Step 3 output mismatch\")\n",
    "\n",
    "\n",
    "    hidden = []\n",
    "    L = wide_convs.shape[1]\n",
    "\n",
    "    for n in range(L // 4): # Now each sliding window corresponds to 2 rows\n",
    "      wide = wide_convs[:, 4*n:4*n + 4].reshape(N, 4*self.features)\n",
    "      mid = mid_convs[:, 4*n:4*n + 4].reshape(N, 4*self.features)\n",
    "      narrow = narrow_convs[:, 4*n:4*n + 4].reshape(N, 4*self.features)\n",
    "\n",
    "      flat = torch.cat((wide, mid, narrow), dim=1).to(device)\n",
    "      if flat.shape[0] != N or flat.shape[1] != 3*4*self.features:\n",
    "        raise Exception(\"Flat shape err\")\n",
    "\n",
    "      layer_1 = self.hidden_fc_1(flat)\n",
    "      layer_1 = self.av(layer_1)\n",
    "\n",
    "      # RESIDUAL CONNECTION !\n",
    "      res = torch.autograd.Variable(self.residual * residual_vectors[n])\n",
    "      layer_1 = (1-self.residual) * layer_1\n",
    "      layer_1 = layer_1 + res\n",
    "\n",
    "      layer_2 = self.hidden_fc_2(layer_1)\n",
    "      layer_2 = self.av(layer_2)\n",
    "\n",
    "      hidden.append(layer_2)\n",
    "\n",
    "    hidden = torch.stack(hidden, dim=0) # Results in (Divided L) x N x Hidden\n",
    "    hidden = self.drop(hidden)\n",
    "\n",
    "\n",
    "    seq = self.transformer_encoder(hidden) # same shape as hidden\n",
    "\n",
    "\n",
    "\n",
    "    transformed = nn.AvgPool1d(seq.shape[0])(torch.transpose(seq,0,2)) # Pooling happens on last dim\n",
    "    transformed = torch.squeeze(transformed, dim=2)\n",
    "    transformed = torch.transpose(transformed, 0, 1) # Should be N x Hidden\n",
    "\n",
    "    transformed = self.av(transformed)\n",
    "    transformed = self.bn3(transformed)\n",
    "    transformed = self.drop(transformed)\n",
    "\n",
    "    final_layer = self.to_out_1(transformed)\n",
    "    final_layer = self.av(final_layer)\n",
    "    final_layer = self.drop(final_layer)\n",
    "    final_layer = self.to_out_2(final_layer)\n",
    "\n",
    "    # classes = self.prob(final_layer) # Dont use, use CEL instead\n",
    "\n",
    "    return F.log_softmax(final_layer, dim=1)\n",
    "\n",
    "\n",
    "  def start_and_end_from_center(self, width, i):\n",
    "    start = i - np.ceil(width)\n",
    "    end = i + np.floor(width) + 1\n",
    "    return (int(start), int(end))\n",
    "\n",
    "\n",
    "\n",
    "  def convolve(self, Kernel, Data, i):\n",
    "\n",
    "    # i is center index so we take equal on either side\n",
    "    T = Kernel.shape[1]\n",
    "    each_side = (T - 1) / 2\n",
    "\n",
    "    # Moves it backwards 1 if kernel is even\n",
    "    start, end = self.start_and_end_from_center(each_side, i)\n",
    "\n",
    "    adj_data = Data[:, start:end, :]\n",
    "\n",
    "    # So now K is 5 x L and adj_data is N x L X 5\n",
    "\n",
    "\n",
    "    N = adj_data.shape[0]\n",
    "\n",
    "    m = torch.bmm(Kernel.repeat(N,1,1), adj_data) # bij, bjk -> bik Slightly faster than einsum\n",
    "\n",
    "    # m = torch.einsum(\"ij, bjk -> bik\", Kernel, adj_data) #identical batch matmul\n",
    "\n",
    "    diag = torch.einsum(\"bii->bi\", m)\n",
    "    # diags = []\n",
    "    # for res in m:\n",
    "    #   diags.append(torch.diag(res))\n",
    "\n",
    "\n",
    "    return diag\n",
    "\n",
    "  def get_residual_vectors(self, narrow, mid, wide):\n",
    "    # Should be N x 8m x Features\n",
    "    # print(narrow.shape, mid.shape, wide.shape)\n",
    "    N = wide.shape[0]\n",
    "    L = wide.shape[1]\n",
    "\n",
    "    apply_avg = lambda matrix: torch.transpose(self.__avgpool__(torch.transpose(matrix, 1,2)), 1,2)\n",
    "\n",
    "    vectors = []\n",
    "\n",
    "    if L % 8:\n",
    "      raise Exception(\"Something went wrong, convs are not mult of 8\")\n",
    "    for i in range(L // 8):\n",
    "\n",
    "      n = torch.autograd.Variable(narrow[:, 8*i:8*(i+1), :])\n",
    "      m = torch.autograd.Variable(mid[:, 8*i:8*(i+1), :])\n",
    "      w = torch.autograd.Variable(wide[:, 8*i:8*(i+1), :])\n",
    "\n",
    "      n = apply_avg(n)\n",
    "      m = apply_avg(m)\n",
    "      w = apply_avg(w)\n",
    "\n",
    "      n = n.reshape(N, 2*self.features)\n",
    "      m = m.reshape(N, 2*self.features)\n",
    "      w = w.reshape(N, 2*self.features)\n",
    "      # gives N x 2 * Features\n",
    "\n",
    "      vectors.append(torch.autograd.Variable(torch.cat((n,m,w), dim=1))) # N x 6 * features\n",
    "\n",
    "    return vectors\n",
    "\n",
    "class lstm(nn.Module):\n",
    "  def __init__(self, into, hidden, out):\n",
    "    super().__init__()\n",
    "\n",
    "    self.rl = nn.functional.sigmoid\n",
    "    self.ls = nn.LSTM(into, hidden, batch_first=True)\n",
    "    self.to_out = nn.Linear(hidden,out)\n",
    "    self.prob = nn.Softmax(dim=1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    _, (f, __) = self.ls(x)\n",
    "\n",
    "    return self.to_out(f.squeeze())\n",
    "\n",
    "class lstm2(nn.Module):\n",
    "  def __init__(self, into, hidden, out):\n",
    "    super().__init__()\n",
    "\n",
    "    self.rl = nn.functional.sigmoid\n",
    "    self.ls = nn.LSTM(into, hidden, batch_first=True, num_layers=2)\n",
    "    self.to_out = nn.Linear(hidden,out)\n",
    "    self.prob = nn.Softmax(dim=1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    _, (f, __) = self.ls(x)\n",
    "\n",
    "    return self.to_out(f[1, :].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1698123021980,
     "user": {
      "displayName": "Matteo",
      "userId": "07662895649750931658"
     },
     "user_tz": 420
    },
    "id": "QCaXFn0b4T4E",
    "outputId": "046486bb-7ddf-4d47-ff86-8c8da5e3c5eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82997\n"
     ]
    }
   ],
   "source": [
    "model = FluxAnomalyPredictionTF(50, 0.15, bn=False, features=3, residual=0).to(device)\n",
    "\n",
    "model_pars = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_pars])\n",
    "\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 202,
     "status": "ok",
     "timestamp": 1698123023002,
     "user": {
      "displayName": "Matteo",
      "userId": "07662895649750931658"
     },
     "user_tz": 420
    },
    "id": "BOJnl8dTJEoi",
    "outputId": "4aa465eb-c350-44e1-9ba4-8fb3b276d6dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([480, 1000, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = DataLoader(data_train, batch_size=len(data_train), shuffle=True, collate_fn=padded_collate)\n",
    "valid = DataLoader(data_valid, batch_size=len(data_valid), shuffle=True, collate_fn=padded_collate)\n",
    "next(iter(train))[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XX8cN71g14oT"
   },
   "source": [
    "# Training Loop (Single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DmGh2Yd4kclP"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "blue"
         },
         "mode": "lines",
         "name": "Training Loss",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "y": [
          1.8568816184997559,
          1.8768774271011353,
          1.4243676662445068
         ]
        },
        {
         "line": {
          "color": "orange"
         },
         "mode": "lines",
         "name": "Validation Loss",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "y": [
          1.7597745656967163,
          1.38139808177948,
          1.3911495208740234
         ]
        },
        {
         "line": {
          "color": "gray"
         },
         "mode": "lines",
         "name": "Null Accuracy",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "y": [
          0,
          0,
          0.9999999090909174
         ]
        },
        {
         "line": {
          "color": "yellow"
         },
         "mode": "lines",
         "name": "Nova Accuracy",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "y": [
          0,
          0,
          0
         ]
        },
        {
         "line": {
          "color": "green"
         },
         "mode": "lines",
         "name": "Pulsator Accuracy",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "y": [
          0.9999992857147959,
          0.9999992857147959,
          0
         ]
        },
        {
         "line": {
          "color": "purple"
         },
         "mode": "lines",
         "name": "Transit Accuracy",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "y": [
          0,
          0,
          0
         ]
        },
        {
         "line": {
          "color": "red"
         },
         "mode": "lines",
         "name": "Total Validation Accuracy",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "y": [
          0.2916666666666667,
          0.2916666666666667,
          0.22916666666666666
         ]
        }
       ],
       "layout": {
        "legend": {
         "x": 1,
         "xanchor": "right",
         "y": 1,
         "yanchor": "top"
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Training and Validation Loss Over Epochs: 2/100"
        },
        "xaxis": {
         "linecolor": "black",
         "linewidth": 1,
         "mirror": true,
         "range": [
          0,
          100
         ],
         "showline": true,
         "tickfont": {
          "size": 12
         },
         "title": {
          "text": "Epochs"
         }
        },
        "yaxis": {
         "linecolor": "black",
         "linewidth": 1,
         "mirror": true,
         "range": [
          0,
          2
         ],
         "showline": true,
         "tickfont": {
          "size": 12
         },
         "title": {
          "text": "Loss"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 :  1.4243676662445068\n",
      "nulls: 0.9999999090909174 novas:  0.0 pulsators:  0.0 transits:  0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data, label \u001b[38;5;129;01min\u001b[39;00m train:\n\u001b[1;32m     45\u001b[0m   model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 46\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m   loss \u001b[38;5;241m=\u001b[39m loss_fn(out, label)\n\u001b[1;32m     50\u001b[0m   epoch_loss\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[4], line 691\u001b[0m, in \u001b[0;36mFluxAnomalyPredictionTF.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    687\u001b[0m hidden \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(hidden, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# Results in (Divided L) x N x Hidden\u001b[39;00m\n\u001b[1;32m    688\u001b[0m hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop(hidden)\n\u001b[0;32m--> 691\u001b[0m seq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# same shape as hidden\u001b[39;00m\n\u001b[1;32m    695\u001b[0m transformed \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mAvgPool1d(seq\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])(torch\u001b[38;5;241m.\u001b[39mtranspose(seq,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m)) \u001b[38;5;66;03m# Pooling happens on last dim\u001b[39;00m\n\u001b[1;32m    696\u001b[0m transformed \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqueeze(transformed, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/torch/nn/modules/transformer.py:306\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    303\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m make_causal\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 306\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    309\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/torch/nn/modules/transformer.py:574\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    573\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sa_block(x, src_mask, src_key_padding_mask))\n\u001b[0;32m--> 574\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ff_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/torch/nn/modules/transformer.py:589\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._ff_block\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ff_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 589\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear2(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout2(x)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/torch/nn/modules/dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/torch/nn/functional.py:1249\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;124;03mDuring training, randomly zeroes some of the elements of the input\u001b[39;00m\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;124;03mtensor with probability :attr:`p` using samples from a Bernoulli\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;124;03m    inplace: If set to ``True``, will do this operation in-place. Default: ``False``\u001b[39;00m\n\u001b[1;32m   1247\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m-> 1249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(p))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/torch/overrides.py:1534\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_torch_function_mode_enabled():\n\u001b[1;32m   1531\u001b[0m     \u001b[38;5;66;03m# if we're here, the mode must be set to a TorchFunctionStackMode\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m     \u001b[38;5;66;03m# this unsets it and calls directly into TorchFunctionStackMode's torch function\u001b[39;00m\n\u001b[1;32m   1533\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _pop_mode_temporarily() \u001b[38;5;28;01mas\u001b[39;00m mode:\n\u001b[0;32m-> 1534\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mmode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1535\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1536\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/torch/utils/_device.py:62\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/torch/nn/functional.py:1252\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(p))\n\u001b[0;32m-> 1252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "lr = 0.005\n",
    "\n",
    "resolution = 20\n",
    "dropout = 0.15\n",
    "batchnorm = False\n",
    "features = 3\n",
    "residual = 0\n",
    "\n",
    "model = FluxAnomalyPredictionTF(resolution, dropout, bn=batchnorm, features=features, residual=residual).to(device)\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "progress_bar = tqdm(total=EPOCHS, desc=\"Training Progress\")\n",
    "\n",
    "trainloss = []\n",
    "validloss = []\n",
    "\n",
    "nullts = []\n",
    "novats = []\n",
    "pulsatingts = []\n",
    "transitts = []\n",
    "accuracyts = []\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "  epoch_loss = []\n",
    "  valid_loss = []\n",
    "\n",
    "  null_correct = 0\n",
    "  nova_correct = 0\n",
    "  pulsating_correct = 0\n",
    "  transit_correct = 0\n",
    "  correct = 0\n",
    "\n",
    "\n",
    "  novas = 0\n",
    "  pulsators = 0\n",
    "  transits = 0\n",
    "  nulls = 0\n",
    "  exs = 0\n",
    "\n",
    "  for data, label in train:\n",
    "\n",
    "    model.train()\n",
    "    out = model(data)\n",
    "\n",
    "    loss = loss_fn(out, label)\n",
    "\n",
    "    epoch_loss.append(loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    optim.zero_grad()\n",
    "\n",
    "\n",
    "  for data, label in valid:\n",
    "    model.eval()\n",
    "    out = model(data)\n",
    "    loss = loss_fn(out, label)\n",
    "    valid_loss.append(loss.item())\n",
    "    i = torch.argmax(out, dim=1).cpu()\n",
    "    j = torch.argmax(label, dim=1).cpu()\n",
    "\n",
    "    for idx, jdx in zip(i,j):\n",
    "      exs += 1\n",
    "      if idx == jdx:\n",
    "        correct += 1\n",
    "\n",
    "      if jdx == 0:\n",
    "        nulls += 1\n",
    "        if idx == jdx:\n",
    "          null_correct += 1\n",
    "\n",
    "      if jdx == 1:\n",
    "        novas += 1\n",
    "        if idx == jdx:\n",
    "          nova_correct +=1\n",
    "      if jdx == 2:\n",
    "        pulsators += 1\n",
    "        if idx == jdx:\n",
    "          pulsating_correct +=1\n",
    "      if jdx == 3:\n",
    "        transits += 1\n",
    "        if idx == jdx:\n",
    "          transit_correct +=1\n",
    "\n",
    "  training_loss_epoch = np.mean(epoch_loss)\n",
    "  validation_loss_epoch = np.mean(valid_loss)\n",
    "\n",
    "  nullac = null_correct / (nulls + 0.000001)\n",
    "  novacc = nova_correct / (novas + 0.000001)\n",
    "  pulsatoracc = pulsating_correct / (pulsators + 0.00001)\n",
    "  transitacc = transit_correct / (transits + 0.00001)\n",
    "  accuracy = correct / exs\n",
    "\n",
    "  trainloss.append(training_loss_epoch)\n",
    "  validloss.append(validation_loss_epoch)\n",
    "\n",
    "  nullts.append(nullac)\n",
    "  novats.append(novacc)\n",
    "  pulsatingts.append(pulsatoracc)\n",
    "  transitts.append(transitacc)\n",
    "  accuracyts.append(accuracy)\n",
    "\n",
    "\n",
    "  progress_bar.update(1)\n",
    "  p = getprogressplot(trainloss, validloss, accuracyts, nullts, novats, pulsatingts, transitts, EPOCHS, e)\n",
    "  clear_output(wait=False)\n",
    "  display(p)\n",
    "\n",
    "  print(\"Epoch \", e, \": \", training_loss_epoch)\n",
    "  print(\"nulls:\", nullac, \"novas: \", novacc, \"pulsators: \", pulsatoracc, \"transits: \", transitacc)\n",
    "\n",
    "x = range(EPOCHS)\n",
    "\n",
    "p = getprogressplot(trainloss, validloss, accuracyts, nullts, novats, pulsatingts, transitts, EPOCHS, e)\n",
    "clear_output(wait=True)\n",
    "display(p)\n",
    "print(\"Epoch \", e, \": \", training_loss_epoch)\n",
    "\n",
    "savestr = \"state_dicts/model\" + str(np.random.randint(1111,9999))\n",
    "with open(ROOT + savestr + \".pt\", \"wb\") as f:\n",
    "  torch.save(model.state_dict(),f)\n",
    "\n",
    "with open(ROOT + savestr + \".pkl\", \"wb\") as f:\n",
    "  pickle.dump(dict(resolution=resolution, dropout=dropout, batchnorm=batchnorm, features=features, residual=residual), f)\n",
    "\n",
    "\n",
    "print(\"saved as {}\".format(savestr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(model.parameters(), lr=0.007)\n",
    "compete([(\"TF\", model, optim)], 150, train, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "qPbsgAA7OIXE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-11-20 21:32:47 73762:31109620 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-11-20 21:32:55 73762:31109620 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-11-20 21:32:55 73762:31109620 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                     dd         4.75%     194.411ms       100.00%        4.093s        4.093s             1  \n",
      "                                            aten::empty         0.11%       4.442ms         0.11%       4.442ms       0.429us         10346  \n",
      "                                          aten::random_         0.00%       5.000us         0.00%       5.000us       2.500us             2  \n",
      "                                             aten::item         0.00%       6.000us         0.00%       7.000us       3.500us             2  \n",
      "                              aten::_local_scalar_dense         0.00%       1.000us         0.00%       1.000us       0.500us             2  \n",
      "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...         0.01%     456.000us         0.15%       6.232ms       6.232ms             1  \n",
      "                                         aten::randperm         0.00%      20.000us         0.00%      35.000us      17.500us             2  \n",
      "                                    aten::scalar_tensor         0.00%       1.000us         0.00%       1.000us       1.000us             1  \n",
      "                                          aten::resize_         0.00%       5.000us         0.00%       5.000us       0.833us             6  \n",
      "                                     aten::resolve_conj         0.00%     159.000us         0.00%     159.000us       0.000us        666008  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 4.093s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = FluxAnomalyPredictionTF(32, 0.1).to(device)\n",
    "\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "    with record_function(\"dd\"):\n",
    "        ex = next(iter(train))\n",
    "        out = model(ex[0])\n",
    "        loss = loss_fn(out, ex[1])\n",
    "        loss.backward()\n",
    "        # for name, param in model.cpu().named_parameters():\n",
    "        #   print(name, param.grad)\n",
    "        # plot_grad_flow(model.cpu().named_parameters())\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPn/w4j+IUa3ZgM7or7h7ji",
   "gpuType": "T4",
   "mount_file_id": "18k-3VG5eHIKWuvn4cbLSEYkNPYsG3W-J",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02705c67d19b4eb188b228046fbf1e99": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26f8b4836e9d4aa3ab3fe425455cb365": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3df46f544a194a80908e44bf1d394491": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4bcf7e6f9cd2451687e1ba12c74240e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5af5e5934a9c441784a1791a818e3e76": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c2d716c0c134147aa3ca644a3983928": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7a4d438c1bef4707babe8b0293c437ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3df46f544a194a80908e44bf1d394491",
      "placeholder": "",
      "style": "IPY_MODEL_5c2d716c0c134147aa3ca644a3983928",
      "value": " 0/720 [00:00&lt;?, ?it/s]"
     }
    },
    "8d345de5fbd84261a1c8588337db694d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9137e576ff0948b6a5bbef5a146e05da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e06b6fd9a99b4bc283bc942d7517086b",
       "IPY_MODEL_f67d8e102ab84d37a7ed583406539773",
       "IPY_MODEL_7a4d438c1bef4707babe8b0293c437ae"
      ],
      "layout": "IPY_MODEL_02705c67d19b4eb188b228046fbf1e99"
     }
    },
    "e06b6fd9a99b4bc283bc942d7517086b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4bcf7e6f9cd2451687e1ba12c74240e5",
      "placeholder": "",
      "style": "IPY_MODEL_8d345de5fbd84261a1c8588337db694d",
      "value": "Training Progress:   0%"
     }
    },
    "f67d8e102ab84d37a7ed583406539773": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5af5e5934a9c441784a1791a818e3e76",
      "max": 720,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_26f8b4836e9d4aa3ab3fe425455cb365",
      "value": 0
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
