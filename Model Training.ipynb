{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epycmNPr0I3d"
   },
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Dwn1PtIp4058"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matteo/.pyenv/versions/3.11.2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from IPython.display import display, clear_output\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.cluster import DBSCAN\n",
    "import torch.nn.functional as F\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import os\n",
    "import sys\n",
    "\n",
    "ROOT = os.path.join(\"./\")\n",
    "sys.path.append(ROOT + \"lib\")\n",
    "\n",
    "from helpers import *\n",
    "from sourceset import SourceSet\n",
    "from general_trainer import compete\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2917,
     "status": "ok",
     "timestamp": 1698123021083,
     "user": {
      "displayName": "Matteo",
      "userId": "07662895649750931658"
     },
     "user_tz": 420
    },
    "id": "0o5bi2-e_n2z",
    "outputId": "1792997b-1077-4089-b8ae-b1b818428b61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<sourceset.SourceSet at 0x2893d9e50>, <sourceset.SourceSet at 0x287fa08d0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(ROOT + \"processed_datasets/data_train.pt\", \"rb\") as f:\n",
    "  data_train = torch.load(f, map_location=device)\n",
    "with open(ROOT + \"processed_datasets/data_valid.pt\", \"rb\") as f:\n",
    "  data_valid = torch.load(f, map_location=device)\n",
    "\n",
    "data_train, data_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PU4Zzbo31tIp"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gd-gDX5vfwTG"
   },
   "outputs": [],
   "source": [
    "class FluxAnomalyPredictionLSTMDEPRECATED(nn.Module):\n",
    "  def __init__(self, stride, dropout, bn=False, features=6, residual=0, out=4):\n",
    "    super().__init__()\n",
    "\n",
    "    self.stride = stride\n",
    "    self.features = features\n",
    "    self.residual = residual\n",
    "    self.lstm_hidden_state_features = 14 # Needed for batchnorm 3, so defined here\n",
    "\n",
    "    # Need Dropouts, Activation fns\n",
    "    self.he = lambda x: nn.init.kaiming_normal_(x, nonlinearity='relu')\n",
    "    self.av = nn.ReLU()\n",
    "    self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    self.batchnorm1 = lambda x: x\n",
    "    self.batchnorm2 = lambda x: x\n",
    "    self.batchnorm3 = lambda x: x\n",
    "\n",
    "    if bn:\n",
    "      self.batchnorm1 = nn.BatchNorm1d(features)\n",
    "      self.batchnorm2 = nn.BatchNorm1d(features)\n",
    "      self.batchnorm3 = nn.BatchNorm1d(self.lstm_hidden_state_features)\n",
    "\n",
    "      self.bn1 = lambda x: torch.transpose(self.batchnorm1(torch.transpose(x,1,2)),1,2)\n",
    "      self.bn2 = lambda x: torch.transpose(self.batchnorm2(torch.transpose(x,1,2)),1,2)\n",
    "      self.bn3 = lambda x: self.batchnorm3(x)\n",
    "    else:\n",
    "      self.bn1 = lambda x: x\n",
    "      self.bn2 = lambda x: x\n",
    "      self.bn3 = lambda x: x\n",
    "\n",
    "\n",
    "    # Step 1\n",
    "\n",
    "    # 5 x 64 X 64 x 5 -diag-> R^5 Vector\n",
    "    self.conv_kernels_64d = nn.ParameterList([self.he(torch.randn(features, 64)) for i in range(8)])\n",
    "    self.conv_biases_64d = nn.ParameterList([torch.randn(features) for i in range(8)])\n",
    "\n",
    "    self.conv_kernel_16d = nn.Parameter(self.he(torch.randn(features, 16)))\n",
    "    self.conv_bias_16d = nn.Parameter(torch.randn(features))\n",
    "\n",
    "    self.conv_kernel_8d = nn.Parameter(self.he(torch.randn(features,8)))\n",
    "    self.conv_bias_8d = nn.Parameter(torch.randn(features))\n",
    "\n",
    "    self.four_max_pool = nn.MaxPool1d(4)\n",
    "\n",
    "    # Step 1.5\n",
    "    # self.certainty_fc_1 = nn.Parameter(torch.zeros(2,3))\n",
    "    # self.certainty_fc_2 = nn.Parameter(torch.zeros(3,1))\n",
    "\n",
    "    # Step 2\n",
    "    self.widechannel_conv_kernel = nn.Parameter(self.he(torch.randn(features, 3)))\n",
    "    self.widechannel_conv_bias = nn.Parameter(torch.randn(features))\n",
    "\n",
    "    self.midchannel_conv_kernel = nn.Parameter(self.he(torch.randn(features, 3)))\n",
    "    self.midchannel_conv_bias = nn.Parameter(torch.randn(features))\n",
    "\n",
    "    self.narrowchannel_conv_kernel = nn.Parameter(self.he(torch.randn(features, 3)))\n",
    "    self.narrowchannel_conv_bias = nn.Parameter(torch.randn(features))\n",
    "\n",
    "\n",
    "    # Step 3\n",
    "    self.pair_max_pool = nn.MaxPool1d(2)\n",
    "    # Then concat all vectors into v \\in R^24\n",
    "\n",
    "    # Step 3.5 Residual connection\n",
    "    self.__avgpool__ = nn.AvgPool1d(4, stride=4)\n",
    "\n",
    "    # Step 4\n",
    "    self.hidden_fc_1 = nn.Linear(3*4*features,3*2*features)\n",
    "    self.hidden_fc_2 = nn.Linear(3*2*features,2*features)\n",
    "\n",
    "    # Step 5\n",
    "    # LSTM\n",
    "\n",
    "    self.lstm_in_features = 2*self.features\n",
    "\n",
    "    self.lstm = nn.LSTM(self.lstm_in_features, self.lstm_hidden_state_features)\n",
    "\n",
    "    # Step 6\n",
    "    # Softmax\n",
    "\n",
    "    self.to_out_1 = nn.Linear(self.lstm_hidden_state_features, 7)\n",
    "    self.to_out_2 = nn.Linear(7, out, bias=False)\n",
    "\n",
    "    self.prob = nn.Softmax(dim=1)\n",
    "\n",
    "    for param in self.parameters():\n",
    "      if len(param.shape) >= 2:\n",
    "        param = self.he(param)\n",
    "\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    # x = Batches X Time X Channels\n",
    "\n",
    "    N = x.shape[0] # Batches\n",
    "    T = x.shape[1] # Time\n",
    "\n",
    "\n",
    "    # Step 1\n",
    "    # Cursory vision convolution\n",
    "    pad_amt = 40\n",
    "\n",
    "    pad = torch.zeros(N, pad_amt, self.features).to(device)\n",
    "\n",
    "    padded_x = torch.cat((pad, torch.cat((x, pad), dim=1)), dim=1) # catting in time\n",
    "\n",
    "    # padded_x.requires_grad = True\n",
    "\n",
    "    window_centers = [] # AKA 64d Convolve Centers\n",
    "\n",
    "    n=0 # strides\n",
    "    while(True):\n",
    "      next_center = pad_amt + 1 + n * self.stride\n",
    "      if next_center > (pad_amt + T + 1): # If our center isnt in real data\n",
    "        break;\n",
    "      else:\n",
    "        window_centers.append(next_center)\n",
    "        n += 1\n",
    "\n",
    "    window_starts = [self.start_and_end_from_center((64 - 1)/2, i)[0] for i in window_centers]\n",
    "    window_ends = [self.start_and_end_from_center((64 - 1)/2, i)[1] for i in window_centers]\n",
    "\n",
    "    midchannel_centers = []\n",
    "    narrowchannel_centers = []\n",
    "    for start in window_starts:\n",
    "      for n in range(8): # 8 strides of 8 -> 64 units\n",
    "        midchannel_centers.append(start + n * 8)\n",
    "\n",
    "      for n in range(32): # 32 strides of 2 -> 64 units\n",
    "        narrowchannel_centers.append(start + n * 2)\n",
    "\n",
    "\n",
    "    wide_convs = []\n",
    "    mid_convs = []\n",
    "    narrow_convs = []\n",
    "\n",
    "    for i in window_centers:\n",
    "      for j in range(8): # Hard coded 8 here\n",
    "        K = self.conv_kernels_64d[j]\n",
    "        B = self.conv_biases_64d[j].repeat(N,1) # Repeat here\n",
    "        conv = self.convolve(K, padded_x, i) # Features x T\n",
    "        conv += B\n",
    "        wide_convs.append(conv)\n",
    "\n",
    "    for i in midchannel_centers:\n",
    "      conv = self.convolve(self.conv_kernel_16d, padded_x, i)\n",
    "      conv += self.conv_bias_16d.repeat(N,1)\n",
    "      mid_convs.append(conv)\n",
    "\n",
    "    for i in narrowchannel_centers:\n",
    "      conv = self.convolve(self.conv_kernel_8d, padded_x, i)\n",
    "      conv += self.conv_bias_8d.repeat(N,1)\n",
    "      narrow_convs.append(conv)\n",
    "\n",
    "    wide_convs = torch.stack(wide_convs, dim=1).to(device)\n",
    "    mid_convs = torch.stack(mid_convs, dim=1).to(device)\n",
    "    narrow_convs = torch.stack(narrow_convs, dim=1).to(device)\n",
    "\n",
    "    narrow_convs = self.four_max_pool(torch.transpose(narrow_convs, 1,2)) # Inp = N x C x L now\n",
    "    narrow_convs = torch.transpose(narrow_convs,1,2) # Back to N x L x C\n",
    "\n",
    "\n",
    "    wide_convs = self.bn1(self.av(wide_convs))\n",
    "    mid_convs = self.bn1(self.av(mid_convs))\n",
    "    narrow_convs = self.bn1(self.av(narrow_convs))\n",
    "\n",
    "    residual_vectors = self.get_residual_vectors(narrow_convs, mid_convs, wide_convs)\n",
    "\n",
    "\n",
    "    wide_convs = 5 * self.drop(wide_convs)\n",
    "    mid_convs = self.drop(mid_convs)\n",
    "    narrow_convs = self.drop(narrow_convs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # convs = N x L x C\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #####\n",
    "    # STEP 1.5\n",
    "    # Compress our 5vectors to 3 vectors, combining mag and uncertainty indices\n",
    "\n",
    "    # if not (wide_convs.shape[1] == mid_convs.shape[1] == narrow_convs.shape[1]):\n",
    "    #   raise Exception(\"Step 1 output mismatch\")\n",
    "\n",
    "\n",
    "    # compacting_fc = lambda x: self.gelu(torch.matmul(self.gelu(torch.matmul(x, self.certainty_fc_1)), self.certainty_fc_2))\n",
    "\n",
    "    # wide_col_0 = compacting_fc(wide_convs[:, 0:2])\n",
    "    # wide_col_1 = compacting_fc(wide_convs[:, 2:4])\n",
    "\n",
    "    # mid_col_0 = compacting_fc(mid_convs[:, 0:2])\n",
    "    # mid_col_1 = compacting_fc(mid_convs[:, 2:4])\n",
    "\n",
    "    # narrow_col_0 = compacting_fc(mid_convs[:, 0:2])\n",
    "    # narrow_col_1 = compacting_fc(mid_convs[:, 2:4])\n",
    "\n",
    "    # wide_convs = torch.stack((wide_col_0, wide_col_1, wide_convs[:, -1].unsqueeze(1)), dim=1)\n",
    "    # mid_convs = torch.stack((mid_col_0, mid_col_1, mid_convs[:, -1].unsqueeze(1)), dim=1)\n",
    "    # narrow_convs = torch.stack((narrow_col_0, narrow_col_1, narrow_convs[:, -1].unsqueeze(1)), dim=1)\n",
    "\n",
    "    # wide_convs = wide_convs.squeeze()\n",
    "    # mid_convs = mid_convs.squeeze()\n",
    "    # narrow_convs = narrow_convs.squeeze()\n",
    "\n",
    "\n",
    "    #####\n",
    "    # STEP 2\n",
    "    # Second Convolution\n",
    "\n",
    "    pad_amt = 10\n",
    "    stride = 1\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for x in (wide_convs, mid_convs, narrow_convs):\n",
    "      T = x.shape[1]\n",
    "      ker = None\n",
    "      bias = None\n",
    "      if len(results) == 0:\n",
    "        ker = self.widechannel_conv_kernel\n",
    "        bias = self.widechannel_conv_bias.repeat(N, 1)\n",
    "\n",
    "      elif len(results) == 1:\n",
    "        ker = self.midchannel_conv_kernel\n",
    "        bias = self.midchannel_conv_bias.repeat(N, 1)\n",
    "\n",
    "      elif len(results) == 2:\n",
    "        ker = self.narrowchannel_conv_kernel\n",
    "        bias = self.narrowchannel_conv_bias.repeat(N, 1)\n",
    "\n",
    "\n",
    "      pad = torch.zeros(N, pad_amt, self.features).to(device)\n",
    "      padded_x = torch.cat((pad, torch.cat((x, pad), dim=1)), dim=1)\n",
    "\n",
    "\n",
    "      result = []\n",
    "\n",
    "      next = pad_amt\n",
    "      while next <= (pad_amt + T - 1):\n",
    "        v = bias + self.convolve(ker, padded_x, next)\n",
    "        result.append(v)\n",
    "        next += stride\n",
    "\n",
    "\n",
    "      results.append(torch.stack(result, dim=1))\n",
    "\n",
    "\n",
    "    wide_convs = self.bn2(self.av(results[0]))\n",
    "    mid_convs = self.bn2(self.av(results[1]))\n",
    "    narrow_convs = self.bn2(self.av(results[2]))\n",
    "\n",
    "    wide_convs = self.drop(wide_convs)\n",
    "    mid_convs = self.drop(mid_convs)\n",
    "    narrow_convs = self.drop(narrow_convs)\n",
    "\n",
    "\n",
    "\n",
    "    ####\n",
    "    # Step 2.5\n",
    "    # Max Pooling Pairs\n",
    "    wide_convs = self.pair_max_pool(torch.transpose(wide_convs, 1,2)) # to N x C x L\n",
    "    mid_convs = self.pair_max_pool(torch.transpose(mid_convs, 1,2))\n",
    "    narrow_convs = self.pair_max_pool(torch.transpose(narrow_convs, 1,2))\n",
    "\n",
    "    wide_convs = torch.transpose(wide_convs, 1,2) # to N x L x C\n",
    "    mid_convs = torch.transpose(mid_convs, 1,2)\n",
    "    narrow_convs = torch.transpose(narrow_convs, 1,2)\n",
    "\n",
    "\n",
    "    ####\n",
    "    # Step 3\n",
    "\n",
    "    # Now each original window reigon is each corresponding 2 rows from all 3 tensors\n",
    "    # 2 rows evenly divides all possible resulting lengths\n",
    "\n",
    "    if not (wide_convs.shape[1] == mid_convs.shape[1] == narrow_convs.shape[1]):\n",
    "      raise Exception(\"Step 3 output mismatch\")\n",
    "\n",
    "\n",
    "    hidden = []\n",
    "    L = wide_convs.shape[1]\n",
    "\n",
    "    for n in range(L // 4): # Now each sliding window corresponds to 2 rows\n",
    "      wide = wide_convs[:, 4*n:4*n + 4].reshape(N, 4*self.features)\n",
    "      mid = mid_convs[:, 4*n:4*n + 4].reshape(N, 4*self.features)\n",
    "      narrow = narrow_convs[:, 4*n:4*n + 4].reshape(N, 4*self.features)\n",
    "\n",
    "      flat = torch.cat((wide, mid, narrow), dim=1).to(device)\n",
    "      if flat.shape[0] != N or flat.shape[1] != 3*4*self.features:\n",
    "        raise Exception(\"Flat shape err\")\n",
    "\n",
    "      layer_1 = self.hidden_fc_1(flat)\n",
    "      layer_1 = self.av(layer_1)\n",
    "\n",
    "      # RESIDUAL CONNECTION !\n",
    "      res = torch.autograd.Variable(self.residual * residual_vectors[n])\n",
    "      layer_1 = (1-self.residual) * layer_1\n",
    "      layer_1 = layer_1 + res\n",
    "\n",
    "\n",
    "      layer_2 = self.hidden_fc_2(layer_1)\n",
    "      layer_2 = self.av(layer_2)\n",
    "\n",
    "      hidden.append(layer_2)\n",
    "\n",
    "\n",
    "    hidden = torch.stack(hidden, dim=0) # Results in L x N x Hidden\n",
    "\n",
    "    hidden = self.drop(hidden)\n",
    "\n",
    "\n",
    "    ####\n",
    "    # Step 6: LSTM\n",
    "\n",
    "    _, (final_hidden_state, c_n) = self.lstm(hidden)\n",
    "\n",
    "    final_hidden_state = self.av(final_hidden_state.squeeze())\n",
    "    final_hidden_state = self.bn3(final_hidden_state)\n",
    "\n",
    "    final_hidden_state = self.drop(final_hidden_state)\n",
    "\n",
    "\n",
    "    final_layer = self.to_out_1(final_hidden_state)\n",
    "    final_layer = self.av(final_layer)\n",
    "\n",
    "    final_layer = self.drop(final_layer)\n",
    "\n",
    "    final_layer = self.to_out_2(final_layer)\n",
    "\n",
    "    classes = self.prob(final_layer)\n",
    "\n",
    "\n",
    "    return F.log_softmax(final_layer, dim=1)\n",
    "\n",
    "\n",
    "  def start_and_end_from_center(self, width, i):\n",
    "    start = i - np.ceil(width)\n",
    "    end = i + np.floor(width) + 1\n",
    "    return (int(start), int(end))\n",
    "\n",
    "\n",
    "\n",
    "  def convolve(self, Kernel, Data, i):\n",
    "\n",
    "    # i is center index so we take equal on either side\n",
    "    T = Kernel.shape[1]\n",
    "    each_side = (T - 1) / 2\n",
    "\n",
    "    # Moves it backwards 1 if kernel is even\n",
    "    start, end = self.start_and_end_from_center(each_side, i)\n",
    "\n",
    "    adj_data = Data[:, start:end, :]\n",
    "\n",
    "    # So now K is 5 x L and adj_data is N x L X 5\n",
    "\n",
    "\n",
    "    N = adj_data.shape[0]\n",
    "\n",
    "    m = torch.bmm(Kernel.repeat(N,1,1), adj_data) # bij, bjk -> bik Slightly faster than einsum\n",
    "\n",
    "    # m = torch.einsum(\"ij, bjk -> bik\", Kernel, adj_data) #identical batch matmul\n",
    "\n",
    "    diag = torch.einsum(\"bii->bi\", m)\n",
    "    # diags = []\n",
    "    # for res in m:\n",
    "    #   diags.append(torch.diag(res))\n",
    "\n",
    "\n",
    "    return diag\n",
    "\n",
    "  def get_residual_vectors(self, narrow, mid, wide):\n",
    "    # Should be N x 8m x Features\n",
    "    # print(narrow.shape, mid.shape, wide.shape)\n",
    "    N = wide.shape[0]\n",
    "    L = wide.shape[1]\n",
    "\n",
    "    apply_avg = lambda matrix: torch.transpose(self.__avgpool__(torch.transpose(matrix, 1,2)), 1,2)\n",
    "\n",
    "    vectors = []\n",
    "\n",
    "    if L % 8:\n",
    "      raise Exception(\"Something went wrong, convs are not mult of 8\")\n",
    "    for i in range(L // 8):\n",
    "\n",
    "      n = torch.autograd.Variable(narrow[:, 8*i:8*(i+1), :])\n",
    "      m = torch.autograd.Variable(mid[:, 8*i:8*(i+1), :])\n",
    "      w = torch.autograd.Variable(wide[:, 8*i:8*(i+1), :])\n",
    "\n",
    "      n = apply_avg(n)\n",
    "      m = apply_avg(m)\n",
    "      w = apply_avg(w)\n",
    "\n",
    "      n = n.reshape(N, 2*self.features)\n",
    "      m = m.reshape(N, 2*self.features)\n",
    "      w = w.reshape(N, 2*self.features)\n",
    "      # gives N x 2 * Features\n",
    "\n",
    "      vectors.append(torch.autograd.Variable(torch.cat((n,m,w), dim=1))) # N x 6 * features\n",
    "\n",
    "    return vectors\n",
    "\n",
    "class FluxAnomalyPredictionTF(nn.Module):\n",
    "  def __init__(self, stride, dropout, bn=False, features=3, residual=0, out=4):\n",
    "    super().__init__()\n",
    "\n",
    "    self.stride = stride\n",
    "    self.features = features\n",
    "    self.residual = residual\n",
    "    self.transformer_hidden_dim = 2*features # Needed for batchnorm 3, so defined here\n",
    "\n",
    "    # Need Dropouts, Activation fns\n",
    "    self.he = lambda x: nn.init.kaiming_normal_(x, nonlinearity='relu')\n",
    "    self.av = nn.ReLU()\n",
    "    self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    self.batchnorm1 = lambda x: x\n",
    "    self.batchnorm2 = lambda x: x\n",
    "    self.batchnorm3 = lambda x: x\n",
    "\n",
    "    if bn:\n",
    "      self.batchnorm1 = nn.BatchNorm1d(features)\n",
    "      self.batchnorm2 = nn.BatchNorm1d(features)\n",
    "      self.batchnorm3 = nn.BatchNorm1d(self.transformer_hidden_dim)\n",
    "\n",
    "      self.bn1 = lambda x: torch.transpose(self.batchnorm1(torch.transpose(x,1,2)),1,2)\n",
    "      self.bn2 = lambda x: torch.transpose(self.batchnorm2(torch.transpose(x,1,2)),1,2)\n",
    "      self.bn3 = lambda x: self.batchnorm3(x)\n",
    "    else:\n",
    "      self.bn1 = lambda x: x\n",
    "      self.bn2 = lambda x: x\n",
    "      self.bn3 = lambda x: x\n",
    "\n",
    "\n",
    "    # Step 1\n",
    "\n",
    "    # 5 x 64 X 64 x 5 -diag-> R^5 Vector\n",
    "    self.conv_kernels_64d = nn.ParameterList([self.he(torch.randn(features, 64)) for i in range(8)])\n",
    "    self.conv_biases_64d = nn.ParameterList([torch.randn(features) for i in range(8)])\n",
    "\n",
    "    self.conv_kernel_16d = nn.Parameter(self.he(torch.randn(features, 16)))\n",
    "    self.conv_bias_16d = nn.Parameter(torch.randn(features))\n",
    "\n",
    "    self.conv_kernel_8d = nn.Parameter(self.he(torch.randn(features,8)))\n",
    "    self.conv_bias_8d = nn.Parameter(torch.randn(features))\n",
    "\n",
    "    self.four_max_pool = nn.MaxPool1d(4)\n",
    "\n",
    "    # Step 1.5\n",
    "    # self.certainty_fc_1 = nn.Parameter(torch.zeros(2,3))\n",
    "    # self.certainty_fc_2 = nn.Parameter(torch.zeros(3,1))\n",
    "\n",
    "    # Step 2\n",
    "    self.widechannel_conv_kernel = nn.Parameter(self.he(torch.randn(features, 3)))\n",
    "    self.widechannel_conv_bias = nn.Parameter(torch.randn(features))\n",
    "\n",
    "    self.midchannel_conv_kernel = nn.Parameter(self.he(torch.randn(features, 3)))\n",
    "    self.midchannel_conv_bias = nn.Parameter(torch.randn(features))\n",
    "\n",
    "    self.narrowchannel_conv_kernel = nn.Parameter(self.he(torch.randn(features, 3)))\n",
    "    self.narrowchannel_conv_bias = nn.Parameter(torch.randn(features))\n",
    "\n",
    "\n",
    "    # Step 3\n",
    "    self.pair_max_pool = nn.MaxPool1d(2)\n",
    "    # Then concat all vectors into v \\in R^24\n",
    "\n",
    "    # Step 3.5 Residual connection\n",
    "    self.__avgpool__ = nn.AvgPool1d(4, stride=4)\n",
    "\n",
    "    # Step 4\n",
    "    self.hidden_fc_1 = nn.Linear(3*4*features, 3*2*features)\n",
    "    self.hidden_fc_2 = nn.Linear(3*2*features, self.transformer_hidden_dim)\n",
    "\n",
    "    # Step 5\n",
    "    # Transformer\n",
    "    self.transformer_encoder_layer = nn.TransformerEncoderLayer(d_model=self.transformer_hidden_dim, nhead=self.features)\n",
    "    self.transformer_encoder = nn.TransformerEncoder(self.transformer_encoder_layer, 2)\n",
    "\n",
    "\n",
    "    # Step 6\n",
    "    # Softmax\n",
    "\n",
    "    self.to_out_1 = nn.Linear(self.transformer_hidden_dim, 7)\n",
    "    self.to_out_2 = nn.Linear(7, out, bias=False)\n",
    "\n",
    "    self.prob = nn.Softmax(dim=1)\n",
    "\n",
    "    for param in self.parameters():\n",
    "      if len(param.shape) >= 2:\n",
    "        param = self.he(param)\n",
    "\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    # x = Batches X Time X Channels\n",
    "\n",
    "    N = x.shape[0] # Batches\n",
    "    T = x.shape[1] # Time\n",
    "\n",
    "    if x.shape[2] != self.features:\n",
    "      raise Exception(\"Feature dimension mismatch\")\n",
    "\n",
    "    # Step 1\n",
    "    # Cursory vision convolution\n",
    "    pad_amt = 40\n",
    "\n",
    "    pad = torch.zeros(N, pad_amt, self.features).to(device)\n",
    "  \n",
    "\n",
    "    padded_x = torch.cat((pad, torch.cat((x, pad), dim=1)), dim=1) # catting in time\n",
    "\n",
    "    # padded_x.requires_grad = True\n",
    "\n",
    "    window_centers = [] # AKA 64d Convolve Centers\n",
    "\n",
    "    n=0 # strides\n",
    "    while(True):\n",
    "      next_center = pad_amt + 1 + n * self.stride\n",
    "      if next_center > (pad_amt + T + 1): # If our center isnt in real data\n",
    "        break;\n",
    "      else:\n",
    "        window_centers.append(next_center)\n",
    "        n += 1\n",
    "\n",
    "    window_starts = [self.start_and_end_from_center((64 - 1)/2, i)[0] for i in window_centers]\n",
    "    window_ends = [self.start_and_end_from_center((64 - 1)/2, i)[1] for i in window_centers]\n",
    "\n",
    "    midchannel_centers = []\n",
    "    narrowchannel_centers = []\n",
    "    for start in window_starts:\n",
    "      for n in range(8): # 8 strides of 8 -> 64 units\n",
    "        midchannel_centers.append(start + n * 8)\n",
    "\n",
    "      for n in range(32): # 32 strides of 2 -> 64 units\n",
    "        narrowchannel_centers.append(start + n * 2)\n",
    "\n",
    "\n",
    "    wide_convs = []\n",
    "    mid_convs = []\n",
    "    narrow_convs = []\n",
    "\n",
    "    for i in window_centers:\n",
    "      for j in range(8): # Hard coded 8 here\n",
    "        K = self.conv_kernels_64d[j]\n",
    "        B = self.conv_biases_64d[j].repeat(N,1) # Repeat here\n",
    "        conv = self.convolve(K, padded_x, i) # Features x T\n",
    "        conv += B\n",
    "        wide_convs.append(conv)\n",
    "\n",
    "    for i in midchannel_centers:\n",
    "      conv = self.convolve(self.conv_kernel_16d, padded_x, i)\n",
    "      conv += self.conv_bias_16d.repeat(N,1)\n",
    "      mid_convs.append(conv)\n",
    "\n",
    "    for i in narrowchannel_centers:\n",
    "      conv = self.convolve(self.conv_kernel_8d, padded_x, i)\n",
    "      conv += self.conv_bias_8d.repeat(N,1)\n",
    "      narrow_convs.append(conv)\n",
    "\n",
    "    wide_convs = torch.stack(wide_convs, dim=1).to(device)\n",
    "    mid_convs = torch.stack(mid_convs, dim=1).to(device)\n",
    "    narrow_convs = torch.stack(narrow_convs, dim=1).to(device)\n",
    "\n",
    "    narrow_convs = self.four_max_pool(torch.transpose(narrow_convs, 1,2)) # Inp = N x C x L now\n",
    "    narrow_convs = torch.transpose(narrow_convs,1,2) # Back to N x L x C\n",
    "\n",
    "\n",
    "    wide_convs = self.bn1(self.av(wide_convs))\n",
    "    mid_convs = self.bn1(self.av(mid_convs))\n",
    "    narrow_convs = self.bn1(self.av(narrow_convs))\n",
    "\n",
    "    residual_vectors = self.get_residual_vectors(narrow_convs, mid_convs, wide_convs)\n",
    "\n",
    "\n",
    "    wide_convs = 5 * self.drop(wide_convs)\n",
    "    mid_convs = self.drop(mid_convs)\n",
    "    narrow_convs = self.drop(narrow_convs)\n",
    "\n",
    "\n",
    "\n",
    "    #####\n",
    "    # STEP 2\n",
    "    # Second Convolution\n",
    "\n",
    "    pad_amt = 10\n",
    "    stride = 1\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for x in (wide_convs, mid_convs, narrow_convs):\n",
    "      T = x.shape[1]\n",
    "      ker = None\n",
    "      bias = None\n",
    "      if len(results) == 0:\n",
    "        ker = self.widechannel_conv_kernel\n",
    "        bias = self.widechannel_conv_bias.repeat(N, 1)\n",
    "\n",
    "      elif len(results) == 1:\n",
    "        ker = self.midchannel_conv_kernel\n",
    "        bias = self.midchannel_conv_bias.repeat(N, 1)\n",
    "\n",
    "      elif len(results) == 2:\n",
    "        ker = self.narrowchannel_conv_kernel\n",
    "        bias = self.narrowchannel_conv_bias.repeat(N, 1)\n",
    "\n",
    "\n",
    "      pad = torch.zeros(N, pad_amt, self.features).to(device)\n",
    "      padded_x = torch.cat((pad, torch.cat((x, pad), dim=1)), dim=1)\n",
    "\n",
    "\n",
    "      result = []\n",
    "\n",
    "      next = pad_amt\n",
    "      while next <= (pad_amt + T - 1):\n",
    "        v = bias + self.convolve(ker, padded_x, next)\n",
    "        result.append(v)\n",
    "        next += stride\n",
    "\n",
    "\n",
    "      results.append(torch.stack(result, dim=1))\n",
    "\n",
    "\n",
    "    wide_convs = self.bn2(self.av(results[0]))\n",
    "    mid_convs = self.bn2(self.av(results[1]))\n",
    "    narrow_convs = self.bn2(self.av(results[2]))\n",
    "\n",
    "    wide_convs = self.drop(wide_convs)\n",
    "    mid_convs = self.drop(mid_convs)\n",
    "    narrow_convs = self.drop(narrow_convs)\n",
    "\n",
    "\n",
    "\n",
    "    ####\n",
    "    # Step 2.5\n",
    "    # Max Pooling Pairs\n",
    "    wide_convs = self.pair_max_pool(torch.transpose(wide_convs, 1,2)) # to N x C x L\n",
    "    mid_convs = self.pair_max_pool(torch.transpose(mid_convs, 1,2))\n",
    "    narrow_convs = self.pair_max_pool(torch.transpose(narrow_convs, 1,2))\n",
    "\n",
    "    wide_convs = torch.transpose(wide_convs, 1,2) # to N x L x C\n",
    "    mid_convs = torch.transpose(mid_convs, 1,2)\n",
    "    narrow_convs = torch.transpose(narrow_convs, 1,2)\n",
    "\n",
    "\n",
    "    ####\n",
    "    # Step 3\n",
    "\n",
    "    # Now each original window reigon is each corresponding 2 rows from all 3 tensors\n",
    "    # 2 rows evenly divides all possible resulting lengths\n",
    "\n",
    "    if not (wide_convs.shape[1] == mid_convs.shape[1] == narrow_convs.shape[1]):\n",
    "      raise Exception(\"Step 3 output mismatch\")\n",
    "\n",
    "\n",
    "    hidden = []\n",
    "    L = wide_convs.shape[1]\n",
    "\n",
    "    for n in range(L // 4): # Now each sliding window corresponds to 2 rows\n",
    "      wide = wide_convs[:, 4*n:4*n + 4].reshape(N, 4*self.features)\n",
    "      mid = mid_convs[:, 4*n:4*n + 4].reshape(N, 4*self.features)\n",
    "      narrow = narrow_convs[:, 4*n:4*n + 4].reshape(N, 4*self.features)\n",
    "\n",
    "      flat = torch.cat((wide, mid, narrow), dim=1).to(device)\n",
    "      if flat.shape[0] != N or flat.shape[1] != 3*4*self.features:\n",
    "        raise Exception(\"Flat shape err\")\n",
    "\n",
    "      layer_1 = self.hidden_fc_1(flat)\n",
    "      layer_1 = self.av(layer_1)\n",
    "\n",
    "      # RESIDUAL CONNECTION !\n",
    "      res = torch.autograd.Variable(self.residual * residual_vectors[n])\n",
    "      layer_1 = (1-self.residual) * layer_1\n",
    "      layer_1 = layer_1 + res\n",
    "\n",
    "      layer_2 = self.hidden_fc_2(layer_1)\n",
    "      layer_2 = self.av(layer_2)\n",
    "\n",
    "      hidden.append(layer_2)\n",
    "\n",
    "    hidden = torch.stack(hidden, dim=0) # Results in (Divided L) x N x Hidden\n",
    "    hidden = self.drop(hidden)\n",
    "\n",
    "\n",
    "    seq = self.transformer_encoder(hidden) # same shape as hidden\n",
    "\n",
    "\n",
    "\n",
    "    transformed = nn.AvgPool1d(seq.shape[0])(torch.transpose(seq,0,2)) # Pooling happens on last dim\n",
    "    transformed = torch.squeeze(transformed, dim=2)\n",
    "    transformed = torch.transpose(transformed, 0, 1) # Should be N x Hidden\n",
    "\n",
    "    transformed = self.av(transformed)\n",
    "    transformed = self.bn3(transformed)\n",
    "    transformed = self.drop(transformed)\n",
    "\n",
    "    final_layer = self.to_out_1(transformed)\n",
    "    final_layer = self.av(final_layer)\n",
    "    final_layer = self.drop(final_layer)\n",
    "    final_layer = self.to_out_2(final_layer)\n",
    "\n",
    "    # classes = self.prob(final_layer) # Dont use, use CEL instead\n",
    "\n",
    "    return F.log_softmax(final_layer, dim=1)\n",
    "\n",
    "\n",
    "  def start_and_end_from_center(self, width, i):\n",
    "    start = i - np.ceil(width)\n",
    "    end = i + np.floor(width) + 1\n",
    "    return (int(start), int(end))\n",
    "\n",
    "\n",
    "\n",
    "  def convolve(self, Kernel, Data, i):\n",
    "\n",
    "    # i is center index so we take equal on either side\n",
    "    T = Kernel.shape[1]\n",
    "    each_side = (T - 1) / 2\n",
    "\n",
    "    # Moves it backwards 1 if kernel is even\n",
    "    start, end = self.start_and_end_from_center(each_side, i)\n",
    "\n",
    "    adj_data = Data[:, start:end, :]\n",
    "\n",
    "    # So now K is 5 x L and adj_data is N x L X 5\n",
    "\n",
    "\n",
    "    N = adj_data.shape[0]\n",
    "\n",
    "    m = torch.bmm(Kernel.repeat(N,1,1), adj_data) # bij, bjk -> bik Slightly faster than einsum\n",
    "\n",
    "    # m = torch.einsum(\"ij, bjk -> bik\", Kernel, adj_data) #identical batch matmul\n",
    "\n",
    "    diag = torch.einsum(\"bii->bi\", m)\n",
    "    # diags = []\n",
    "    # for res in m:\n",
    "    #   diags.append(torch.diag(res))\n",
    "\n",
    "\n",
    "    return diag\n",
    "\n",
    "  def get_residual_vectors(self, narrow, mid, wide):\n",
    "    # Should be N x 8m x Features\n",
    "    # print(narrow.shape, mid.shape, wide.shape)\n",
    "    N = wide.shape[0]\n",
    "    L = wide.shape[1]\n",
    "\n",
    "    apply_avg = lambda matrix: torch.transpose(self.__avgpool__(torch.transpose(matrix, 1,2)), 1,2)\n",
    "\n",
    "    vectors = []\n",
    "\n",
    "    if L % 8:\n",
    "      raise Exception(\"Something went wrong, convs are not mult of 8\")\n",
    "    for i in range(L // 8):\n",
    "\n",
    "      n = torch.autograd.Variable(narrow[:, 8*i:8*(i+1), :])\n",
    "      m = torch.autograd.Variable(mid[:, 8*i:8*(i+1), :])\n",
    "      w = torch.autograd.Variable(wide[:, 8*i:8*(i+1), :])\n",
    "\n",
    "      n = apply_avg(n)\n",
    "      m = apply_avg(m)\n",
    "      w = apply_avg(w)\n",
    "\n",
    "      n = n.reshape(N, 2*self.features)\n",
    "      m = m.reshape(N, 2*self.features)\n",
    "      w = w.reshape(N, 2*self.features)\n",
    "      # gives N x 2 * Features\n",
    "\n",
    "      vectors.append(torch.autograd.Variable(torch.cat((n,m,w), dim=1))) # N x 6 * features\n",
    "\n",
    "    return vectors\n",
    "\n",
    "class lstm(nn.Module):\n",
    "  def __init__(self, into, hidden, out):\n",
    "    super().__init__()\n",
    "\n",
    "    self.rl = nn.functional.sigmoid\n",
    "    self.ls = nn.LSTM(into, hidden, batch_first=True)\n",
    "    self.to_out = nn.Linear(hidden,out)\n",
    "    self.prob = nn.Softmax(dim=1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    _, (f, __) = self.ls(x)\n",
    "\n",
    "    return self.to_out(f.squeeze())\n",
    "\n",
    "class lstm2(nn.Module):\n",
    "  def __init__(self, into, hidden, out):\n",
    "    super().__init__()\n",
    "\n",
    "    self.rl = nn.functional.sigmoid\n",
    "    self.ls = nn.LSTM(into, hidden, batch_first=True, num_layers=2)\n",
    "    self.to_out = nn.Linear(hidden,out)\n",
    "    self.prob = nn.Softmax(dim=1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    _, (f, __) = self.ls(x)\n",
    "\n",
    "    return self.to_out(f[1, :].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1698123021980,
     "user": {
      "displayName": "Matteo",
      "userId": "07662895649750931658"
     },
     "user_tz": 420
    },
    "id": "QCaXFn0b4T4E",
    "outputId": "046486bb-7ddf-4d47-ff86-8c8da5e3c5eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82997\n"
     ]
    }
   ],
   "source": [
    "model = FluxAnomalyPredictionTF(20, 0.15, bn=False, features=3, residual=0).to(device)\n",
    "\n",
    "model_pars = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_pars])\n",
    "\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 202,
     "status": "ok",
     "timestamp": 1698123023002,
     "user": {
      "displayName": "Matteo",
      "userId": "07662895649750931658"
     },
     "user_tz": 420
    },
    "id": "BOJnl8dTJEoi",
    "outputId": "4aa465eb-c350-44e1-9ba4-8fb3b276d6dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([480, 999, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = DataLoader(data_train, batch_size=len(data_train), shuffle=True, collate_fn=padded_collate)\n",
    "valid = DataLoader(data_valid, batch_size=len(data_valid), shuffle=True, collate_fn=padded_collate)\n",
    "next(iter(train))[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XX8cN71g14oT"
   },
   "source": [
    "# Training Loop (Single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DmGh2Yd4kclP"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 500\n",
    "lr = 0.007\n",
    "\n",
    "model = FluxAnomalyPredictionTF(20, 0.15, bn=False, features=3, residual=0).to(device)\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "progress_bar = tqdm(total=EPOCHS, desc=\"Training Progress\")\n",
    "\n",
    "trainloss = []\n",
    "validloss = []\n",
    "\n",
    "nullts = []\n",
    "novats = []\n",
    "pulsatingts = []\n",
    "transitts = []\n",
    "accuracyts = []\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "  epoch_loss = []\n",
    "  valid_loss = []\n",
    "\n",
    "  null_correct = 0\n",
    "  nova_correct = 0\n",
    "  pulsating_correct = 0\n",
    "  transit_correct = 0\n",
    "  correct = 0\n",
    "\n",
    "\n",
    "  novas = 0\n",
    "  pulsators = 0\n",
    "  transits = 0\n",
    "  nulls = 0\n",
    "  exs = 0\n",
    "\n",
    "  for data, label in train:\n",
    "\n",
    "    model.train()\n",
    "    out = model(data)\n",
    "\n",
    "    loss = loss_fn(out, label)\n",
    "\n",
    "    epoch_loss.append(loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    optim.zero_grad()\n",
    "\n",
    "\n",
    "  for data, label in valid:\n",
    "    model.eval()\n",
    "    out = model(data)\n",
    "    loss = loss_fn(out, label)\n",
    "    valid_loss.append(loss.item())\n",
    "    i = torch.argmax(out, dim=1).cpu()\n",
    "    j = torch.argmax(label, dim=1).cpu()\n",
    "\n",
    "    for idx, jdx in zip(i,j):\n",
    "      exs += 1\n",
    "      if idx == jdx:\n",
    "        correct += 1\n",
    "\n",
    "      if jdx == 0:\n",
    "        nulls += 1\n",
    "        if idx == jdx:\n",
    "          null_correct += 1\n",
    "\n",
    "      if jdx == 1:\n",
    "        novas += 1\n",
    "        if idx == jdx:\n",
    "          nova_correct +=1\n",
    "      if jdx == 2:\n",
    "        pulsators += 1\n",
    "        if idx == jdx:\n",
    "          pulsating_correct +=1\n",
    "      if jdx == 3:\n",
    "        transits += 1\n",
    "        if idx == jdx:\n",
    "          transit_correct +=1\n",
    "\n",
    "  training_loss_epoch = np.mean(epoch_loss)\n",
    "  validation_loss_epoch = np.mean(valid_loss)\n",
    "\n",
    "  nullac = null_correct / (nulls + 0.000001)\n",
    "  novacc = nova_correct / (novas + 0.000001)\n",
    "  pulsatoracc = pulsating_correct / (pulsators + 0.00001)\n",
    "  transitacc = transit_correct / (transits + 0.00001)\n",
    "  accuracy = correct / exs\n",
    "\n",
    "  trainloss.append(training_loss_epoch)\n",
    "  validloss.append(validation_loss_epoch)\n",
    "\n",
    "  nullts.append(nullac)\n",
    "  novats.append(novacc)\n",
    "  pulsatingts.append(pulsatoracc)\n",
    "  transitts.append(transitacc)\n",
    "  accuracyts.append(accuracy)\n",
    "\n",
    "\n",
    "  progress_bar.update(1)\n",
    "  p = getprogressplot(trainloss, validloss, accuracyts, nullts, novats, pulsatingts, transitts, EPOCHS, e)\n",
    "  clear_output(wait=False)\n",
    "  display(p)\n",
    "\n",
    "  print(\"Epoch \", e, \": \", training_loss_epoch)\n",
    "  print(\"nulls:\", nullac, \"novas: \", novacc, \"pulsators: \", pulsatoracc, \"transits: \", transitacc)\n",
    "\n",
    "x = range(EPOCHS)\n",
    "\n",
    "p = getprogressplot(trainloss, validloss, accuracyts, nullts, novats, pulsatingts, transitts, EPOCHS, e)\n",
    "clear_output(wait=True)\n",
    "display(p)\n",
    "print(\"Epoch \", e, \": \", training_loss_epoch)\n",
    "\n",
    "savestr = \"models/model\" + str(np.random.randint(1111,9999)) + \".pt\"\n",
    "with open(ROOT + savestr, \"wb\") as f:\n",
    "  torch.save(model.state_dict(),f)\n",
    "\n",
    "print(\"saved as {}\".format(savestr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(model.parameters(), lr=0.007)\n",
    "compete([(\"TF\", model, optim)], 150, train, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "qPbsgAA7OIXE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-11-20 21:32:47 73762:31109620 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-11-20 21:32:55 73762:31109620 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-11-20 21:32:55 73762:31109620 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                     dd         4.75%     194.411ms       100.00%        4.093s        4.093s             1  \n",
      "                                            aten::empty         0.11%       4.442ms         0.11%       4.442ms       0.429us         10346  \n",
      "                                          aten::random_         0.00%       5.000us         0.00%       5.000us       2.500us             2  \n",
      "                                             aten::item         0.00%       6.000us         0.00%       7.000us       3.500us             2  \n",
      "                              aten::_local_scalar_dense         0.00%       1.000us         0.00%       1.000us       0.500us             2  \n",
      "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...         0.01%     456.000us         0.15%       6.232ms       6.232ms             1  \n",
      "                                         aten::randperm         0.00%      20.000us         0.00%      35.000us      17.500us             2  \n",
      "                                    aten::scalar_tensor         0.00%       1.000us         0.00%       1.000us       1.000us             1  \n",
      "                                          aten::resize_         0.00%       5.000us         0.00%       5.000us       0.833us             6  \n",
      "                                     aten::resolve_conj         0.00%     159.000us         0.00%     159.000us       0.000us        666008  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 4.093s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = FluxAnomalyPredictionTF(32, 0.1).to(device)\n",
    "\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "    with record_function(\"dd\"):\n",
    "        ex = next(iter(train))\n",
    "        out = model(ex[0])\n",
    "        loss = loss_fn(out, ex[1])\n",
    "        loss.backward()\n",
    "        # for name, param in model.cpu().named_parameters():\n",
    "        #   print(name, param.grad)\n",
    "        # plot_grad_flow(model.cpu().named_parameters())\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPn/w4j+IUa3ZgM7or7h7ji",
   "gpuType": "T4",
   "mount_file_id": "18k-3VG5eHIKWuvn4cbLSEYkNPYsG3W-J",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02705c67d19b4eb188b228046fbf1e99": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26f8b4836e9d4aa3ab3fe425455cb365": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3df46f544a194a80908e44bf1d394491": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4bcf7e6f9cd2451687e1ba12c74240e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5af5e5934a9c441784a1791a818e3e76": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c2d716c0c134147aa3ca644a3983928": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7a4d438c1bef4707babe8b0293c437ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3df46f544a194a80908e44bf1d394491",
      "placeholder": "",
      "style": "IPY_MODEL_5c2d716c0c134147aa3ca644a3983928",
      "value": " 0/720 [00:00&lt;?, ?it/s]"
     }
    },
    "8d345de5fbd84261a1c8588337db694d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9137e576ff0948b6a5bbef5a146e05da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e06b6fd9a99b4bc283bc942d7517086b",
       "IPY_MODEL_f67d8e102ab84d37a7ed583406539773",
       "IPY_MODEL_7a4d438c1bef4707babe8b0293c437ae"
      ],
      "layout": "IPY_MODEL_02705c67d19b4eb188b228046fbf1e99"
     }
    },
    "e06b6fd9a99b4bc283bc942d7517086b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4bcf7e6f9cd2451687e1ba12c74240e5",
      "placeholder": "",
      "style": "IPY_MODEL_8d345de5fbd84261a1c8588337db694d",
      "value": "Training Progress:   0%"
     }
    },
    "f67d8e102ab84d37a7ed583406539773": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5af5e5934a9c441784a1791a818e3e76",
      "max": 720,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_26f8b4836e9d4aa3ab3fe425455cb365",
      "value": 0
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
