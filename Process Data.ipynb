{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPxTVATuLewu"
   },
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-13UXM7xeZAE"
   },
   "outputs": [],
   "source": [
    "import common\n",
    "import numpy as np\n",
    "import torch\n",
    "from rich import print\n",
    "import pickle\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import display, clear_output\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "import astropy.units as u\n",
    "from astroquery.ipac.irsa import Irsa\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import sklearn\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "\n",
    "ROOT = os.path.join(\"./\")\n",
    "sys.path.append(ROOT + \"lib\")\n",
    "\n",
    "from plotly_style import update_layout\n",
    "from flux_table import get_flux, LightSource\n",
    "from fluxtable_to_tensor import fluxtable_to_tensor\n",
    "\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "neowise = 'neowiser_p1bs_psd'\n",
    "min_qual_frame = 4\n",
    "min_obj_qual = 3\n",
    "\n",
    "test_cutoff = 0.9\n",
    "\n",
    "QUERY = True # Toggle querying - Only do this if youve changed the data.csvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPVHCeHrK94N"
   },
   "source": [
    "# Spreadsheets to Data Tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rVtcWMwlfeef"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>%\r</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m100\u001b[0m%\r"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">transit:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "transit:  \u001b[1;36m48\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if QUERY:\n",
    "  raw_classes = {\n",
    "      \"null\": {\n",
    "\n",
    "      },\n",
    "      \"nova\": {\n",
    "\n",
    "      },\n",
    "      \"pulsating_var\": {\n",
    "\n",
    "      },\n",
    "      \"transit\": {\n",
    "\n",
    "      }\n",
    "  }\n",
    "\n",
    "  for roots, dirs, files in os.walk(ROOT + \"object_spreadsheets/\"):\n",
    "    for spreadsheet in files:\n",
    "      kind = spreadsheet[:-4] # remove .csv\n",
    "      bucket = raw_classes[kind]\n",
    "\n",
    "      df = pd.read_csv(ROOT + \"object_spreadsheets/\" + spreadsheet)\n",
    "      df.dropna(axis=0, how=\"any\", inplace=True)\n",
    "\n",
    "      rows = len(df)\n",
    "\n",
    "\n",
    "      i = 0\n",
    "      for objname, ra, dec, rad, qual in zip(df[\"Name\"], df[\"RAJ2000\"], df[\"DecJ2000\"], df[\"query_rad\"], df[\"qual\"]):\n",
    "        i += 1\n",
    "        radius = float(rad)\n",
    "        qual = int(qual)\n",
    "        if qual < min_obj_qual:\n",
    "          continue\n",
    "\n",
    "        tbl = Irsa.query_region(\"{} {}\".format(ra, dec), catalog=neowise, spatial=\"Cone\",\n",
    "                            radius=radius * u.arcsec)\n",
    "\n",
    "        tbl = tbl.to_pandas()\n",
    "        tbl = tbl.loc[tbl[\"qual_frame\"]>= min_qual_frame]\n",
    "\n",
    "\n",
    "        bucket[objname] = {}\n",
    "        bucket[objname][\"df\"] = tbl\n",
    "        bucket[objname][\"np\"] = tbl.to_numpy()\n",
    "        bucket[objname][\"cluster\"] = {}\n",
    "        bucket[objname][\"flux\"] = {}\n",
    "\n",
    "        print(\"{}%\".format(i*100 // rows), end=\"\\r\")\n",
    "        print(kind + \": \", len(df.loc[df[\"qual\"] >= min_obj_qual]))\n",
    "        clear_output(wait=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 677,
     "status": "ok",
     "timestamp": 1698126346666,
     "user": {
      "displayName": "Matteo",
      "userId": "07662895649750931658"
     },
     "user_tz": 420
    },
    "id": "9VPnpTY6gEDw",
    "outputId": "a1e15d1a-325e-44a5-d684-7074f9c57805"
   },
   "outputs": [],
   "source": [
    "plotting = False\n",
    "\n",
    "if QUERY:\n",
    "  eps = {\n",
    "      \"null\": 1.25/3600,\n",
    "      \"nova\": 2/3600,\n",
    "      \"transit\": 1.5/3600,\n",
    "      \"pulsating_var\": 1.5/3600\n",
    "  }\n",
    "\n",
    "  min_pts = {\n",
    "      \"null\": 7,\n",
    "      \"nova\": 4,\n",
    "      \"transit\": 5,\n",
    "      \"pulsating_var\": 5\n",
    "  }\n",
    "\n",
    "  min_cluster_pts = 20\n",
    "\n",
    "  for kind in raw_classes:\n",
    "    for obj in raw_classes[kind]:\n",
    "      np_tbl = raw_classes[kind][obj][\"np\"]\n",
    "\n",
    "      cluster_tbl = np_tbl[:, :2]\n",
    "\n",
    "      clstr = DBSCAN(eps=eps[kind], min_samples=min_pts[kind]).fit(cluster_tbl) # high minsamples cutting out some very sparse examples\n",
    "\n",
    "      labels = clstr.labels_\n",
    "\n",
    "\n",
    "      raw_classes[kind][obj][\"cluster\"] = {}\n",
    "      noisepct = 0\n",
    "      for i in range(len(labels)): # For all the pts\n",
    "        if labels[i] != -1:\n",
    "          if labels[i] not in raw_classes[kind][obj][\"cluster\"]:\n",
    "            raw_classes[kind][obj][\"cluster\"][labels[i]] = []\n",
    "\n",
    "          raw_classes[kind][obj][\"cluster\"][labels[i]].append(np_tbl[i]) # Put it into the cluster dict with its label as key\n",
    "\n",
    "\n",
    "      for cluster_label in raw_classes[kind][obj][\"cluster\"].copy(): #  ------- TODO: Check that non-reigon query tables are only returning ONE CLUSTER. --------\n",
    "        raw_classes[kind][obj][\"cluster\"][cluster_label] = np.array(raw_classes[kind][obj][\"cluster\"][cluster_label])\n",
    "\n",
    "        if len(raw_classes[kind][obj][\"cluster\"][cluster_label]) < min_cluster_pts:\n",
    "          del raw_classes[kind][obj][\"cluster\"][cluster_label]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "error",
     "timestamp": 1698126830425,
     "user": {
      "displayName": "Matteo",
      "userId": "07662895649750931658"
     },
     "user_tz": 420
    },
    "id": "k4P3UBIkgTm4",
    "outputId": "9cd5212c-584a-42d0-a09d-0b7fbdd2e39b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matteo/WISE/./lib/flux_table.py:12: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  tbl[tbl == 'null'] = 0\n"
     ]
    }
   ],
   "source": [
    "if QUERY:\n",
    "  for kind in raw_classes:\n",
    "    for objname in raw_classes[kind]:\n",
    "      for cluster_label in raw_classes[kind][objname][\"cluster\"]:\n",
    "        flux_table = get_flux(raw_classes[kind][objname][\"cluster\"][cluster_label], raw_classes[kind][objname][\"df\"].columns.tolist())\n",
    "        raw_classes[kind][objname][\"flux\"][cluster_label] = flux_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "FGxnRtTTF_y6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Examples removed for testing:   Null:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>  Nova:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>  Pulsating Var:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>  Transit:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Examples removed for testing:   Null:  \u001b[1;36m5\u001b[0m  Nova:  \u001b[1;36m4\u001b[0m  Pulsating Var:  \u001b[1;36m5\u001b[0m  Transit:  \u001b[1;36m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "buckets = {\"null\": [], \"nova\": [], \"pulsating_var\": [], \"transit\": []}\n",
    "buckets_test = {\"null\": [], \"nova\": [], \"pulsating_var\": [], \"transit\": []}\n",
    "\n",
    "if not QUERY:\n",
    "  with open(ROOT + \"cached_data/train_buckets.pkl\", \"rb\") as f: # Save buckets\n",
    "    buckets = pickle.load(f)\n",
    "else:\n",
    "  for kind in buckets_test:\n",
    "    i = 0\n",
    "    for objname in raw_classes[kind]:\n",
    "      if i < min(test_cutoff * len(raw_classes[kind]) - 1, len(raw_classes[kind]) - 1):\n",
    "        for idx in raw_classes[kind][objname][\"flux\"]:\n",
    "          buckets[kind].append(raw_classes[kind][objname][\"flux\"][idx]) # Populate buckets\n",
    "          i+=1\n",
    "      else:\n",
    "        buckets_test[kind].append(raw_classes[kind][objname][\"df\"])\n",
    "    \n",
    "  print(\"Examples removed for testing:   Null: \", len(buckets_test[\"null\"]), \" Nova: \", len(buckets_test[\"nova\"]), \" Pulsating Var: \", len(buckets_test[\"pulsating_var\"]), \" Transit: \", len(buckets_test[\"transit\"]))\n",
    "  with open(ROOT + \"cached_data/train_buckets.pkl\", \"wb\") as f: # Save buckets\n",
    "    pickle.dump(buckets, f)\n",
    "\n",
    "  with open(ROOT + \"cached_data/test_buckets.pkl\", \"wb\") as f: # Save buckets\n",
    "    pickle.dump(buckets_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "executionInfo": {
     "elapsed": 417,
     "status": "ok",
     "timestamp": 1698207996188,
     "user": {
      "displayName": "Matteo",
      "userId": "07662895649750931658"
     },
     "user_tz": 420
    },
    "id": "H1ph4JlggaZi",
    "outputId": "08b91ad7-acba-4a72-f04e-44681bd8b2c5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Total examples of each class: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">44</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">43</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Total examples of each class: \u001b[1m[\u001b[0m\u001b[1;36m36\u001b[0m \u001b[1;36m31\u001b[0m \u001b[1;36m44\u001b[0m \u001b[1;36m43\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Weights: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.25541126</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.26623377</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.23809524</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.24025974</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Weights: \u001b[1m[\u001b[0m\u001b[1;36m0.25541126\u001b[0m \u001b[1;36m0.26623377\u001b[0m \u001b[1;36m0.23809524\u001b[0m \u001b[1;36m0.24025974\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "amt_train = 0.7\n",
    "\n",
    "class_weights = np.array([len(buckets[\"null\"]), len(buckets[\"nova\"]), len(buckets[\"pulsating_var\"]), len(buckets[\"transit\"])])\n",
    "\n",
    "\n",
    "print(\"Total examples of each class:\", class_weights)\n",
    "total = np.sum(class_weights)\n",
    "class_weights = total - class_weights\n",
    "class_weights = class_weights / (3 * total)\n",
    "print(\"Weights:\", class_weights)\n",
    "\n",
    "class_weights_ = torch.tensor(class_weights)\n",
    "\n",
    "\n",
    "buckets_train = {}\n",
    "buckets_valid = {}\n",
    "\n",
    "for name, data_dict_list in buckets.items(): # Split training items\n",
    "    total_examples = len(data_dict_list)\n",
    "    train_end = int(total_examples * amt_train)\n",
    "\n",
    "    buckets_train[name] = data_dict_list[:train_end]\n",
    "    buckets_valid[name] = data_dict_list[train_end:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kb8AksyKLWl3"
   },
   "source": [
    "# Dataset and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "2Ko33v2qGQdR"
   },
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "\n",
    "def swap(pct):\n",
    "  def inner(data):\n",
    "    new = torch.clone(data)\n",
    "    n = int(pct*len(new)) // 2\n",
    "    for _ in range(n):\n",
    "      one, two = random.sample(range(len(new)), 2)\n",
    "\n",
    "      temp = torch.clone(new[one])\n",
    "\n",
    "      new[one] = new[two]\n",
    "      new[two] = temp\n",
    "    return new\n",
    "  return inner\n",
    "\n",
    "\n",
    "def flip_x(data):\n",
    "  return torch.flip(data, (0,))\n",
    "\n",
    "def flip_y(data):\n",
    "  new = torch.clone(data)\n",
    "  new[:, 0] = -1 * new[:, 0]\n",
    "  new[:, 2] = -1 * new[:, 2]\n",
    "  return new\n",
    "\n",
    "def resample(std, pct=0.25):\n",
    "  def inner(data):\n",
    "    new = torch.clone(data)\n",
    "    stddev = [0 for _ in range(len(new))]\n",
    "\n",
    "    for i in random.sample(range(len(stddev)), int(pct*len(stddev))):\n",
    "      stddev[i] = std\n",
    "\n",
    "    stddev = torch.tensor(stddev)\n",
    "\n",
    "    new[:, 0] = torch.normal(new[:, 0], stddev)\n",
    "    new[:, 2] = torch.normal(new[:, 2], stddev)\n",
    "    return new\n",
    "\n",
    "  return inner\n",
    "\n",
    "def rescale_x(data):\n",
    "  s = random.random() *1.5\n",
    "\n",
    "  new = torch.clone(data)\n",
    "\n",
    "  new[:, -1] = s * new[:, -1]\n",
    "\n",
    "  return new\n",
    "\n",
    "def rescale_y(data):\n",
    "  s = random.random() * 1.5\n",
    "\n",
    "  new = torch.clone(data)\n",
    "\n",
    "  new[:, 0] = s * new[:, 0]\n",
    "  new[:, 2] = s * new[:, 2]\n",
    "\n",
    "  return new\n",
    "\n",
    "\n",
    "aug = [(rescale_x, 1), (rescale_y, 1), (resample(0.65, 0.35), 1), (flip_x, 1), (swap(0.1), 1), (flip_y, 1), (swap(0.2), 1), (resample(1, 0.25), 1)]\n",
    "\n",
    "class FluxSet(Dataset):\n",
    "  def __init__(self, classes, augmentation=None, choose=3, augmentation_frac=3, equalize=False):\n",
    "\n",
    "    self.choose = choose\n",
    "    self.augmentation_frac = augmentation_frac\n",
    "\n",
    "    self.buckets = {\"null\": [], \"nova\": [], \"pulsating_var\": [], \"transit\": []}\n",
    "    self.class_weights = class_weights_\n",
    "    for kind in classes:\n",
    "      flux_dicts = classes[kind]\n",
    "      for flux in flux_dicts: # each flux dict\n",
    "\n",
    "\n",
    "        timeseries_array = self.to_np(flux)\n",
    "\n",
    "        self.buckets[kind].append(torch.tensor(timeseries_array))\n",
    "\n",
    "    self.all = []\n",
    "\n",
    "    if augmentation:\n",
    "      for kind in self.buckets:\n",
    "        new = []\n",
    "        new += self.buckets[kind]\n",
    "        for ex in self.buckets[kind]:\n",
    "          for _ in range(self.augmentation_frac):\n",
    "            new += self.apply_pipeline([ex], random.sample(augmentation, choose))\n",
    "\n",
    "        self.buckets[kind] = new\n",
    "\n",
    "      # Equalization\n",
    "      if equalize:\n",
    "        lens = [len(self.buckets[b]) for b in self.buckets]\n",
    "        makeup = [max(lens) - v for v in lens]\n",
    "\n",
    "        for i, count in enumerate(makeup):\n",
    "          key = list(self.buckets.keys())[i]\n",
    "          for ex in self.buckets[key]:\n",
    "            if count <= 0:\n",
    "              break\n",
    "            self.buckets[key] += self.apply_pipeline([ex], random.sample(augmentation, choose))\n",
    "            count -= 1\n",
    "        # print(lens, [len(self.buckets[b]) for b in self.buckets])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for kind in self.buckets: # Data, Label pairing\n",
    "      for i, ex in enumerate(self.buckets[kind]):\n",
    "\n",
    "        label = torch.zeros(4)\n",
    "        label[list(self.buckets.keys()).index(kind)] = 1\n",
    "\n",
    "        self.all.append((ex, label))\n",
    "        self.buckets[kind][i] = ((ex, label))\n",
    "\n",
    "  def apply_pipeline(self, examples, pipeline):\n",
    "    p = copy(pipeline)\n",
    "\n",
    "    if len(p) == 0:\n",
    "      return examples\n",
    "\n",
    "    new = []\n",
    "    fn, times = p.pop(0)\n",
    "    for ex in examples:\n",
    "      for _ in range(times):\n",
    "        new.append(fn(ex))\n",
    "      del ex\n",
    "\n",
    "    return self.apply_pipeline(new, p)\n",
    "\n",
    "  def to_np(self, flux): # IMPORTANT! Defines order of data\n",
    "      # Len(pts) x 5 matrix\n",
    "      w1 = flux[\"norm\"][\"w1\"]\n",
    "      w1sig = flux[\"norm\"][\"w1sig\"]\n",
    "      w2 = flux[\"norm\"][\"w2\"]\n",
    "      w2sig = flux[\"norm\"][\"w2sig\"]\n",
    "      dt = flux[\"norm\"][\"dt\"]\n",
    "      day = flux[\"norm\"][\"day\"]\n",
    "\n",
    "      w1f = flux[\"norm\"][\"w1flux\"]\n",
    "\n",
    "      std_val = (flux[\"norm\"][\"w1std\"] + flux[\"norm\"][\"w2std\"]) / 2\n",
    "\n",
    "      std = np.array([std_val for _ in w1])\n",
    "\n",
    "      # Len(pts) x 5 matrix\n",
    "      # IMPORTANT! Defines order of data\n",
    "      return np.stack((w1f, std, day), axis=0).T\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    # Commented out is random sampling\n",
    "    # key = random.choice(list(self.buckets.keys()))\n",
    "    # item = random.choice(self.buckets[key])\n",
    "    # return item\n",
    "    return self.all[idx]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 708,
     "status": "ok",
     "timestamp": 1698124820275,
     "user": {
      "displayName": "Matteo",
      "userId": "07662895649750931658"
     },
     "user_tz": 420
    },
    "id": "gVFYIoC3AL6w",
    "outputId": "177d9c6b-b50c-4ed1-fd30-34e94419a8c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = FluxSet(buckets_train, aug, equalize=True)\n",
    "valid = FluxSet(buckets_valid)\n",
    "\n",
    "with open(ROOT + \"processed_datasets/data_train.pt\", \"wb\") as f:\n",
    "  torch.save(train, f)\n",
    "with open(ROOT + \"processed_datasets/data_valid.pt\", \"wb\") as f:\n",
    "  torch.save(valid, f)\n",
    "\n",
    "len(train)\n",
    "\n",
    "train[0][0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 303,
     "status": "ok",
     "timestamp": 1698125003860,
     "user": {
      "displayName": "Matteo",
      "userId": "07662895649750931658"
     },
     "user_tz": 420
    },
    "id": "cbyAhOM7Inpm",
    "outputId": "4490b93c-cc61-4fbd-c9b0-38384e4ee639"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The dataset does not contain NaN values.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The dataset does not contain NaN values.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "has_nan = False  # Initialize a flag to indicate the presence of NaN values\n",
    "\n",
    "for sample in train:\n",
    "    # Check if the sample contains NaN values\n",
    "    if torch.isnan(sample[0]).any():\n",
    "        has_nan = True\n",
    "        break  # Exit the loop as soon as a NaN is found\n",
    "\n",
    "if has_nan:\n",
    "    print(\"The dataset contains NaN values.\")\n",
    "else:\n",
    "    print(\"The dataset does not contain NaN values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fM8QWxxDYLq4"
   },
   "source": [
    "# Toy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DP9fq8HlYOOg"
   },
   "outputs": [],
   "source": [
    "def N(u, var):\n",
    "  return np.random.normal(u, np.sqrt(var))\n",
    "\n",
    "def sample(func, var, minx, maxx, pts, sparsity=0.5):\n",
    "  rng = np.random.default_rng()\n",
    "  res = (maxx-minx) / pts\n",
    "\n",
    "  all_x = []\n",
    "  for i in range(pts):\n",
    "    if rng.random() <= sparsity:\n",
    "      continue\n",
    "\n",
    "    all_x.append(minx + i*res)\n",
    "\n",
    "\n",
    "\n",
    "  all_y = [func(x) for x in all_x]\n",
    "\n",
    "  valrange = max(all_y) - min(all_y)\n",
    "  all_y = [N(y, var*valrange) for y in all_y]\n",
    "\n",
    "  all_y = sp.stats.zscore(all_y)\n",
    "  return (all_x, all_y)\n",
    "\n",
    "def pos_encoding(unsorted):\n",
    "  unsorted = np.array(unsorted)\n",
    "  sorted = unsorted[unsorted[:, -1].argsort()] # sort ascending\n",
    "\n",
    "  times = [0] + list(sorted[:, -1])\n",
    "  pos = np.array([times[i] - times[i-1] for i in range(1, len(times))])\n",
    "\n",
    "  sorted[:, -1] = pos # change abs time to positional encoding\n",
    "  return torch.tensor(sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H3nAQqd9YZWy"
   },
   "outputs": [],
   "source": [
    "def n_examples(fn_gen, var, minx, maxx, pts, sparsity, N):\n",
    "  ex = []\n",
    "\n",
    "  fn = fn_gen()\n",
    "\n",
    "  for i in range(N):\n",
    "    x, y = sample(fn, var, minx, maxx, pts, sparsity)\n",
    "    ts = []\n",
    "    for j in range(len(x)):\n",
    "      xpt = x[j]\n",
    "      ypt = y[j]\n",
    "      ts.append(np.array([ypt - np.random.rand()*var*10, np.random.rand()*var*10, ypt + np.random.rand()*var*10, np.random.rand()*var*10, xpt/np.max(x), xpt]))\n",
    "\n",
    "    ts = pos_encoding(ts)\n",
    "\n",
    "    ts = torch.tensor(ts)\n",
    "\n",
    "    ex.append(ts)\n",
    "\n",
    "  return ex\n",
    "\n",
    "class PseudoSet(Dataset):\n",
    "  def __init__(self, classes):\n",
    "    self.classes = classes\n",
    "\n",
    "    self.all = []\n",
    "    for i, class_ in enumerate(self.classes):\n",
    "      label = torch.zeros(len(self.classes))\n",
    "      label[i] = 1\n",
    "      for ex in class_:\n",
    "        self.all.append((ex, label))\n",
    "\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.all[idx]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9pahaQ9KbuDM"
   },
   "outputs": [],
   "source": [
    "num_ex = 100\n",
    "var = 0.005\n",
    "\n",
    "s, u = np.random.rand()*75, np.random.rand()*310\n",
    "norm = lambda s, u, x: (1 / np.sqrt(s**2 * 2 * 3.141)) * np.exp(-0.5 * ((x - u) / s)**2)\n",
    "\n",
    "def linefn_gen():\n",
    "  m = np.random.rand()*100\n",
    "  return lambda x: m * x\n",
    "\n",
    "def logfn_gen():\n",
    "  a = np.random.rand()*2\n",
    "  b = np.random.rand()*75\n",
    "  return lambda x: a * np.log(b * x)\n",
    "\n",
    "def bellfn_gen():\n",
    "  s = np.random.rand()*12\n",
    "  u = (np.random.rand() - 0.5) * 6\n",
    "  norm = lambda s, u, x: (1 / np.sqrt(s**2 * 2 * 3.141)) * np.exp(-0.5 * ((x - u) / s)**2)\n",
    "  return lambda x: norm(s, u, x)\n",
    "\n",
    "\n",
    "lines = n_examples(linefn_gen, 5*var, 0, 1000, 267, 0.65, num_ex)\n",
    "logs = n_examples(logfn_gen, var, 0.1, 4, 267, 0.65, num_ex)\n",
    "bells = n_examples(bellfn_gen, 0.01*var, -10, 10, 267, 0.65, num_ex)\n",
    "\n",
    "def displayex(ex):\n",
    "  fig = go.Figure()\n",
    "  tr1 = go.Scatter(\n",
    "      x=ex[:, -2],\n",
    "      y=ex[:, 0],\n",
    "      mode='markers',\n",
    "      marker=dict(size=5, opacity=.75)\n",
    "  )\n",
    "  tr2 = go.Scatter(\n",
    "      x=ex[:, -2],\n",
    "      y=ex[:, 2],\n",
    "      mode='markers',\n",
    "      marker=dict(size=5, opacity=.75)\n",
    "  )\n",
    "\n",
    "  fig.add_trace(tr1)\n",
    "  fig.add_trace(tr2)\n",
    "\n",
    "  fig.show()\n",
    "\n",
    "displayex(lines[15])\n",
    "displayex(logs[15])\n",
    "displayex(bells[15])\n",
    "\n",
    "\n",
    "trainsplit = 0.7\n",
    "\n",
    "splitidx = int(0.7 * num_ex)\n",
    "\n",
    "train = PseudoSet((lines[:splitidx], logs[:splitidx], bells[:splitidx]))\n",
    "valid = PseudoSet((lines[splitidx:], logs[splitidx:], bells[splitidx:]))\n",
    "\n",
    "print(train[0][0].shape)\n",
    "\n",
    "with open(ROOT + \"datasets/toy_data_train.pt\", \"wb\") as f:\n",
    "  torch.save(train, f)\n",
    "with open(ROOT + \"datasets/toy_data_valid.pt\", \"wb\") as f:\n",
    "  torch.save(valid, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejR6LDG7LcsD"
   },
   "source": [
    "# Data Vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 199,
     "status": "ok",
     "timestamp": 1695270022906,
     "user": {
      "displayName": "Matteo",
      "userId": "07662895649750931658"
     },
     "user_tz": 420
    },
    "id": "2TsQzzhgcSue",
    "outputId": "ae4ed0b4-5f0f-4fc8-c6bf-c23211bb29f9"
   },
   "outputs": [],
   "source": [
    "ex = buckets['transit'][7] # One Example\n",
    "\n",
    "l = np.argmin([len(x[\"raw\"][\"w1\"]) for x in buckets['null']])\n",
    "print(l)\n",
    "\n",
    "def get_trace(data_dict, key):\n",
    "\n",
    "  x_data = data_dict[\"day\"]\n",
    "  y_data = data_dict[key]\n",
    "\n",
    "  sort_idxs = np.argsort(x_data)\n",
    "\n",
    "  x_data = x_data[sort_idxs]\n",
    "  y_data = y_data[sort_idxs]\n",
    "\n",
    "\n",
    "  return go.Scatter(\n",
    "    x=x_data,\n",
    "    y=y_data,\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, opacity=.75),\n",
    "    name=key,\n",
    "  )\n",
    "\n",
    "data_dict = ex[\"norm\"]\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(get_trace(data_dict, \"w1flux\"))\n",
    "\n",
    "\n",
    "\n",
    "update_layout(fig, legend_out=True)\n",
    "\n",
    "fig.layout.width = 1200\n",
    "fig.layout.height = 0.65 * fig.layout.width\n",
    "\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(get_trace(data_dict, \"w1\"))\n",
    "\n",
    "\n",
    "update_layout(fig, legend_out=True)\n",
    "\n",
    "fig.layout.width = 1200\n",
    "fig.layout.height = 0.65 * fig.layout.width\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O1YXGmAjlmfs"
   },
   "outputs": [],
   "source": [
    "def plot_from_datadict(data_dict, use_norm=False):\n",
    "  key = \"norm\" if use_norm else \"raw\"\n",
    "\n",
    "  fig = go.Figure()\n",
    "\n",
    "  fig.add_trace(get_trace(data_dict[key], \"w1\"))\n",
    "  fig.add_trace(get_trace(data_dict[key], \"w2\"))\n",
    "  fig.add_trace(get_trace(data_dict[key], \"w1sig\"))\n",
    "  fig.add_trace(get_trace(data_dict[key], \"w2sig\"))\n",
    "\n",
    "\n",
    "  update_layout(fig, legend_out=True)\n",
    "\n",
    "  fig.layout.width = 800\n",
    "  fig.layout.height = 0.65 * fig.layout.width\n",
    "\n",
    "\n",
    "  return fig\n",
    "\n",
    "def plot_from_tensor(data):\n",
    "  fig = go.Figure()\n",
    "\n",
    "  w1 = data[:, 0].numpy()\n",
    "  std = data[:, 1].numpy()\n",
    "\n",
    "\n",
    "  day = data[:, -1].numpy()\n",
    "\n",
    "\n",
    "  fig.add_trace(go.Scatter(x=day, y=w1, marker=dict(size=5, opacity=0.7), name=\"w1mpro z-scored\", mode='markers'))\n",
    "  fig.add_trace(go.Scatter(x=day, y=std, marker=dict(size=5, opacity=0.7), name=\"w2mpro z-scored\", mode='markers'))\n",
    "\n",
    "  update_layout(fig, legend_out=True)\n",
    "\n",
    "  fig.layout.width = 800\n",
    "  fig.layout.height = 0.65 * fig.layout.width\n",
    "\n",
    "\n",
    "  return fig\n",
    "\n",
    "# Show all novae\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "psRJbQsJRF81"
   },
   "outputs": [],
   "source": [
    "d, l = list(train)[500]\n",
    "plot_from_tensor(d).show()\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$$x$$"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "fM8QWxxDYLq4",
    "ejR6LDG7LcsD"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
