{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPxTVATuLewu"
   },
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-13UXM7xeZAE"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from rich import print\n",
    "import pickle\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import clear_output\n",
    "import astropy.units as u\n",
    "from astroquery.ipac.irsa import Irsa\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "import os\n",
    "import sys\n",
    "\n",
    "ROOT = os.path.join(\"./\")\n",
    "sys.path.append(ROOT + \"lib\")\n",
    "\n",
    "from lightsource import LightSource\n",
    "from sourceset import SourceSet, default_aug\n",
    "from helpers import get_coordinates\n",
    "\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "neowise = 'neowiser_p1bs_psd'\n",
    "min_qual_frame = 4\n",
    "min_obj_qual = 3\n",
    "\n",
    "test_cutoff = 0.9\n",
    "\n",
    "QUERY = False # Toggle querying - Only do this if youve changed the data.csvs\n",
    "RECLUSTER = False # Toggle re-clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPVHCeHrK94N"
   },
   "source": [
    "# Spreadsheets to Data Tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rVtcWMwlfeef"
   },
   "outputs": [],
   "source": [
    "if QUERY:\n",
    "  raw_classes = {\n",
    "      \"null\": {\n",
    "\n",
    "      },\n",
    "      \"nova\": {\n",
    "\n",
    "      },\n",
    "      \"pulsating_var\": {\n",
    "\n",
    "      },\n",
    "      \"transit\": {\n",
    "\n",
    "      }\n",
    "  }\n",
    "\n",
    "  for roots, dirs, files in os.walk(ROOT + \"object_spreadsheets/\"):\n",
    "    for spreadsheet in files:\n",
    "      kind = spreadsheet[:-4] # remove .csv\n",
    "      bucket = raw_classes[kind]\n",
    "\n",
    "      df = pd.read_csv(ROOT + \"object_spreadsheets/\" + spreadsheet)\n",
    "      df.dropna(axis=0, how=\"any\", inplace=True)\n",
    "\n",
    "      i = 0\n",
    "      for objname, ra, dec, rad, qual in zip(df[\"Name\"], df[\"RAJ2000\"], df[\"DecJ2000\"], df[\"query_rad\"], df[\"qual\"]):\n",
    "        i += 1\n",
    "        radius = float(rad)\n",
    "        qual = int(qual)\n",
    "        if qual < min_obj_qual:\n",
    "          continue\n",
    "\n",
    "        print(\"Querying {}...\".format(objname))\n",
    "\n",
    "        coordstring = \"{} {}\".format(ra, dec)\n",
    "        c = get_coordinates(coordstring) # Safer\n",
    "\n",
    "        tbl = Irsa.query_region(c, catalog=neowise, spatial=\"Cone\",\n",
    "                            radius=radius * u.arcsec)\n",
    "\n",
    "        tbl = tbl.to_pandas()\n",
    "        tbl = tbl.loc[tbl[\"qual_frame\"]>= min_qual_frame]\n",
    "\n",
    "        bucket[objname] = LightSource(tbl)\n",
    "\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        print(\"{}%\".format(i*100 // len(df)), end=\"\\r\")\n",
    "        print(kind + \": \", len(df.loc[df[\"qual\"] >= min_obj_qual]))\n",
    "\n",
    "else:\n",
    "  raw_classes = pickle.load(open(ROOT + \"cached_data/raw_classes.pkl\", \"rb\"))\n",
    "\n",
    "  #Print sources and their number of detections\n",
    "  # for kind in raw_classes:\n",
    "  #   for objname in raw_classes[kind]:\n",
    "  #       obj = raw_classes[kind][objname]\n",
    "  #       l = len(obj.get_numpy())\n",
    "  #       print(\"{} source: {} - {}dets\".format(kind, objname, l))\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 677,
     "status": "ok",
     "timestamp": 1698126346666,
     "user": {
      "displayName": "Matteo",
      "userId": "07662895649750931658"
     },
     "user_tz": 420
    },
    "id": "9VPnpTY6gEDw",
    "outputId": "a1e15d1a-325e-44a5-d684-7074f9c57805"
   },
   "outputs": [],
   "source": [
    "if RECLUSTER:\n",
    "  eps = {\n",
    "      \"null\": 0.75/3600,\n",
    "      \"nova\": 0.75/3600,\n",
    "      \"transit\": 1/3600,\n",
    "      \"pulsating_var\": 1/3600\n",
    "  }\n",
    "\n",
    "  min_pts = {\n",
    "      \"null\": 15,\n",
    "      \"nova\": 8,\n",
    "      \"transit\": 12,\n",
    "      \"pulsating_var\": 12\n",
    "  }\n",
    "\n",
    "  for kind in raw_classes:\n",
    "    for obj in raw_classes[kind]:\n",
    "      np_tbl = raw_classes[kind][obj].get_numpy()\n",
    "      df = raw_classes[kind][obj].get_pandas()\n",
    "\n",
    "      cluster_tbl = np_tbl[:, :2]\n",
    "      clstr = DBSCAN(eps=eps[kind], min_samples=min_pts[kind]).fit(cluster_tbl) # high minsamples cutting out some very sparse examples\n",
    "\n",
    "      labels = clstr.labels_\n",
    "      cluster_sizes = np.bincount(labels[labels!=-1])\n",
    "      biggest_cluster = np.argmax(cluster_sizes)\n",
    "      num_removed = len(np_tbl) - cluster_sizes[biggest_cluster]\n",
    "      if num_removed / biggest_cluster >= 0.2:\n",
    "        print(\"Warning: {}'s biggest cluster is sparse: {} to {} pts after clustering\".format(obj, len(np_tbl), biggest_cluster))\n",
    "\n",
    "      filter_mask = [x == biggest for x in labels]\n",
    "      df = df[filter_mask]\n",
    "      raw_classes[kind][obj] = LightSource(df)\n",
    "\n",
    "  with open(ROOT + \"cached_data/raw_classes.pkl\", \"wb\") as f:\n",
    "    pickle.dump(raw_classes, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FGxnRtTTF_y6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Examples removed for testing:   Null:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>  Nova:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>  Pulsating Var:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>  Transit:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Examples removed for testing:   Null:  \u001b[1;36m5\u001b[0m  Nova:  \u001b[1;36m4\u001b[0m  Pulsating Var:  \u001b[1;36m5\u001b[0m  Transit:  \u001b[1;36m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "buckets = {\"null\": [], \"nova\": [], \"pulsating_var\": [], \"transit\": []}\n",
    "buckets_test = {\"null\": [], \"nova\": [], \"pulsating_var\": [], \"transit\": []}\n",
    "for kind in buckets_test:\n",
    "  i = 0\n",
    "  for objname in raw_classes[kind]:\n",
    "    if i < test_cutoff * len(raw_classes[kind]) - 1: # cutoff to test set\n",
    "      buckets[kind].append(raw_classes[kind][objname])\n",
    "    else:\n",
    "      buckets_test[kind].append(raw_classes[kind][objname])\n",
    "    i += 1\n",
    "  \n",
    "print(\"Examples removed for testing:   Null: \", len(buckets_test[\"null\"]), \" Nova: \", len(buckets_test[\"nova\"]), \" Pulsating Var: \", len(buckets_test[\"pulsating_var\"]), \" Transit: \", len(buckets_test[\"transit\"]))\n",
    "with open(ROOT + \"cached_data/train_buckets.pkl\", \"wb\") as f: # Save buckets\n",
    "  pickle.dump(buckets, f)\n",
    "\n",
    "with open(ROOT + \"cached_data/test_buckets.pkl\", \"wb\") as f: # Save buckets\n",
    "  pickle.dump(buckets_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "executionInfo": {
     "elapsed": 417,
     "status": "ok",
     "timestamp": 1698207996188,
     "user": {
      "displayName": "Matteo",
      "userId": "07662895649750931658"
     },
     "user_tz": 420
    },
    "id": "H1ph4JlggaZi",
    "outputId": "08b91ad7-acba-4a72-f04e-44681bd8b2c5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Total examples of each class: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">44</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">43</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Total examples of each class: \u001b[1m[\u001b[0m\u001b[1;36m36\u001b[0m \u001b[1;36m31\u001b[0m \u001b[1;36m44\u001b[0m \u001b[1;36m43\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Weights: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.23376623</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2012987</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.28571429</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.27922078</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Weights: \u001b[1m[\u001b[0m\u001b[1;36m0.23376623\u001b[0m \u001b[1;36m0.2012987\u001b[0m  \u001b[1;36m0.28571429\u001b[0m \u001b[1;36m0.27922078\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "amt_train = 0.7\n",
    "\n",
    "num_of_examples = np.array([len(buckets[\"null\"]), len(buckets[\"nova\"]), len(buckets[\"pulsating_var\"]), len(buckets[\"transit\"])])\n",
    "class_weights = num_of_examples / np.sum(num_of_examples)\n",
    "\n",
    "print(\"Total examples of each class:\", num_of_examples)\n",
    "print(\"Weights:\", class_weights)\n",
    "\n",
    "class_weights_ = torch.tensor(class_weights)\n",
    "\n",
    "\n",
    "buckets_train = {}\n",
    "buckets_valid = {}\n",
    "\n",
    "for name, data_dict_list in buckets.items(): # Split training items\n",
    "    total_examples = len(data_dict_list)\n",
    "    train_end = int(total_examples * amt_train)\n",
    "\n",
    "    buckets_train[name] = data_dict_list[:train_end]\n",
    "    buckets_valid[name] = data_dict_list[train_end:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kb8AksyKLWl3"
   },
   "source": [
    "# Dataset and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 708,
     "status": "ok",
     "timestamp": 1698124820275,
     "user": {
      "displayName": "Matteo",
      "userId": "07662895649750931658"
     },
     "user_tz": 420
    },
    "id": "gVFYIoC3AL6w",
    "outputId": "177d9c6b-b50c-4ed1-fd30-34e94419a8c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length =  260\n",
      "Length =  265\n",
      "Length =  263\n",
      "Length =  249\n",
      "Length =  272\n",
      "Length =  276\n",
      "Length =  226\n",
      "Length =  217\n",
      "Length =  158\n",
      "Length =  442\n",
      "Length =  447\n",
      "Length =  404\n",
      "Length =  316\n",
      "Length =  241\n",
      "Length =  246\n",
      "Length =  251\n",
      "Length =  1853\n",
      "newlen  999\n",
      "Length =  762\n",
      "Length =  31525\n",
      "newlen  999\n",
      "Length =  31700\n",
      "newlen  999\n",
      "Length =  31582\n",
      "newlen  999\n",
      "Length =  31908\n",
      "newlen  999\n",
      "Length =  31917\n",
      "newlen  999\n",
      "Length =  32011\n",
      "newlen  999\n",
      "Length =  31839\n",
      "newlen  999\n",
      "Length =  107\n",
      "Length =  71\n",
      "Length =  207\n",
      "Length =  34\n",
      "Length =  39\n",
      "Length =  159\n",
      "Length =  141\n",
      "Length =  392\n",
      "Length =  28\n",
      "Length =  165\n",
      "Length =  20\n",
      "Length =  49\n",
      "Length =  38\n",
      "Length =  146\n",
      "Length =  84\n",
      "Length =  46\n",
      "Length =  148\n",
      "Length =  177\n",
      "Length =  31\n",
      "Length =  33\n",
      "Length =  31\n",
      "Length =  494\n",
      "Length =  335\n",
      "Length =  298\n",
      "Length =  238\n",
      "Length =  246\n",
      "Length =  228\n",
      "Length =  228\n",
      "Length =  248\n",
      "Length =  217\n",
      "Length =  264\n",
      "Length =  250\n",
      "Length =  271\n",
      "Length =  268\n",
      "Length =  307\n",
      "Length =  286\n",
      "Length =  3932\n",
      "newlen  999\n",
      "Length =  318\n",
      "Length =  189\n",
      "Length =  247\n",
      "Length =  249\n",
      "Length =  1292\n",
      "newlen  999\n",
      "Length =  229\n",
      "Length =  242\n",
      "Length =  235\n",
      "Length =  225\n",
      "Length =  249\n",
      "Length =  227\n",
      "Length =  289\n",
      "Length =  611\n",
      "Length =  252\n",
      "Length =  246\n",
      "Length =  259\n",
      "Length =  228\n",
      "Length =  249\n",
      "Length =  238\n",
      "Length =  236\n",
      "Length =  234\n",
      "Length =  209\n",
      "Length =  254\n",
      "Length =  275\n",
      "Length =  255\n",
      "Length =  219\n",
      "Length =  200\n",
      "Length =  224\n",
      "Length =  237\n",
      "Length =  264\n",
      "Length =  305\n",
      "Length =  294\n",
      "Length =  241\n",
      "Length =  240\n",
      "Length =  221\n",
      "Length =  366\n",
      "Length =  355\n",
      "Length =  365\n",
      "Length =  299\n",
      "Length =  330\n",
      "Length =  311\n",
      "Length =  282\n",
      "Length =  268\n",
      "Length =  277\n",
      "Length =  29719\n",
      "newlen  999\n",
      "Length =  31653\n",
      "newlen  999\n",
      "Length =  31544\n",
      "newlen  999\n",
      "Length =  13348\n",
      "newlen  999\n",
      "Length =  16333\n",
      "newlen  999\n",
      "Length =  5655\n",
      "newlen  999\n",
      "Length =  1316\n",
      "newlen  999\n",
      "Length =  355\n",
      "Length =  321\n",
      "Length =  29306\n",
      "newlen  999\n",
      "Length =  29369\n",
      "newlen  999\n",
      "Length =  58\n",
      "Length =  12\n",
      "Length =  106\n",
      "Length =  56\n",
      "Length =  50\n",
      "Length =  23\n",
      "Length =  78\n",
      "Length =  587\n",
      "Length =  42\n",
      "Length =  26\n",
      "Length =  269\n",
      "Length =  251\n",
      "Length =  297\n",
      "Length =  236\n",
      "Length =  236\n",
      "Length =  260\n",
      "Length =  286\n",
      "Length =  299\n",
      "Length =  239\n",
      "Length =  317\n",
      "Length =  241\n",
      "Length =  290\n",
      "Length =  319\n",
      "Length =  216\n",
      "Length =  256\n",
      "Length =  555\n",
      "Length =  332\n",
      "Length =  281\n",
      "Length =  326\n",
      "Length =  310\n",
      "Length =  377\n",
      "Length =  347\n",
      "Length =  312\n",
      "Length =  281\n",
      "Length =  299\n",
      "Length =  320\n",
      "Length =  438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(480, 48)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = SourceSet(buckets_train, default_aug, equalize=True)\n",
    "valid = SourceSet(buckets_valid)\n",
    "\n",
    "with open(ROOT + \"processed_datasets/data_train.pt\", \"wb\") as f:\n",
    "  torch.save(train, f)\n",
    "with open(ROOT + \"processed_datasets/data_valid.pt\", \"wb\") as f:\n",
    "  torch.save(valid, f)\n",
    "\n",
    "len(train), len(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 303,
     "status": "ok",
     "timestamp": 1698125003860,
     "user": {
      "displayName": "Matteo",
      "userId": "07662895649750931658"
     },
     "user_tz": 420
    },
    "id": "cbyAhOM7Inpm",
    "outputId": "4490b93c-cc61-4fbd-c9b0-38384e4ee639"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The dataset does not contain NaN values.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The dataset does not contain NaN values.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "has_nan = False  # Initialize a flag to indicate the presence of NaN values\n",
    "\n",
    "for sample in train:\n",
    "    # Check if the sample contains NaN values\n",
    "    if torch.isnan(sample[0]).any():\n",
    "        has_nan = True\n",
    "        break  # Exit the loop as soon as a NaN is found\n",
    "\n",
    "if has_nan:\n",
    "    print(\"The dataset contains NaN values.\")\n",
    "else:\n",
    "    print(\"The dataset does not contain NaN values.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "fM8QWxxDYLq4",
    "ejR6LDG7LcsD"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
