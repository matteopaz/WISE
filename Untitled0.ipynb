{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPir7pbhh8qDqDl+8/eaqvF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["%%capture\n","if True:\n","  !pip install astroquery\n","  !pip install plotly\n","  !pip install kaleido\n","  !pip install nbformat"],"metadata":{"id":"naXrNuV1uHnh","executionInfo":{"status":"ok","timestamp":1698204974627,"user_tz":420,"elapsed":43007,"user":{"displayName":"Matteo","userId":"07662895649750931658"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ZF597VBGNgkX","executionInfo":{"status":"ok","timestamp":1698205006038,"user_tz":420,"elapsed":31415,"user":{"displayName":"Matteo","userId":"07662895649750931658"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0390917e-25f4-49fd-d078-ca361b30b4b7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["import torch\n","import pandas as pd\n","import numpy as np\n","import pickle\n","import plotly.graph_objects as go\n","import sklearn\n","from sklearn.cluster import DBSCAN\n","import os\n","import sys\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","ROOT = os.path.join(\"/content\", \"drive\", \"MyDrive\", \"Colab_Data\", \"src/\")\n","sys.path.append(ROOT + \"common_code\")\n","\n","from plotly_style import update_layout\n","from flux_table import get_flux\n","from fluxtable_to_tensor import fluxtable_to_tensor\n","# with open(ROOT + \"models/model.pt\", \"rb\") as f:\n","#   model = torch.load(f)\n","# state = torch.load(ROOT + \"models/model.pt\")\n","TEST = True\n","BATCHSIZE = 10"]},{"cell_type":"code","source":["def get_flux(tbl, cols):\n","    dets = tbl.to_numpy()\n","    # Get correct columns\n","    colnames = cols.tolist()\n","    mjdindx = colnames.index(\"mjd\")\n","    w1indx = colnames.index(\"w1mpro\")\n","    w2indx = colnames.index(\"w2mpro\")\n","    w1sindx = colnames.index(\"w1sigmpro\")\n","    w2sindx = colnames.index(\"w2sigmpro\")\n","\n","    # Type processing\n","    dets[dets == 'null'] = 0\n","    mjds = dets[:,mjdindx].astype(float)\n","    w1mpro = np.nan_to_num(dets[:, w1indx].astype(float), nan=0.0)\n","    w1sig = np.nan_to_num(dets[:, w1sindx].astype(float), nan=0.0)\n","    w2mpro = np.nan_to_num(dets[:, w2indx].astype(float), nan=0.0)\n","    w2sig = np.nan_to_num(dets[:, w2sindx].astype(float), nan=0.0)\n","\n","    # Sort by date\n","    sorter = np.argsort(mjds)\n","\n","    # print(mjds, sorter)\n","\n","    mjds = mjds[sorter]\n","    w1mpro = w1mpro[sorter]\n","    w1sig = w1sig[sorter]\n","    w2mpro = w2mpro[sorter]\n","    w2sig = w2sig[sorter]\n","\n","    # Analysis\n","\n","    w1mean = np.nanmean(w1mpro)\n","    w1median = np.nanmedian(w1mpro)\n","\n","    w2mean = np.nanmean(w2mpro)\n","    w2median = np.nanmedian(w2mpro)\n","\n","    w1var = np.nanvar(w1mpro)\n","    w2var = np.nanvar(w2mpro)\n","    w1std = np.sqrt(w1var)\n","    w2std = np.sqrt(w2var)\n","\n","    w1mad = np.nanmedian([abs(mag - w1median) for mag in w1mpro]) # Mean Absolute Deviation - Not used\n","    w2mad = np.nanmedian([abs(mag - w2median) for mag in w2mpro])\n","\n","    # Normalize with modified z-scoring\n","    w1norm = []\n","    w2norm = []\n","    for mag in w1mpro:\n","        w1norm.append((mag - w1mean) / (w1std)) # Z-score divided by 5.\n","\n","    for mag in w2mpro:\n","        w2norm.append((mag - w2mean) / (w2std))\n","\n","    w1norm = np.nan_to_num(np.array(w1norm))\n","    w2norm = np.nan_to_num(np.array(w2norm))\n","\n","\n","    # Optional Flux format\n","    to_flux_w1 = lambda m: 309.54 * 10**(-m / 2.5)\n","    to_flux_w2 = lambda m: 171.787 * 10**(-m / 2.5)\n","    w1flux = to_flux_w1(w1mpro)\n","    w2flux = to_flux_w2(w2mpro)\n","\n","    # Flux normalization arcsin params\n","    ADJ = 0\n","    DIV = 0.001\n","\n","    w1flux_norm = np.arcsinh((to_flux_w1(w1mpro) - ADJ) /DIV)\n","    w2flux_norm = np.arcsinh((to_flux_w2(w2mpro) - ADJ) /DIV)\n","\n","\n","\n","    # Days since first timepoint\n","    day = mjds - mjds[0]\n","\n","    day_norm = day / np.max(day)\n","\n","    # Times since last observation\n","\n","    dt = [day[i+1] - day[i] for i in range(len(day) - 1)]\n","    dt = [np.median(dt)] + dt\n","\n","\n","    # print(\"day\", day)\n","    # print(\"dt\", dt)\n","\n","\n","    # Normalized times since last observation\n","\n","    dt_norm = np.array([np.arcsinh(dt_ex / np.median(dt)) for dt_ex in dt]).flatten()\n","\n","\n","\n","\n","    data_dict = {\n","        \"raw\": {\n","          \"w1\": w1mpro,\n","          \"w1flux\": w1flux,\n","          \"w1sig\": w1sig,\n","          \"w2\": w2mpro,\n","          \"w2flux\": w2flux,\n","          \"w2sig\": w2sig,\n","          \"mjd\": mjds,\n","          \"day\": day,\n","          \"dt\": dt\n","        },\n","        \"norm\": {\n","          \"w1\": w1norm,\n","          \"w1flux\": w1flux_norm,\n","          \"w1std\": w1std,\n","          \"w1sig\": w1sig,\n","          \"w2\": w2norm,\n","          \"w2std\": w2std,\n","          \"w2flux\": w2flux_norm,\n","          \"w2sig\": w2sig,\n","          \"mjd\": mjds,\n","          \"day\": day_norm,\n","          \"dt\": dt_norm\n","        },\n","        \"analyze\": {\n","            \"mean\": {\n","                \"w1\": w1mean,\n","                \"w2\": w2mean\n","            },\n","            \"median\": {\n","                \"w1\": w1median,\n","                \"w2\": w2median\n","            }\n","        }\n","    }\n","\n","\n","    return data_dict"],"metadata":{"id":"4s62vUU46orX","executionInfo":{"status":"ok","timestamp":1698207807562,"user_tz":420,"elapsed":164,"user":{"displayName":"Matteo","userId":"07662895649750931658"}}},"execution_count":69,"outputs":[]},{"cell_type":"code","source":["object_key = {}\n","test_row_key = {}\n","raw = pd.DataFrame()\n","\n","if TEST:\n","  with open(ROOT + \"datasets/test_buckets.pkl\", \"rb\") as f:\n","    test_buckets = pickle.load(f)\n","\n","  for kind in test_buckets:\n","    for obj in test_buckets[kind]:\n","      ra = obj[\"ra\"].to_numpy()\n","      dec = obj[\"dec\"].to_numpy()\n","      center = (np.mean(ra), np.mean(dec))\n","      object_key[center] = kind\n","\n","  for kind in test_buckets:\n","    for df in test_buckets[kind]:\n","      start = len(raw) - 1\n","      end = start + len(df)\n","      raw = pd.concat((raw, df), ignore_index=True)\n","      for i in range(start,end):\n","        test_row_key[i] = kind\n","\n","\n","  raw.insert(len(raw.columns), \"idx\", list(range(len(raw))), True) #indexing\n","else:\n","  pass"],"metadata":{"id":"vGe9oyXyQ2Jy","executionInfo":{"status":"ok","timestamp":1698206434315,"user_tz":420,"elapsed":183,"user":{"displayName":"Matteo","userId":"07662895649750931658"}}},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":["Clustering and collecting objects"],"metadata":{"id":"_beFJRacc6Jc"}},{"cell_type":"code","source":["clstr_tbl = raw[[\"ra\", \"dec\"]]\n","dbscan = DBSCAN(eps=1.25, min_samples=6).fit(clstr_tbl)\n","labels = dbscan.labels_\n","\n","objects = {}\n","\n","for i, label in enumerate(labels):\n","  if label != -1:\n","    if label not in objects:\n","      objects[label] = raw.iloc[[i]]\n","    else:\n","      objects[label] = pd.concat((objects[label], raw.iloc[[i]]))"],"metadata":{"id":"vt5rU-zB12dB","executionInfo":{"status":"ok","timestamp":1698206488270,"user_tz":420,"elapsed":13455,"user":{"displayName":"Matteo","userId":"07662895649750931658"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["len(raw)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4swXlmyV-grb","executionInfo":{"status":"ok","timestamp":1698206499570,"user_tz":420,"elapsed":4,"user":{"displayName":"Matteo","userId":"07662895649750931658"}},"outputId":"71a20c29-eefe-4145-c55b-abac24ac94ab"},"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5227"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["print(sum([len(o) for o in objects.values()]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gSGWaYKr-OZe","executionInfo":{"status":"ok","timestamp":1698206500535,"user_tz":420,"elapsed":175,"user":{"displayName":"Matteo","userId":"07662895649750931658"}},"outputId":"3dd4b70c-ce3c-450e-e2eb-bd83b4555cb6"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["5227\n"]}]},{"cell_type":"code","source":["len(set(raw[\"mjd\"]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ee7wo6J_FNpB","executionInfo":{"status":"ok","timestamp":1698207981271,"user_tz":420,"elapsed":347,"user":{"displayName":"Matteo","userId":"07662895649750931658"}},"outputId":"98787cc9-aee2-4903-eb2a-6a931c51efb7"},"execution_count":80,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3994"]},"metadata":{},"execution_count":80}]},{"cell_type":"code","source":["len(set(objects[1][\"mjd\"])) - len(objects[1][\"mjd\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6_rdg5vqERYL","executionInfo":{"status":"ok","timestamp":1698207933790,"user_tz":420,"elapsed":4,"user":{"displayName":"Matteo","userId":"07662895649750931658"}},"outputId":"b30514f5-1aaf-4376-b7e7-a2c2129c3b45"},"execution_count":77,"outputs":[{"output_type":"execute_result","data":{"text/plain":["-474"]},"metadata":{},"execution_count":77}]},{"cell_type":"code","source":["print(get_flux(objects[0], objects[0].columns))"],"metadata":{"id":"s3XTdzAxdZye"},"execution_count":null,"outputs":[]}]}